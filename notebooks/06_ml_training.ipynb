{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# ML Training with MSD Lung RadiObject: Segmentation\n",
    "\n",
    "This notebook trains a 3D UNet for lung tumor segmentation using the Medical Segmentation Decathlon data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Load** RadiObject from URI (S3 or local)\n",
    "2. **Explore** data and segmentation masks\n",
    "3. **Split** into train/validation sets\n",
    "4. **Train** a MONAI UNet model\n",
    "5. **Evaluate** with Dice score\n",
    "\n",
    "## Task\n",
    "\n",
    "Semantic segmentation: Predict lung tumor mask from CT volume patches.\n",
    "\n",
    "**Prerequisites:** Run [05_ingest_msd.ipynb](./05_ingest_msd.ipynb) first to create the MSD Lung RadiObject with CT and seg collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from config import MSD_LUNG_URI, S3_REGION\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import Compose, RandFlipd\n",
    "\n",
    "from radiobject import RadiObject, configure\n",
    "from radiobject.ctx import S3Config\n",
    "from radiobject.ml import (\n",
    "    create_training_dataloader,\n",
    "    create_validation_dataloader,\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"RadiObject URI: {MSD_LUNG_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine compute device\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Training device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure S3 access if using S3 URI\n",
    "if MSD_LUNG_URI.startswith(\"s3://\"):\n",
    "    configure(s3=S3Config(region=S3_REGION, max_parallel_ops=8))\n",
    "\n",
    "TEMP_DIR = tempfile.mkdtemp(prefix=\"msd_ml_\")\n",
    "print(f\"Temp directory: {TEMP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-radiobject",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RadiObject\n",
    "radi = RadiObject(MSD_LUNG_URI)\n",
    "\n",
    "# Quick summary using describe()\n",
    "print(radi.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-collections",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify both CT and seg collections exist\n",
    "print(f\"Collections: {radi.collection_names}\")\n",
    "print(f\"CT shape: {radi.CT.shape}\")\n",
    "print(f\"seg shape: {radi.seg.shape}\")\n",
    "\n",
    "if \"seg\" not in radi.collection_names:\n",
    "    raise RuntimeError(\n",
    "        \"Segmentation collection not found. \"\n",
    "        \"Please re-run 05_ingest_msd.ipynb with FORCE_REINGEST=True\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CT and segmentation overlay for a few subjects\n",
    "subject_ids = list(radi.obs_subject_ids)[:3]\n",
    "\n",
    "fig, axes = plt.subplots(len(subject_ids), 3, figsize=(12, 4 * len(subject_ids)))\n",
    "\n",
    "for row, subject_id in enumerate(subject_ids):\n",
    "    ct_vol = radi.loc[subject_id].CT.iloc[0]\n",
    "    seg_vol = radi.loc[subject_id].seg.iloc[0]\n",
    "\n",
    "    # Find slice with tumor\n",
    "    seg_data = seg_vol.to_numpy()\n",
    "    tumor_slices = np.where(seg_data.sum(axis=(0, 1)) > 0)[0]\n",
    "    mid_z = (\n",
    "        tumor_slices[len(tumor_slices) // 2] if len(tumor_slices) > 0 else seg_data.shape[2] // 2\n",
    "    )\n",
    "\n",
    "    # CT\n",
    "    axes[row, 0].imshow(ct_vol.axial(z=mid_z).T, cmap=\"gray\", origin=\"lower\")\n",
    "    axes[row, 0].set_title(f\"{subject_id} - CT\")\n",
    "    axes[row, 0].axis(\"off\")\n",
    "\n",
    "    # Segmentation\n",
    "    axes[row, 1].imshow(seg_vol.axial(z=mid_z).T, cmap=\"hot\", origin=\"lower\")\n",
    "    axes[row, 1].set_title(f\"{subject_id} - Tumor Mask\")\n",
    "    axes[row, 1].axis(\"off\")\n",
    "\n",
    "    # Overlay\n",
    "    axes[row, 2].imshow(ct_vol.axial(z=mid_z).T, cmap=\"gray\", origin=\"lower\")\n",
    "    mask = seg_vol.axial(z=mid_z).T > 0\n",
    "    axes[row, 2].imshow(np.ma.masked_where(~mask, mask), cmap=\"Reds\", alpha=0.5, origin=\"lower\")\n",
    "    axes[row, 2].set_title(f\"{subject_id} - Overlay\")\n",
    "    axes[row, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-val-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 split\n",
    "all_ids = list(radi.obs_subject_ids)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_ids)\n",
    "\n",
    "split_idx = int(0.8 * len(all_ids))\n",
    "train_ids = all_ids[:split_idx]\n",
    "val_ids = all_ids[split_idx:]\n",
    "\n",
    "print(f\"Training subjects: {len(train_ids)}\")\n",
    "print(f\"Validation subjects: {len(val_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-splits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val RadiObjects using loc[] and to_radi_object()\n",
    "train_uri = f\"{TEMP_DIR}/train_radi\"\n",
    "val_uri = f\"{TEMP_DIR}/val_radi\"\n",
    "\n",
    "radi_train = radi.loc[train_ids].to_radi_object(train_uri)\n",
    "radi_val = radi.loc[val_ids].to_radi_object(val_uri)\n",
    "\n",
    "print(f\"Train RadiObject: {radi_train}\")\n",
    "print(f\"Val RadiObject: {radi_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-dataloaders",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "BATCH_SIZE = 2\n",
    "PATCH_SIZE = (64, 64, 64)\n",
    "\n",
    "# Define transforms - only random flip (applies to both CT and seg consistently)\n",
    "# Normalization is applied only to CT channel in training loop\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        RandFlipd(keys=\"image\", prob=0.5, spatial_axis=[0, 1, 2]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create dataloaders with multi-collection input\n",
    "# [CT, seg] -> stacked as channels: batch[\"image\"] shape (B, 2, D, H, W)\n",
    "# Channel 0 = CT (input), Channel 1 = seg (label)\n",
    "train_loader = create_training_dataloader(\n",
    "    [radi_train.CT, radi_train.seg],  # Multi-collection: first=image, second=label\n",
    "    batch_size=BATCH_SIZE,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False,\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "# Validation: no augmentation\n",
    "val_loader = create_validation_dataloader(\n",
    "    [radi_val.CT, radi_val.seg],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a batch\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "print(f\"Batch keys: {list(batch.keys())}\")\n",
    "print(f\"Image shape: {batch['image'].shape}\")  # (B, 2, D, H, W) - CT + seg stacked\n",
    "print(f\"Image dtype: {batch['image'].dtype}\")\n",
    "print(f\"Memory per batch: {batch['image'].nbytes / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Verify channel structure\n",
    "ct_channel = batch[\"image\"][:, 0:1, ...]  # CT\n",
    "seg_channel = batch[\"image\"][:, 1:2, ...]  # Segmentation mask\n",
    "print(f\"\\nCT channel range: [{ct_channel.min():.2f}, {ct_channel.max():.2f}]\")\n",
    "print(f\"Seg channel unique values: {torch.unique(seg_channel).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONAI UNet for 3D segmentation\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,  # background + tumor\n",
    "    channels=(16, 32, 64, 128),\n",
    "    strides=(2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_dice\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_dice\": [],\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_ct(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Normalize CT intensities to zero mean, unit variance.\"\"\"\n",
    "    return (x - x.mean()) / (x.std() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training on {DEVICE} for {NUM_EPOCHS} epochs...\\n\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    dice_metric.reset()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Split stacked channels: CT (input) and seg (label)\n",
    "        images = batch[\"image\"][:, 0:1, ...].to(DEVICE)  # CT channel\n",
    "        labels = batch[\"image\"][:, 1:2, ...].long().to(DEVICE)  # seg channel\n",
    "\n",
    "        # Normalize CT only (not seg mask)\n",
    "        images = normalize_ct(images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Compute Dice on predictions\n",
    "        preds = torch.argmax(outputs, dim=1, keepdim=True)\n",
    "        dice_metric(preds, labels)\n",
    "\n",
    "    train_dice = dice_metric.aggregate().item()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    dice_metric.reset()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch[\"image\"][:, 0:1, ...].to(DEVICE)\n",
    "            labels = batch[\"image\"][:, 1:2, ...].long().to(DEVICE)\n",
    "\n",
    "            images = normalize_ct(images)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1, keepdim=True)\n",
    "            dice_metric(preds, labels)\n",
    "\n",
    "    val_dice = dice_metric.aggregate().item()\n",
    "\n",
    "    # Record metrics\n",
    "    history[\"train_loss\"].append(train_loss / len(train_loader))\n",
    "    history[\"train_dice\"].append(train_dice)\n",
    "    history[\"val_loss\"].append(val_loss / len(val_loader))\n",
    "    history[\"val_dice\"].append(val_dice)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1:2d}/{NUM_EPOCHS}: \"\n",
    "        f\"Train Loss={history['train_loss'][-1]:.4f}, \"\n",
    "        f\"Train Dice={history['train_dice'][-1]:.4f}, \"\n",
    "        f\"Val Loss={history['val_loss'][-1]:.4f}, \"\n",
    "        f\"Val Dice={history['val_dice'][-1]:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history[\"train_loss\"], marker=\"o\", label=\"Train\")\n",
    "axes[0].plot(history[\"val_loss\"], marker=\"s\", label=\"Validation\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training & Validation Loss\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice Score\n",
    "axes[1].plot(history[\"train_dice\"], marker=\"o\", label=\"Train\")\n",
    "axes[1].plot(history[\"val_dice\"], marker=\"s\", label=\"Validation\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Dice Score\")\n",
    "axes[1].set_title(\"Training & Validation Dice\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final metrics\n",
    "print(\"=\" * 40)\n",
    "print(\"Final Results\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Best Train Dice: {max(history['train_dice']):.4f}\")\n",
    "print(f\"Best Val Dice: {max(history['val_dice']):.4f}\")\n",
    "print(f\"Final Train Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final Val Loss: {history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on validation data\n",
    "model.eval()\n",
    "batch = next(iter(val_loader))\n",
    "images = batch[\"image\"][:, 0:1, ...].to(DEVICE)\n",
    "labels = batch[\"image\"][:, 1:2, ...].cpu().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    images_norm = normalize_ct(images)\n",
    "    outputs = model(images_norm)\n",
    "    preds = torch.argmax(outputs, dim=1, keepdim=True).cpu().numpy()\n",
    "\n",
    "# Show first sample\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "mid_z = images.shape[4] // 2\n",
    "\n",
    "# CT\n",
    "axes[0].imshow(images[0, 0, :, :, mid_z].cpu().T, cmap=\"gray\", origin=\"lower\")\n",
    "axes[0].set_title(\"Input CT\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Ground Truth\n",
    "axes[1].imshow(labels[0, 0, :, :, mid_z].T, cmap=\"hot\", origin=\"lower\")\n",
    "axes[1].set_title(\"Ground Truth\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Prediction\n",
    "axes[2].imshow(preds[0, 0, :, :, mid_z].T, cmap=\"hot\", origin=\"lower\")\n",
    "axes[2].set_title(\"Prediction\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Validation Sample (z={mid_z})\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup temporary directory\n",
    "shutil.rmtree(TEMP_DIR)\n",
    "print(f\"Cleaned up: {TEMP_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
