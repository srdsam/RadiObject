{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# Framework Benchmark: RadiObject vs MONAI vs TorchIO\n\nPublication-quality benchmark comparing medical imaging data loading frameworks across multiple storage backends.\n\n## Storage Backends Matrix\n\n| Backend | RadiObject | MONAI | TorchIO | S3 Support |\n|---------|------------|-------|---------|------------|\n| TileDB (AXIAL) | ✅ | — | — | ✅ Native |\n| TileDB (ISOTROPIC) | ✅ | — | — | ✅ Native |\n| NIfTI compressed (.nii.gz) | — | ✅ | ✅ | ❌ Download first |\n| NIfTI uncompressed (.nii) | — | ✅ | ✅ | ❌ Download first |\n| NumPy (.npy) | — | ✅ | ✅ | ❌ Download first |\n\n**Key insight**: NumPy backend isolates framework overhead from file format parsing.\n\n## Metrics Measured\n\n| Category | Metrics |\n|----------|---------|\n| **Disk Space** | Bytes per format, compression ratio |\n| **Memory** | Heap (tracemalloc), RSS (psutil), peak vs sustained |\n| **I/O Time** | Full volume, partial read, random access |\n| **ML Training** | DataLoader throughput, GPU memory (if available) |\n\n## Benchmark Categories\n\n| Category | Focus | RadiObject Advantage |\n|----------|-------|---------------------|\n| **0. Dataset Prep** | Create all storage formats | Measure disk space |\n| **1. Storage Formats** | Format overhead comparison | — |\n| **2. Data Loading** | Core I/O performance | Partial reads, O(1) indexing |\n| **3. Analysis** | In-notebook exploration | Metadata queries |\n| **4. ML Training** | DataLoader throughput | Patch extraction |\n| **5. S3 Cloud** | Remote data access | Native S3 support (unique) |\n\n## Frameworks\n\n| Framework | Primary Use | Storage Model |\n|-----------|-------------|---------------|\n| **RadiObject** | TileDB-backed radiology atlas | Local + S3 native |\n| **MONAI** | Medical imaging DL | NIfTI/DICOM files |\n| **TorchIO** | Medical imaging augmentation | NIfTI files |"
  },
  {
   "cell_type": "markdown",
   "id": "env-header",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (papermill)\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SIZE = (64, 64, 64)\n",
    "NUM_WORKERS = 0\n",
    "N_WARMUP = 5  # Increased from 3 for better warm cache\n",
    "N_BATCHES = 20\n",
    "N_RUNS = 10  # Increased from 5 for statistical rigor\n",
    "S3_BUCKET = \"souzy-scratch\"\n",
    "RUN_S3_BENCHMARKS = True\n",
    "OUTPUT_DIR = \"../assets/benchmark\"\n",
    "N_SUBJECTS_FOR_TILED = 20  # Subjects for benchmark datasets\n",
    "RANDOM_SEED = 42  # Fixed seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env-specs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "import tracemalloc\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import psutil\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "# Fix random seeds for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MACHINE SPECIFICATIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Timestamp: {datetime.now().isoformat()}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "\n",
    "try:\n",
    "    chip = subprocess.check_output([\"sysctl\", \"-n\", \"machdep.cpu.brand_string\"], text=True).strip()\n",
    "    print(f\"CPU: {chip}\")\n",
    "except Exception:\n",
    "    print(f\"CPU: {platform.processor()}\")\n",
    "\n",
    "print(\n",
    "    f\"CPU Cores: {psutil.cpu_count(logical=False)} physical, \"\n",
    "    f\"{psutil.cpu_count(logical=True)} logical\"\n",
    ")\n",
    "print(f\"RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "\n",
    "# Check for GPU\n",
    "HAVE_CUDA = False\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        HAVE_CUDA = True\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  CUDA: {torch.version.cuda}\")\n",
    "        print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n",
    "    else:\n",
    "        print(\"GPU: Not available (CUDA not detected)\")\n",
    "except ImportError:\n",
    "    print(\"GPU: Not available (PyTorch not installed)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env-frameworks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Fix numpy seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "\n",
    "HAVE_MONAI = False\n",
    "HAVE_TORCHIO = False\n",
    "HAVE_SIMPLEITK = False\n",
    "\n",
    "try:\n",
    "    import monai\n",
    "    from monai.data import DataLoader as MonaiDataLoader\n",
    "    from monai.data import Dataset as MonaiDataset\n",
    "    from monai.transforms import (\n",
    "        Compose,\n",
    "        EnsureChannelFirstd,\n",
    "        LoadImaged,\n",
    "        RandSpatialCropd,\n",
    "    )\n",
    "\n",
    "    HAVE_MONAI = True\n",
    "    print(f\"MONAI: {monai.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"MONAI: Not installed\")\n",
    "\n",
    "try:\n",
    "    import torchio as tio\n",
    "\n",
    "    HAVE_TORCHIO = True\n",
    "    print(f\"TorchIO: {tio.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"TorchIO: Not installed\")\n",
    "\n",
    "try:\n",
    "    import SimpleITK as sitk\n",
    "\n",
    "    HAVE_SIMPLEITK = True\n",
    "    print(f\"SimpleITK: {sitk.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"SimpleITK: Not installed\")\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from radiobject import RadiObject, configure\n",
    "from radiobject.ctx import S3Config, SliceOrientation, TileConfig\n",
    "from radiobject.ml import create_training_dataloader\n",
    "\n",
    "print(\"\\nRadiObject: Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import S3_REGION\n",
    "\n",
    "# Paths relative to benchmarks/ directory\n",
    "DATA_DIR = Path(\"../data\")\n",
    "NIFTI_DIR = DATA_DIR / \"msd_lung\" / \"Task06_Lung\" / \"imagesTr\"\n",
    "ASSETS_DIR = Path(\"../assets/benchmark\")\n",
    "BENCHMARK_DIR = DATA_DIR / \"benchmark\"\n",
    "\n",
    "# URIs for different storage formats\n",
    "LOCAL_AXIAL_URI = str(BENCHMARK_DIR / \"radiobject-axial\")\n",
    "LOCAL_ISOTROPIC_URI = str(BENCHMARK_DIR / \"radiobject-isotropic\")\n",
    "NIFTI_COMPRESSED_DIR = BENCHMARK_DIR / \"nifti-compressed\"\n",
    "NIFTI_UNCOMPRESSED_DIR = BENCHMARK_DIR / \"nifti-uncompressed\"\n",
    "NUMPY_DIR = BENCHMARK_DIR / \"numpy\"\n",
    "\n",
    "S3_AXIAL_URI = f\"s3://{S3_BUCKET}/benchmark/radiobject-axial\"\n",
    "S3_ISOTROPIC_URI = f\"s3://{S3_BUCKET}/benchmark/radiobject-isotropic\"\n",
    "\n",
    "# Create directories\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ASSETS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BENCHMARK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Patch size: {PATCH_SIZE}\")\n",
    "print(f\"Warmup iterations: {N_WARMUP}\")\n",
    "print(f\"Benchmark batches: {N_BATCHES}\")\n",
    "print(f\"Runs per framework: {N_RUNS}\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "print(\"\\nLocal URIs:\")\n",
    "print(f\"  TileDB Axial: {LOCAL_AXIAL_URI}\")\n",
    "print(f\"  TileDB Isotropic: {LOCAL_ISOTROPIC_URI}\")\n",
    "print(f\"  NIfTI compressed: {NIFTI_COMPRESSED_DIR}\")\n",
    "print(f\"  NIfTI uncompressed: {NIFTI_UNCOMPRESSED_DIR}\")\n",
    "print(f\"  NumPy: {NUMPY_DIR}\")\n",
    "print(\"\\nS3 URIs:\")\n",
    "print(f\"  Axial: {S3_AXIAL_URI}\")\n",
    "print(f\"  Isotropic: {S3_ISOTROPIC_URI}\")\n",
    "print(f\"\\nSource NIfTI directory: {NIFTI_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utils-header",
   "metadata": {},
   "source": "## 2. Benchmark Infrastructure\n\nEnhanced with CPU, memory, GPU profiling, and disk space measurement."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cpu-sampler",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPUSampler:\n",
    "    \"\"\"Sample CPU utilization during an operation.\"\"\"\n",
    "\n",
    "    def __init__(self, interval_ms: int = 100):\n",
    "        self.interval = interval_ms / 1000\n",
    "        self.samples: list[float] = []\n",
    "        self._stop = False\n",
    "        self._thread: threading.Thread | None = None\n",
    "\n",
    "    def start(self) -> None:\n",
    "        self._stop = False\n",
    "        self.samples = []\n",
    "        self._thread = threading.Thread(target=self._sample, daemon=True)\n",
    "        self._thread.start()\n",
    "\n",
    "    def _sample(self) -> None:\n",
    "        while not self._stop:\n",
    "            self.samples.append(psutil.cpu_percent(interval=None))\n",
    "            time.sleep(self.interval)\n",
    "\n",
    "    def stop(self) -> tuple[float, float]:\n",
    "        self._stop = True\n",
    "        if self._thread:\n",
    "            self._thread.join(timeout=1.0)\n",
    "        if self.samples:\n",
    "            return float(np.mean(self.samples)), float(max(self.samples))\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    def __enter__(self) -> \"CPUSampler\":\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args) -> None:\n",
    "        self.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils-classes",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BenchmarkResult:\n",
    "    \"\"\"Single benchmark run result with comprehensive profiling.\"\"\"\n",
    "\n",
    "    framework: str\n",
    "    benchmark_name: str\n",
    "    scenario: str  # \"local\" or \"s3\"\n",
    "    tiling_strategy: str = \"\"  # \"axial\" or \"isotropic\"\n",
    "    storage_format: str = \"\"  # \"tiledb\", \"nifti_gz\", \"nifti\", \"numpy\"\n",
    "\n",
    "    # Timing\n",
    "    time_mean_ms: float = 0.0\n",
    "    time_std_ms: float = 0.0\n",
    "    cold_start_ms: float = 0.0\n",
    "    batch_times_ms: list[float] = field(default_factory=list)\n",
    "\n",
    "    # CPU metrics\n",
    "    cpu_percent_mean: float = 0.0\n",
    "    cpu_percent_peak: float = 0.0\n",
    "\n",
    "    # Memory metrics (CPU)\n",
    "    peak_heap_mb: float = 0.0  # tracemalloc\n",
    "    peak_rss_mb: float = 0.0  # psutil\n",
    "\n",
    "    # GPU metrics\n",
    "    peak_gpu_allocated_mb: float = 0.0  # torch.cuda.max_memory_allocated\n",
    "    peak_gpu_reserved_mb: float = 0.0  # torch.cuda.max_memory_reserved\n",
    "\n",
    "    # Disk metrics\n",
    "    disk_size_mb: float = 0.0\n",
    "\n",
    "    # Throughput\n",
    "    throughput_samples_per_sec: float = 0.0\n",
    "    throughput_mb_per_sec: float = 0.0\n",
    "\n",
    "    # Metadata\n",
    "    data_size_mb: float = 0.0\n",
    "    n_samples: int = 0\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            \"framework\": self.framework,\n",
    "            \"benchmark_name\": self.benchmark_name,\n",
    "            \"scenario\": self.scenario,\n",
    "            \"tiling_strategy\": self.tiling_strategy,\n",
    "            \"storage_format\": self.storage_format,\n",
    "            \"time_mean_ms\": round(self.time_mean_ms, 3),\n",
    "            \"time_std_ms\": round(self.time_std_ms, 3),\n",
    "            \"cold_start_ms\": round(self.cold_start_ms, 3),\n",
    "            \"cpu_percent_mean\": round(self.cpu_percent_mean, 1),\n",
    "            \"cpu_percent_peak\": round(self.cpu_percent_peak, 1),\n",
    "            \"peak_heap_mb\": round(self.peak_heap_mb, 2),\n",
    "            \"peak_rss_mb\": round(self.peak_rss_mb, 2),\n",
    "            \"peak_gpu_allocated_mb\": round(self.peak_gpu_allocated_mb, 2),\n",
    "            \"peak_gpu_reserved_mb\": round(self.peak_gpu_reserved_mb, 2),\n",
    "            \"disk_size_mb\": round(self.disk_size_mb, 2),\n",
    "            \"throughput_samples_per_sec\": round(self.throughput_samples_per_sec, 2),\n",
    "            \"n_samples\": self.n_samples,\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiskSpaceResult:\n",
    "    \"\"\"Disk space measurement for a storage format.\"\"\"\n",
    "\n",
    "    format_name: str\n",
    "    path: str\n",
    "    size_bytes: int\n",
    "    size_mb: float\n",
    "    n_files: int\n",
    "    compression_ratio: float = 0.0  # vs raw voxel data\n",
    "    raw_voxel_bytes: int = 0\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            \"format_name\": self.format_name,\n",
    "            \"path\": self.path,\n",
    "            \"size_bytes\": self.size_bytes,\n",
    "            \"size_mb\": round(self.size_mb, 2),\n",
    "            \"n_files\": self.n_files,\n",
    "            \"compression_ratio\": round(self.compression_ratio, 3),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j7rphghr3gg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory_size_bytes(path: Path) -> tuple[int, int]:\n",
    "    \"\"\"Recursively measure directory size. Returns (total_bytes, file_count).\"\"\"\n",
    "    total = 0\n",
    "    count = 0\n",
    "    if path.is_file():\n",
    "        return path.stat().st_size, 1\n",
    "    for entry in path.rglob(\"*\"):\n",
    "        if entry.is_file():\n",
    "            total += entry.stat().st_size\n",
    "            count += 1\n",
    "    return total, count\n",
    "\n",
    "\n",
    "def get_directory_size_mb(path: Path) -> float:\n",
    "    \"\"\"Recursively measure directory size in MB.\"\"\"\n",
    "    size_bytes, _ = get_directory_size_bytes(path)\n",
    "    return size_bytes / (1024 * 1024)\n",
    "\n",
    "\n",
    "def create_uncompressed_nifti(src: Path, dst: Path) -> None:\n",
    "    \"\"\"Convert .nii.gz to .nii (uncompressed).\"\"\"\n",
    "    img = nib.load(str(src))\n",
    "    nib.save(img, str(dst))\n",
    "\n",
    "\n",
    "def create_numpy_from_nifti(src: Path, dst: Path) -> None:\n",
    "    \"\"\"Convert NIfTI to .npy.\"\"\"\n",
    "    img = nib.load(str(src))\n",
    "    data = img.get_fdata()\n",
    "    np.save(str(dst), data)\n",
    "\n",
    "\n",
    "def compute_raw_voxel_bytes(nifti_path: Path) -> int:\n",
    "    \"\"\"Compute raw voxel data size (uncompressed, no header).\"\"\"\n",
    "    img = nib.load(str(nifti_path))\n",
    "    shape = img.shape\n",
    "    dtype = img.get_data_dtype()\n",
    "    n_voxels = np.prod(shape)\n",
    "    bytes_per_voxel = np.dtype(dtype).itemsize\n",
    "    return int(n_voxels * bytes_per_voxel)\n",
    "\n",
    "\n",
    "def compute_checksum(data: np.ndarray) -> str:\n",
    "    \"\"\"Compute MD5 checksum of array data for validation.\"\"\"\n",
    "    return hashlib.md5(data.tobytes()).hexdigest()\n",
    "\n",
    "\n",
    "def measure_disk_space(\n",
    "    path: Path,\n",
    "    format_name: str,\n",
    "    raw_voxel_bytes: int = 0,\n",
    ") -> DiskSpaceResult:\n",
    "    \"\"\"Measure disk space for a storage format.\"\"\"\n",
    "    if not path.exists():\n",
    "        return DiskSpaceResult(format_name, str(path), 0, 0.0, 0)\n",
    "\n",
    "    size_bytes, n_files = get_directory_size_bytes(path)\n",
    "    size_mb = size_bytes / (1024 * 1024)\n",
    "    compression_ratio = raw_voxel_bytes / size_bytes if size_bytes > 0 else 0.0\n",
    "\n",
    "    return DiskSpaceResult(\n",
    "        format_name=format_name,\n",
    "        path=str(path),\n",
    "        size_bytes=size_bytes,\n",
    "        size_mb=size_mb,\n",
    "        n_files=n_files,\n",
    "        compression_ratio=compression_ratio,\n",
    "        raw_voxel_bytes=raw_voxel_bytes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_operation(\n",
    "    func: Callable,\n",
    "    framework: str,\n",
    "    benchmark_name: str,\n",
    "    scenario: str = \"local\",\n",
    "    tiling: str = \"\",\n",
    "    storage_format: str = \"\",\n",
    "    n_warmup: int = N_WARMUP,\n",
    "    n_runs: int = N_RUNS,\n",
    "    track_gpu: bool = False,\n",
    ") -> BenchmarkResult:\n",
    "    \"\"\"Benchmark an operation with CPU, memory, and GPU profiling.\"\"\"\n",
    "    process = psutil.Process()\n",
    "    gc.collect()\n",
    "\n",
    "    # Reset GPU memory stats if tracking\n",
    "    if track_gpu and HAVE_CUDA:\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Cold start with memory tracking\n",
    "    tracemalloc.start()\n",
    "    rss_before = process.memory_info().rss\n",
    "    cpu_sampler = CPUSampler()\n",
    "    cpu_sampler.start()\n",
    "\n",
    "    cold_start = time.perf_counter()\n",
    "    func()\n",
    "    cold_time = (time.perf_counter() - cold_start) * 1000\n",
    "\n",
    "    cpu_mean, cpu_peak = cpu_sampler.stop()\n",
    "    _, peak_heap = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    rss_after = process.memory_info().rss\n",
    "\n",
    "    # Capture GPU metrics after cold start\n",
    "    gpu_allocated = 0.0\n",
    "    gpu_reserved = 0.0\n",
    "    if track_gpu and HAVE_CUDA:\n",
    "        gpu_allocated = torch.cuda.max_memory_allocated() / (1024 * 1024)\n",
    "        gpu_reserved = torch.cuda.max_memory_reserved() / (1024 * 1024)\n",
    "\n",
    "    # Warmup (remaining iterations)\n",
    "    for _ in range(n_warmup - 1):\n",
    "        func()\n",
    "\n",
    "    # Timed runs with GC between each\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        gc.collect()\n",
    "        start = time.perf_counter()\n",
    "        func()\n",
    "        times.append((time.perf_counter() - start) * 1000)\n",
    "\n",
    "    return BenchmarkResult(\n",
    "        framework=framework,\n",
    "        benchmark_name=benchmark_name,\n",
    "        scenario=scenario,\n",
    "        tiling_strategy=tiling,\n",
    "        storage_format=storage_format,\n",
    "        time_mean_ms=float(np.mean(times)),\n",
    "        time_std_ms=float(np.std(times)),\n",
    "        cold_start_ms=cold_time,\n",
    "        batch_times_ms=times,\n",
    "        cpu_percent_mean=cpu_mean,\n",
    "        cpu_percent_peak=cpu_peak,\n",
    "        peak_heap_mb=peak_heap / (1024 * 1024),\n",
    "        peak_rss_mb=(rss_after - rss_before) / (1024 * 1024),\n",
    "        peak_gpu_allocated_mb=gpu_allocated,\n",
    "        peak_gpu_reserved_mb=gpu_reserved,\n",
    "        n_samples=n_runs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils-dataloader",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_dataloader(\n",
    "    loader: DataLoader,\n",
    "    framework: str,\n",
    "    benchmark_name: str,\n",
    "    scenario: str,\n",
    "    tiling: str = \"\",\n",
    "    image_key: str = \"image\",\n",
    "    n_warmup: int = N_WARMUP,\n",
    "    n_batches: int = N_BATCHES,\n",
    ") -> BenchmarkResult:\n",
    "    \"\"\"Benchmark a PyTorch DataLoader with CPU/memory profiling.\"\"\"\n",
    "    process = psutil.Process()\n",
    "    gc.collect()\n",
    "    tracemalloc.start()\n",
    "    rss_before = process.memory_info().rss\n",
    "    cpu_sampler = CPUSampler()\n",
    "    cpu_sampler.start()\n",
    "\n",
    "    # Cold start\n",
    "    loader_iter = iter(loader)\n",
    "    cold_start = time.perf_counter()\n",
    "    first_batch = next(loader_iter)\n",
    "    if isinstance(first_batch, dict):\n",
    "        _ = first_batch[image_key].shape\n",
    "    else:\n",
    "        _ = first_batch.shape\n",
    "    cold_start_time = (time.perf_counter() - cold_start) * 1000\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(n_warmup - 1):\n",
    "        try:\n",
    "            batch = next(loader_iter)\n",
    "        except StopIteration:\n",
    "            loader_iter = iter(loader)\n",
    "            batch = next(loader_iter)\n",
    "\n",
    "    # Benchmark batches\n",
    "    batch_times = []\n",
    "    for _ in range(n_batches):\n",
    "        try:\n",
    "            start = time.perf_counter()\n",
    "            batch = next(loader_iter)\n",
    "            if isinstance(batch, dict):\n",
    "                _ = batch[image_key].shape\n",
    "            else:\n",
    "                _ = batch.shape\n",
    "            batch_times.append((time.perf_counter() - start) * 1000)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "    cpu_mean, cpu_peak = cpu_sampler.stop()\n",
    "    _, peak_heap = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    rss_after = process.memory_info().rss\n",
    "\n",
    "    mean_batch = float(np.mean(batch_times)) if batch_times else 0.0\n",
    "    throughput = (BATCH_SIZE / (mean_batch / 1000)) if mean_batch > 0 else 0.0\n",
    "\n",
    "    return BenchmarkResult(\n",
    "        framework=framework,\n",
    "        benchmark_name=benchmark_name,\n",
    "        scenario=scenario,\n",
    "        tiling_strategy=tiling,\n",
    "        time_mean_ms=mean_batch,\n",
    "        time_std_ms=float(np.std(batch_times)) if batch_times else 0.0,\n",
    "        cold_start_ms=cold_start_time,\n",
    "        batch_times_ms=batch_times,\n",
    "        cpu_percent_mean=cpu_mean,\n",
    "        cpu_percent_peak=cpu_peak,\n",
    "        peak_heap_mb=peak_heap / (1024 * 1024),\n",
    "        peak_rss_mb=(rss_after - rss_before) / (1024 * 1024),\n",
    "        throughput_samples_per_sec=throughput,\n",
    "        n_samples=len(batch_times) * BATCH_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": "## 3. Dataset Preparation\n\nCreate all storage formats from the same source data for fair comparison.\n\n| Format | Directory | Description |\n|--------|-----------|-------------|\n| `radiobject-axial` | TileDB Group | AXIAL tiling (X, Y, 1) for 2D slices |\n| `radiobject-isotropic` | TileDB Group | ISOTROPIC tiling (64³) for 3D ROI |\n| `nifti-compressed` | .nii.gz files | Gzip compressed NIfTI |\n| `nifti-uncompressed` | .nii files | Uncompressed NIfTI |\n| `numpy` | .npy files | Raw NumPy arrays |\n\n**Key insight**: NumPy backend isolates framework overhead from file format parsing."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-find-nifti",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find source NIfTI files\n",
    "nifti_paths = []\n",
    "\n",
    "if NIFTI_DIR.exists():\n",
    "    nifti_paths = sorted(NIFTI_DIR.glob(\"*.nii.gz\"))[:N_SUBJECTS_FOR_TILED]\n",
    "    if nifti_paths:\n",
    "        print(f\"Found {len(list(NIFTI_DIR.glob('*.nii.gz')))} NIfTI files in {NIFTI_DIR}\")\n",
    "        sample = nib.load(str(nifti_paths[0]))\n",
    "        print(f\"  Sample: {nifti_paths[0].name}\")\n",
    "        print(f\"  Shape: {sample.shape}\")\n",
    "        print(f\"  Dtype: {sample.get_data_dtype()}\")\n",
    "        print(f\"  Using first {N_SUBJECTS_FOR_TILED} for benchmark datasets\")\n",
    "\n",
    "        # Compute raw voxel size for compression ratio calculation\n",
    "        raw_bytes = compute_raw_voxel_bytes(nifti_paths[0])\n",
    "        print(f\"  Raw voxel size per volume: {raw_bytes / (1024*1024):.1f} MB\")\n",
    "else:\n",
    "    print(f\"NIfTI directory not found: {NIFTI_DIR}\")\n",
    "    print(\"Please download MSD-Lung dataset first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p6njk8gvltm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_storage_formats(\n",
    "    source_niftis: list[Path],\n",
    "    benchmark_dir: Path,\n",
    ") -> dict[str, Path]:\n",
    "    \"\"\"Create all storage formats from source NIfTI files.\"\"\"\n",
    "    formats_created = {}\n",
    "\n",
    "    if not source_niftis:\n",
    "        print(\"No source NIfTI files available\")\n",
    "        return formats_created\n",
    "\n",
    "    # 1. Create NIfTI compressed directory (symlinks to source)\n",
    "    nifti_gz_dir = benchmark_dir / \"nifti-compressed\"\n",
    "    if not nifti_gz_dir.exists():\n",
    "        nifti_gz_dir.mkdir(parents=True)\n",
    "        print(f\"Creating NIfTI compressed links: {nifti_gz_dir}\")\n",
    "        for src in source_niftis:\n",
    "            dst = nifti_gz_dir / src.name\n",
    "            if not dst.exists():\n",
    "                # Copy instead of symlink for accurate size measurement\n",
    "                shutil.copy2(src, dst)\n",
    "    else:\n",
    "        print(f\"NIfTI compressed exists: {nifti_gz_dir}\")\n",
    "    formats_created[\"nifti_gz\"] = nifti_gz_dir\n",
    "\n",
    "    # 2. Create uncompressed NIfTI\n",
    "    nifti_dir = benchmark_dir / \"nifti-uncompressed\"\n",
    "    if not nifti_dir.exists():\n",
    "        nifti_dir.mkdir(parents=True)\n",
    "        print(f\"Creating NIfTI uncompressed: {nifti_dir}\")\n",
    "        for src in source_niftis:\n",
    "            dst = nifti_dir / src.name.replace(\".nii.gz\", \".nii\")\n",
    "            if not dst.exists():\n",
    "                create_uncompressed_nifti(src, dst)\n",
    "                print(f\"  Created: {dst.name}\")\n",
    "    else:\n",
    "        print(f\"NIfTI uncompressed exists: {nifti_dir}\")\n",
    "    formats_created[\"nifti\"] = nifti_dir\n",
    "\n",
    "    # 3. Create NumPy files\n",
    "    numpy_dir = benchmark_dir / \"numpy\"\n",
    "    if not numpy_dir.exists():\n",
    "        numpy_dir.mkdir(parents=True)\n",
    "        print(f\"Creating NumPy: {numpy_dir}\")\n",
    "        for src in source_niftis:\n",
    "            dst = numpy_dir / src.name.replace(\".nii.gz\", \".npy\")\n",
    "            if not dst.exists():\n",
    "                create_numpy_from_nifti(src, dst)\n",
    "                print(f\"  Created: {dst.name}\")\n",
    "    else:\n",
    "        print(f\"NumPy exists: {numpy_dir}\")\n",
    "    formats_created[\"numpy\"] = numpy_dir\n",
    "\n",
    "    return formats_created\n",
    "\n",
    "\n",
    "# Create all storage formats\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPARING STORAGE FORMATS\")\n",
    "print(\"=\" * 60)\n",
    "storage_formats = prepare_all_storage_formats(nifti_paths, BENCHMARK_DIR)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-create-axial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiled_radiobject(\n",
    "    uri: str,\n",
    "    nifti_paths: list[Path],\n",
    "    orientation: SliceOrientation,\n",
    "    collection_name: str = \"CT\",\n",
    ") -> RadiObject | None:\n",
    "    \"\"\"Create RadiObject with specific tiling strategy.\"\"\"\n",
    "    if not nifti_paths:\n",
    "        print(\"No NIfTI files available\")\n",
    "        return None\n",
    "\n",
    "    # Check if already exists\n",
    "    if not uri.startswith(\"s3://\") and Path(uri).exists():\n",
    "        print(f\"Loading existing: {uri}\")\n",
    "        return RadiObject(uri)\n",
    "\n",
    "    print(f\"Creating RadiObject with {orientation.value} tiling: {uri}\")\n",
    "\n",
    "    # Configure tiling\n",
    "    configure(tile=TileConfig(orientation=orientation))\n",
    "\n",
    "    # Create using from_niftis\n",
    "    radi = RadiObject.from_niftis(\n",
    "        uri=uri,\n",
    "        image_dir=str(NIFTI_DIR),\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "\n",
    "    print(f\"  Created: {len(radi)} subjects\")\n",
    "    return radi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-create-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local axial-tiled dataset\n",
    "radi_local_axial = None\n",
    "if nifti_paths:\n",
    "    radi_local_axial = create_tiled_radiobject(\n",
    "        LOCAL_AXIAL_URI,\n",
    "        nifti_paths,\n",
    "        SliceOrientation.AXIAL,\n",
    "    )\n",
    "\n",
    "if radi_local_axial:\n",
    "    print(\"\\nLocal AXIAL dataset ready:\")\n",
    "    print(f\"  Subjects: {len(radi_local_axial)}\")\n",
    "    print(f\"  Collections: {radi_local_axial.collection_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-create-isotropic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local isotropic-tiled dataset\n",
    "radi_local_isotropic = None\n",
    "if nifti_paths:\n",
    "    radi_local_isotropic = create_tiled_radiobject(\n",
    "        LOCAL_ISOTROPIC_URI,\n",
    "        nifti_paths,\n",
    "        SliceOrientation.ISOTROPIC,\n",
    "    )\n",
    "\n",
    "if radi_local_isotropic:\n",
    "    print(\"\\nLocal ISOTROPIC dataset ready:\")\n",
    "    print(f\"  Subjects: {len(radi_local_isotropic)}\")\n",
    "    print(f\"  Collections: {radi_local_isotropic.collection_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-s3-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure S3 and load/create S3 datasets\n",
    "from config import AWS_PROFILE\n",
    "\n",
    "radi_s3_axial = None\n",
    "radi_s3_isotropic = None\n",
    "\n",
    "if RUN_S3_BENCHMARKS:\n",
    "    # Set AWS profile for boto3 credential lookup\n",
    "    if AWS_PROFILE:\n",
    "        os.environ[\"AWS_PROFILE\"] = AWS_PROFILE\n",
    "        print(f\"Using AWS profile: {AWS_PROFILE}\")\n",
    "\n",
    "    configure(s3=S3Config(region=S3_REGION, max_parallel_ops=8))\n",
    "    print(f\"Configured S3 for region: {S3_REGION}\")\n",
    "\n",
    "    # Try to load existing S3 datasets\n",
    "    try:\n",
    "        radi_s3_axial = RadiObject(S3_AXIAL_URI)\n",
    "        _ = len(radi_s3_axial)  # Force metadata load to verify dataset exists\n",
    "        print(f\"Loaded S3 AXIAL: {S3_AXIAL_URI}\")\n",
    "        print(f\"  Subjects: {len(radi_s3_axial)}\")\n",
    "    except Exception as e:\n",
    "        radi_s3_axial = None  # Ensure None if load failed\n",
    "        print(f\"S3 AXIAL not available: {type(e).__name__}\")\n",
    "        print(\"  To create: use RadiObject.from_niftis with S3 URI\")\n",
    "\n",
    "    try:\n",
    "        radi_s3_isotropic = RadiObject(S3_ISOTROPIC_URI)\n",
    "        _ = len(radi_s3_isotropic)  # Force metadata load to verify dataset exists\n",
    "        print(f\"Loaded S3 ISOTROPIC: {S3_ISOTROPIC_URI}\")\n",
    "        print(f\"  Subjects: {len(radi_s3_isotropic)}\")\n",
    "    except Exception as e:\n",
    "        radi_s3_isotropic = None  # Ensure None if load failed\n",
    "        print(f\"S3 ISOTROPIC not available: {type(e).__name__}\")\n",
    "else:\n",
    "    print(\"S3 benchmarks disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-verify-tiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiledb\n",
    "\n",
    "\n",
    "def verify_tiling(uri: str, name: str) -> None:\n",
    "    \"\"\"Verify tile extents in a RadiObject volume.\"\"\"\n",
    "    try:\n",
    "        radi = RadiObject(uri)\n",
    "        vol = radi.collection(radi.collection_names[0]).iloc[0]\n",
    "        schema = tiledb.ArraySchema.load(vol.uri)\n",
    "\n",
    "        print(f\"\\n{name} ({uri.split('/')[-1]}):\")\n",
    "        print(f\"  Volume shape: {vol.shape}\")\n",
    "        for i, dim in enumerate(schema.domain):\n",
    "            print(f\"  Dim {dim.name}: tile extent = {dim.tile}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: Not available ({type(e).__name__})\")\n",
    "\n",
    "\n",
    "verify_tiling(LOCAL_AXIAL_URI, \"Local AXIAL\")\n",
    "verify_tiling(LOCAL_ISOTROPIC_URI, \"Local ISOTROPIC\")\n",
    "if RUN_S3_BENCHMARKS:\n",
    "    verify_tiling(S3_AXIAL_URI, \"S3 AXIAL\")\n",
    "    verify_tiling(S3_ISOTROPIC_URI, \"S3 ISOTROPIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ig15ch72qre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure disk space for all storage formats\n",
    "print(\"=\" * 60)\n",
    "print(\"DISK SPACE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "disk_space_results: list[DiskSpaceResult] = []\n",
    "\n",
    "# Compute total raw voxel bytes\n",
    "total_raw_bytes = 0\n",
    "if nifti_paths:\n",
    "    for p in nifti_paths:\n",
    "        total_raw_bytes += compute_raw_voxel_bytes(p)\n",
    "    print(f\"Total raw voxel data: {total_raw_bytes / (1024**3):.2f} GB\")\n",
    "    print()\n",
    "\n",
    "# Measure each format\n",
    "format_paths = [\n",
    "    (\"TileDB (AXIAL)\", Path(LOCAL_AXIAL_URI)),\n",
    "    (\"TileDB (ISOTROPIC)\", Path(LOCAL_ISOTROPIC_URI)),\n",
    "    (\"NIfTI (.nii.gz)\", NIFTI_COMPRESSED_DIR),\n",
    "    (\"NIfTI (.nii)\", NIFTI_UNCOMPRESSED_DIR),\n",
    "    (\"NumPy (.npy)\", NUMPY_DIR),\n",
    "]\n",
    "\n",
    "for name, path in format_paths:\n",
    "    result = measure_disk_space(path, name, total_raw_bytes)\n",
    "    if result.size_bytes > 0:\n",
    "        disk_space_results.append(result)\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Size: {result.size_mb:.1f} MB ({result.n_files} files)\")\n",
    "        print(f\"  Compression ratio: {result.compression_ratio:.2f}x\")\n",
    "\n",
    "# Summary table\n",
    "if disk_space_results:\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    df = pd.DataFrame([r.to_dict() for r in disk_space_results])\n",
    "    display(df[[\"format_name\", \"size_mb\", \"n_files\", \"compression_ratio\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cat1-header",
   "metadata": {},
   "source": "## 4. Category 1: Storage Format Comparison\n\n**Purpose**: Isolate file format overhead from framework overhead.\n\n| Test | What It Measures |\n|------|------------------|\n| NIfTI compressed vs uncompressed | Gzip decompression cost |\n| NIfTI vs NumPy (same framework) | NIfTI parsing overhead |\n| TileDB AXIAL vs ISOTROPIC | Tiling strategy impact |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat1-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for all results\n",
    "all_results: list[BenchmarkResult] = []\n",
    "\n",
    "# Get file paths for different formats\n",
    "nifti_gz_paths = (\n",
    "    sorted(NIFTI_COMPRESSED_DIR.glob(\"*.nii.gz\")) if NIFTI_COMPRESSED_DIR.exists() else []\n",
    ")\n",
    "nifti_paths_uncompressed = (\n",
    "    sorted(NIFTI_UNCOMPRESSED_DIR.glob(\"*.nii\")) if NIFTI_UNCOMPRESSED_DIR.exists() else []\n",
    ")\n",
    "numpy_paths = sorted(NUMPY_DIR.glob(\"*.npy\")) if NUMPY_DIR.exists() else []\n",
    "\n",
    "print(\"Available benchmark files:\")\n",
    "print(f\"  NIfTI compressed: {len(nifti_gz_paths)}\")\n",
    "print(f\"  NIfTI uncompressed: {len(nifti_paths_uncompressed)}\")\n",
    "print(f\"  NumPy: {len(numpy_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g83bkn9mgel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_storage_formats():\n",
    "    \"\"\"Benchmark 1.1: Storage Format Loading Comparison.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 1.1: Storage Format Loading\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Compare load times across file formats using the same framework\")\n",
    "    print(\"Insight: Isolates format parsing cost from framework overhead\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # --- NIfTI Compressed vs Uncompressed ---\n",
    "    print(\"--- NIfTI: Gzip Decompression Cost ---\")\n",
    "\n",
    "    if nifti_gz_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: nib.load(str(nifti_gz_paths[0])).get_fdata(),\n",
    "            \"nibabel\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            storage_format=\"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"NIfTI compressed (.nii.gz): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\"\n",
    "        )\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    if nifti_paths_uncompressed:\n",
    "        result = benchmark_operation(\n",
    "            lambda: nib.load(str(nifti_paths_uncompressed[0])).get_fdata(),\n",
    "            \"nibabel\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            storage_format=\"nifti\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"NIfTI uncompressed (.nii): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\"\n",
    "        )\n",
    "\n",
    "    # Calculate gzip overhead\n",
    "    nifti_gz_result = next((r for r in results if r.storage_format == \"nifti_gz\"), None)\n",
    "    nifti_result = next((r for r in results if r.storage_format == \"nifti\"), None)\n",
    "    if nifti_gz_result and nifti_result and nifti_result.time_mean_ms > 0:\n",
    "        gzip_overhead = (nifti_gz_result.time_mean_ms / nifti_result.time_mean_ms - 1) * 100\n",
    "        print(f\"  Gzip overhead: {gzip_overhead:.1f}%\")\n",
    "\n",
    "    # --- NIfTI vs NumPy ---\n",
    "    print(\"\\n--- NIfTI vs NumPy: Format Parsing Cost ---\")\n",
    "\n",
    "    if numpy_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: np.load(str(numpy_paths[0])),\n",
    "            \"numpy\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            storage_format=\"numpy\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"NumPy (.npy): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    numpy_result = next((r for r in results if r.storage_format == \"numpy\"), None)\n",
    "    if nifti_result and numpy_result and numpy_result.time_mean_ms > 0:\n",
    "        parsing_overhead = (nifti_result.time_mean_ms / numpy_result.time_mean_ms - 1) * 100\n",
    "        print(f\"  NIfTI parsing overhead vs NumPy: {parsing_overhead:.1f}%\")\n",
    "\n",
    "    # --- TileDB Tiling Comparison ---\n",
    "    print(\"\\n--- TileDB: Tiling Strategy ---\")\n",
    "\n",
    "    if radi_local_axial:\n",
    "        vol = radi_local_axial.collection(radi_local_axial.collection_names[0]).iloc[0]\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol.to_numpy(),\n",
    "            \"RadiObject\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            tiling=\"axial\",\n",
    "            storage_format=\"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"TileDB AXIAL: {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "\n",
    "    if radi_local_isotropic:\n",
    "        vol = radi_local_isotropic.collection(radi_local_isotropic.collection_names[0]).iloc[0]\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol.to_numpy(),\n",
    "            \"RadiObject\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            tiling=\"isotropic\",\n",
    "            storage_format=\"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"TileDB ISOTROPIC: {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "\n",
    "    print(\"\\n--- Key Insights ---\")\n",
    "    print(\"1. Gzip adds decompression overhead but saves disk space\")\n",
    "    print(\"2. NIfTI header parsing adds modest overhead vs raw NumPy\")\n",
    "    print(\"3. TileDB tiling strategy has minimal impact on full-volume loads\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_storage_formats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat1-full-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_full_volume_load():\n",
    "    \"\"\"Benchmark 2.1: Full Volume Loading (Local and S3).\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 2.1: Full Volume Load\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Load complete 3D volume into memory\")\n",
    "    print(\"Expectation: MONAI/TorchIO optimized for NIfTI; RadiObject competitive\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # RadiObject Local (axial-tiled)\n",
    "    if radi_local_axial:\n",
    "        vol = radi_local_axial.collection(radi_local_axial.collection_names[0]).iloc[0]\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol.to_numpy(), \"RadiObject\", \"full_volume\", \"local\", \"axial\", \"tiledb\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject (local/axial): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\"\n",
    "        )\n",
    "        print(f\"  CPU: {result.cpu_percent_mean:.1f}% mean, {result.cpu_percent_peak:.1f}% peak\")\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    # RadiObject S3 (if available)\n",
    "    if radi_s3_axial:\n",
    "        vol = radi_s3_axial.collection(radi_s3_axial.collection_names[0]).iloc[0]\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol.to_numpy(), \"RadiObject\", \"full_volume\", \"s3\", \"axial\", \"tiledb\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"RadiObject (S3/axial): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "\n",
    "    # MONAI (local only - can't read S3 natively)\n",
    "    if HAVE_MONAI and nifti_gz_paths:\n",
    "        from monai.transforms import LoadImage\n",
    "\n",
    "        loader = LoadImage(image_only=True)\n",
    "        result = benchmark_operation(\n",
    "            lambda: loader(str(nifti_gz_paths[0])), \"MONAI\", \"full_volume\", \"local\", \"\", \"nifti_gz\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"MONAI (local): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "        print(f\"  CPU: {result.cpu_percent_mean:.1f}% mean\")\n",
    "\n",
    "    # TorchIO (local only)\n",
    "    if HAVE_TORCHIO and nifti_gz_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: tio.ScalarImage(str(nifti_gz_paths[0])).data,\n",
    "            \"TorchIO\",\n",
    "            \"full_volume\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"TorchIO (local): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_full_volume_load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat1-partial-reads",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_partial_reads():\n",
    "    \"\"\"Benchmark 2.2: Partial Reads with CORRECTLY TILED datasets.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 2.2: Partial Reads (Tiling Comparison)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Extract 2D slice or 3D ROI - compare tiling strategies\")\n",
    "    print(\"Key insight: Tiling strategy MUST match access pattern!\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Get volumes for testing\n",
    "    vol_axial_local = None\n",
    "    vol_isotropic_local = None\n",
    "    vol_axial_s3 = None\n",
    "    vol_isotropic_s3 = None\n",
    "\n",
    "    if radi_local_axial:\n",
    "        vol_axial_local = radi_local_axial.collection(radi_local_axial.collection_names[0]).iloc[0]\n",
    "    if radi_local_isotropic:\n",
    "        vol_isotropic_local = radi_local_isotropic.collection(\n",
    "            radi_local_isotropic.collection_names[0]\n",
    "        ).iloc[0]\n",
    "    if radi_s3_axial:\n",
    "        vol_axial_s3 = radi_s3_axial.collection(radi_s3_axial.collection_names[0]).iloc[0]\n",
    "    if radi_s3_isotropic:\n",
    "        vol_isotropic_s3 = radi_s3_isotropic.collection(radi_s3_isotropic.collection_names[0]).iloc[\n",
    "            0\n",
    "        ]\n",
    "\n",
    "    # --- 2D SLICE BENCHMARKS ---\n",
    "    print(\"\\n--- 2D Axial Slice Extraction ---\")\n",
    "\n",
    "    # 2D Slice on AXIAL-tiled (OPTIMAL)\n",
    "    if vol_axial_local:\n",
    "        mid_z = vol_axial_local.shape[2] // 2\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_axial_local.axial(mid_z),\n",
    "            \"RadiObject\",\n",
    "            \"slice_2d\",\n",
    "            \"local\",\n",
    "            \"axial\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"AXIAL-tiled (local): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms [OPTIMAL]\"\n",
    "        )\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    # 2D Slice on ISOTROPIC-tiled (SUBOPTIMAL)\n",
    "    if vol_isotropic_local:\n",
    "        mid_z = vol_isotropic_local.shape[2] // 2\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_isotropic_local.axial(mid_z),\n",
    "            \"RadiObject\",\n",
    "            \"slice_2d\",\n",
    "            \"local\",\n",
    "            \"isotropic\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"ISOTROPIC-tiled (local): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms [suboptimal]\"\n",
    "        )\n",
    "\n",
    "    # S3 variants\n",
    "    if vol_axial_s3:\n",
    "        mid_z = vol_axial_s3.shape[2] // 2\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_axial_s3.axial(mid_z), \"RadiObject\", \"slice_2d\", \"s3\", \"axial\", \"tiledb\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"AXIAL-tiled (S3): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    if vol_isotropic_s3:\n",
    "        mid_z = vol_isotropic_s3.shape[2] // 2\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_isotropic_s3.axial(mid_z),\n",
    "            \"RadiObject\",\n",
    "            \"slice_2d\",\n",
    "            \"s3\",\n",
    "            \"isotropic\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"ISOTROPIC-tiled (S3): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    # MONAI/TorchIO (must load full volume then slice)\n",
    "    if HAVE_MONAI and nifti_gz_paths:\n",
    "        from monai.transforms import LoadImage\n",
    "\n",
    "        loader = LoadImage(image_only=True)\n",
    "        result = benchmark_operation(\n",
    "            lambda: loader(str(nifti_gz_paths[0]))[\n",
    "                :, :, loader(str(nifti_gz_paths[0])).shape[2] // 2\n",
    "            ],\n",
    "            \"MONAI\",\n",
    "            \"slice_2d\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"MONAI (full load + slice): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\"\n",
    "        )\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    if HAVE_TORCHIO and nifti_gz_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: tio.ScalarImage(str(nifti_gz_paths[0])).data[\n",
    "                :, :, :, tio.ScalarImage(str(nifti_gz_paths[0])).shape[3] // 2\n",
    "            ],\n",
    "            \"TorchIO\",\n",
    "            \"slice_2d\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"TorchIO (full load + slice): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\"\n",
    "        )\n",
    "\n",
    "    # --- 3D ROI BENCHMARKS ---\n",
    "    print(\"\\n--- 3D ROI Extraction (64x64x64) ---\")\n",
    "    roi_size = 64\n",
    "\n",
    "    # 3D ROI on ISOTROPIC-tiled (OPTIMAL)\n",
    "    if vol_isotropic_local:\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_isotropic_local.slice(\n",
    "                x=slice(0, roi_size), y=slice(0, roi_size), z=slice(0, roi_size)\n",
    "            ),\n",
    "            \"RadiObject\",\n",
    "            \"roi_3d\",\n",
    "            \"local\",\n",
    "            \"isotropic\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"ISOTROPIC-tiled (local): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms [OPTIMAL]\"\n",
    "        )\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    # 3D ROI on AXIAL-tiled (SUBOPTIMAL)\n",
    "    if vol_axial_local:\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_axial_local.slice(\n",
    "                x=slice(0, roi_size), y=slice(0, roi_size), z=slice(0, roi_size)\n",
    "            ),\n",
    "            \"RadiObject\",\n",
    "            \"roi_3d\",\n",
    "            \"local\",\n",
    "            \"axial\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"AXIAL-tiled (local): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms [suboptimal]\"\n",
    "        )\n",
    "\n",
    "    # S3 variants\n",
    "    if vol_isotropic_s3:\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_isotropic_s3.slice(\n",
    "                x=slice(0, roi_size), y=slice(0, roi_size), z=slice(0, roi_size)\n",
    "            ),\n",
    "            \"RadiObject\",\n",
    "            \"roi_3d\",\n",
    "            \"s3\",\n",
    "            \"isotropic\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"ISOTROPIC-tiled (S3): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    if vol_axial_s3:\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_axial_s3.slice(\n",
    "                x=slice(0, roi_size), y=slice(0, roi_size), z=slice(0, roi_size)\n",
    "            ),\n",
    "            \"RadiObject\",\n",
    "            \"roi_3d\",\n",
    "            \"s3\",\n",
    "            \"axial\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"AXIAL-tiled (S3): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    # MONAI/TorchIO comparison\n",
    "    if HAVE_MONAI and nifti_gz_paths:\n",
    "        from monai.transforms import LoadImage\n",
    "\n",
    "        loader = LoadImage(image_only=True)\n",
    "        result = benchmark_operation(\n",
    "            lambda: loader(str(nifti_gz_paths[0]))[:roi_size, :roi_size, :roi_size],\n",
    "            \"MONAI\",\n",
    "            \"roi_3d\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"MONAI (full load): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    if HAVE_TORCHIO and nifti_gz_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: tio.ScalarImage(str(nifti_gz_paths[0])).data[\n",
    "                :, :roi_size, :roi_size, :roi_size\n",
    "            ],\n",
    "            \"TorchIO\",\n",
    "            \"roi_3d\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"TorchIO (full load): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    # --- Speedup Analysis ---\n",
    "    print(\"\\n--- Tiling Strategy Impact ---\")\n",
    "    slice_axial = next(\n",
    "        (\n",
    "            r\n",
    "            for r in results\n",
    "            if r.benchmark_name == \"slice_2d\"\n",
    "            and r.tiling_strategy == \"axial\"\n",
    "            and r.scenario == \"local\"\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    slice_isotropic = next(\n",
    "        (\n",
    "            r\n",
    "            for r in results\n",
    "            if r.benchmark_name == \"slice_2d\"\n",
    "            and r.tiling_strategy == \"isotropic\"\n",
    "            and r.scenario == \"local\"\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    if slice_axial and slice_isotropic and slice_axial.time_mean_ms > 0:\n",
    "        ratio = slice_isotropic.time_mean_ms / slice_axial.time_mean_ms\n",
    "        print(f\"2D Slice: AXIAL tiling is {ratio:.1f}x faster than ISOTROPIC\")\n",
    "\n",
    "    roi_isotropic = next(\n",
    "        (\n",
    "            r\n",
    "            for r in results\n",
    "            if r.benchmark_name == \"roi_3d\"\n",
    "            and r.tiling_strategy == \"isotropic\"\n",
    "            and r.scenario == \"local\"\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    roi_axial = next(\n",
    "        (\n",
    "            r\n",
    "            for r in results\n",
    "            if r.benchmark_name == \"roi_3d\"\n",
    "            and r.tiling_strategy == \"axial\"\n",
    "            and r.scenario == \"local\"\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    if roi_isotropic and roi_axial and roi_isotropic.time_mean_ms > 0:\n",
    "        ratio = roi_axial.time_mean_ms / roi_isotropic.time_mean_ms\n",
    "        print(f\"3D ROI: ISOTROPIC tiling is {ratio:.1f}x faster than AXIAL\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_partial_reads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat1-random-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_random_access():\n",
    "    \"\"\"Benchmark 2.3: Random Access Pattern.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 2.3: Random Access\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Access volumes in random order (not sequential)\")\n",
    "    print(\"Expectation: RadiObject O(1) indexing; file-based frameworks similar\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "    n_accesses = min(10, len(nifti_gz_paths)) if nifti_gz_paths else 0\n",
    "\n",
    "    if n_accesses < 3:\n",
    "        print(\"Need at least 3 volumes for random access benchmark\")\n",
    "        return results\n",
    "\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    indices = np.random.permutation(n_accesses).tolist()\n",
    "\n",
    "    # RadiObject Local\n",
    "    if radi_local_axial and len(radi_local_axial) >= n_accesses:\n",
    "        collection = radi_local_axial.collection(radi_local_axial.collection_names[0])\n",
    "\n",
    "        def radiobject_random():\n",
    "            for idx in indices:\n",
    "                _ = collection.iloc[idx].to_numpy()\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            radiobject_random, \"RadiObject\", \"random_access\", \"local\", \"axial\", \"tiledb\", n_runs=3\n",
    "        )\n",
    "        result.n_samples = n_accesses\n",
    "        per_vol = result.time_mean_ms / n_accesses\n",
    "        results.append(result)\n",
    "        print(f\"RadiObject (local): {per_vol:.1f} ms/volume ({result.time_mean_ms:.1f} ms total)\")\n",
    "\n",
    "    # RadiObject S3\n",
    "    if radi_s3_axial and len(radi_s3_axial) >= n_accesses:\n",
    "        collection = radi_s3_axial.collection(radi_s3_axial.collection_names[0])\n",
    "\n",
    "        def radiobject_s3_random():\n",
    "            for idx in indices:\n",
    "                _ = collection.iloc[idx].to_numpy()\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            radiobject_s3_random, \"RadiObject\", \"random_access\", \"s3\", \"axial\", \"tiledb\", n_runs=3\n",
    "        )\n",
    "        result.n_samples = n_accesses\n",
    "        per_vol = result.time_mean_ms / n_accesses\n",
    "        results.append(result)\n",
    "        print(f\"RadiObject (S3): {per_vol:.1f} ms/volume ({result.time_mean_ms:.1f} ms total)\")\n",
    "\n",
    "    # MONAI\n",
    "    if HAVE_MONAI and len(nifti_gz_paths) >= n_accesses:\n",
    "        from monai.transforms import LoadImage\n",
    "\n",
    "        loader = LoadImage(image_only=True)\n",
    "        paths = [nifti_gz_paths[i] for i in range(n_accesses)]\n",
    "\n",
    "        def monai_random():\n",
    "            for idx in indices:\n",
    "                _ = loader(str(paths[idx]))\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            monai_random, \"MONAI\", \"random_access\", \"local\", \"\", \"nifti_gz\", n_runs=3\n",
    "        )\n",
    "        result.n_samples = n_accesses\n",
    "        per_vol = result.time_mean_ms / n_accesses\n",
    "        results.append(result)\n",
    "        print(f\"MONAI (local): {per_vol:.1f} ms/volume ({result.time_mean_ms:.1f} ms total)\")\n",
    "\n",
    "    # TorchIO\n",
    "    if HAVE_TORCHIO and len(nifti_gz_paths) >= n_accesses:\n",
    "        paths = [nifti_gz_paths[i] for i in range(n_accesses)]\n",
    "\n",
    "        def torchio_random():\n",
    "            for idx in indices:\n",
    "                img = tio.ScalarImage(str(paths[idx]))\n",
    "                _ = img.data\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            torchio_random, \"TorchIO\", \"random_access\", \"local\", \"\", \"nifti_gz\", n_runs=3\n",
    "        )\n",
    "        result.n_samples = n_accesses\n",
    "        per_vol = result.time_mean_ms / n_accesses\n",
    "        results.append(result)\n",
    "        print(f\"TorchIO (local): {per_vol:.1f} ms/volume ({result.time_mean_ms:.1f} ms total)\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_random_access())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cat2-header",
   "metadata": {},
   "source": [
    "## 5. Category 2: Analysis Workflow Benchmarks\n",
    "\n",
    "In-notebook exploration and analysis workflows.\n",
    "\n",
    "| Benchmark | What It Tests | RadiObject Advantage |\n",
    "|-----------|---------------|---------------------|\n",
    "| Metadata Query | Filter subjects by attributes | TileDB QueryCondition |\n",
    "| Index Lookup | Access by subject ID | O(1) vs file scan |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat2-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_metadata_operations():\n",
    "    \"\"\"Benchmark 2.1: Metadata and Index Operations.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 2.1: Metadata & Index Operations\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Access metadata, filter subjects, lookup by ID\")\n",
    "    print(\"Expectation: RadiObject O(1) operations; file-based need scanning\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # RadiObject Local\n",
    "    if radi_local_axial:\n",
    "        # Index lookup by position\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_local_axial.iloc[0], \"RadiObject\", \"iloc_lookup\", \"local\", \"axial\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject iloc[0] (local): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\"\n",
    "        )\n",
    "\n",
    "        # obs_subject_ids property\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_local_axial.obs_subject_ids,\n",
    "            \"RadiObject\",\n",
    "            \"obs_subject_ids\",\n",
    "            \"local\",\n",
    "            \"axial\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject obs_subject_ids (local): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\"\n",
    "        )\n",
    "\n",
    "        # collection_names property\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_local_axial.collection_names,\n",
    "            \"RadiObject\",\n",
    "            \"collection_names\",\n",
    "            \"local\",\n",
    "            \"axial\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject collection_names (local): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\"\n",
    "        )\n",
    "\n",
    "    # RadiObject S3\n",
    "    if radi_s3_axial:\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_s3_axial.iloc[0], \"RadiObject\", \"iloc_lookup\", \"s3\", \"axial\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"RadiObject iloc[0] (S3): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\")\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_s3_axial.obs_subject_ids, \"RadiObject\", \"obs_subject_ids\", \"s3\", \"axial\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject obs_subject_ids (S3): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\"\n",
    "        )\n",
    "\n",
    "    # File-based comparison\n",
    "    if nifti_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: list(NIFTI_DIR.glob(\"*.nii.gz\")), \"File\", \"glob_scan\", \"local\", \"\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"\\nFile glob('*.nii.gz'): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    print(\"\\n--- Key Insight ---\")\n",
    "    print(\"RadiObject metadata operations are O(1) due to TileDB indexing\")\n",
    "    print(\"File-based systems require directory scanning or path construction\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_metadata_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cat3-header",
   "metadata": {},
   "source": [
    "## 6. Category 3: ML Training Benchmarks\n",
    "\n",
    "PyTorch DataLoader throughput for deep learning training.\n",
    "\n",
    "| Benchmark | What It Tests | RadiObject Advantage |\n",
    "|-----------|---------------|---------------------|\n",
    "| DataLoader Throughput | Samples/sec during training | Competitive locally |\n",
    "| Patch Extraction | Random patch loading | Partial reads |\n",
    "| Memory Efficiency | Peak RAM during epoch | Lazy loading |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat3-adapters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radiobject_loader(\n",
    "    radi: RadiObject,\n",
    "    patch_size: tuple[int, int, int] | None = None,\n",
    ") -> DataLoader | None:\n",
    "    \"\"\"Create RadiObject DataLoader.\"\"\"\n",
    "    try:\n",
    "        return create_training_dataloader(\n",
    "            radi,\n",
    "            modalities=[radi.collection_names[0]],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            patch_size=patch_size or PATCH_SIZE,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"  RadiObject DataLoader error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_monai_loader(\n",
    "    paths: list[Path],\n",
    "    patch_size: tuple[int, int, int] | None = None,\n",
    ") -> DataLoader | None:\n",
    "    \"\"\"Create MONAI DataLoader.\"\"\"\n",
    "    if not HAVE_MONAI or not paths:\n",
    "        return None\n",
    "\n",
    "    data_dicts = [{\"image\": str(p)} for p in paths]\n",
    "    ps = patch_size or PATCH_SIZE\n",
    "\n",
    "    transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\"]),\n",
    "            RandSpatialCropd(keys=[\"image\"], roi_size=ps, random_size=False),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = MonaiDataset(data=data_dicts, transform=transforms)\n",
    "    return MonaiDataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "\n",
    "\n",
    "def create_torchio_loader(\n",
    "    paths: list[Path],\n",
    "    patch_size: tuple[int, int, int] | None = None,\n",
    ") -> DataLoader | None:\n",
    "    \"\"\"Create TorchIO DataLoader.\"\"\"\n",
    "    if not HAVE_TORCHIO or not paths:\n",
    "        return None\n",
    "\n",
    "    subjects = [tio.Subject(image=tio.ScalarImage(str(p))) for p in paths]\n",
    "    ps = patch_size or PATCH_SIZE\n",
    "    transform = tio.Compose([tio.CropOrPad(ps)])\n",
    "    dataset = tio.SubjectsDataset(subjects, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat3-throughput",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_dataloader_throughput():\n",
    "    \"\"\"Benchmark: ML DataLoader Throughput (samples/sec).\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK: ML DataLoader Throughput\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Config: batch_size={BATCH_SIZE}, patch_size={PATCH_SIZE}\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # RadiObject Local (isotropic for patch extraction)\n",
    "    if radi_local_isotropic:\n",
    "        loader = create_radiobject_loader(radi_local_isotropic)\n",
    "        if loader:\n",
    "            result = benchmark_dataloader(\n",
    "                loader, \"RadiObject\", \"dataloader_throughput\", \"local\", \"isotropic\"\n",
    "            )\n",
    "            results.append(result)\n",
    "            print(f\"RadiObject (local): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "            print(f\"  Batch: {result.time_mean_ms:.1f} ms | Memory: {result.peak_heap_mb:.0f} MB\")\n",
    "            del loader\n",
    "            gc.collect()\n",
    "\n",
    "    # RadiObject S3\n",
    "    if radi_s3_isotropic:\n",
    "        loader = create_radiobject_loader(radi_s3_isotropic)\n",
    "        if loader:\n",
    "            result = benchmark_dataloader(\n",
    "                loader,\n",
    "                \"RadiObject\",\n",
    "                \"dataloader_throughput\",\n",
    "                \"s3\",\n",
    "                \"isotropic\",\n",
    "                n_batches=min(10, N_BATCHES),\n",
    "            )\n",
    "            results.append(result)\n",
    "            print(f\"RadiObject (S3): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "            print(f\"  Batch: {result.time_mean_ms:.1f} ms\")\n",
    "            del loader\n",
    "            gc.collect()\n",
    "\n",
    "    # MONAI - use benchmark NIfTI files\n",
    "    if HAVE_MONAI and nifti_gz_paths:\n",
    "        loader = create_monai_loader(nifti_gz_paths)\n",
    "        if loader:\n",
    "            result = benchmark_dataloader(loader, \"MONAI\", \"dataloader_throughput\", \"local\", \"\")\n",
    "            result.storage_format = \"nifti_gz\"\n",
    "            results.append(result)\n",
    "            print(f\"MONAI (local): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "            print(f\"  Batch: {result.time_mean_ms:.1f} ms | Memory: {result.peak_heap_mb:.0f} MB\")\n",
    "            del loader\n",
    "            gc.collect()\n",
    "\n",
    "    # TorchIO - use benchmark NIfTI files\n",
    "    if HAVE_TORCHIO and nifti_gz_paths:\n",
    "        loader = create_torchio_loader(nifti_gz_paths)\n",
    "        if loader:\n",
    "            gc.collect()\n",
    "            tracemalloc.start()\n",
    "            cpu_sampler = CPUSampler()\n",
    "            cpu_sampler.start()\n",
    "\n",
    "            loader_iter = iter(loader)\n",
    "            cold_start = time.perf_counter()\n",
    "            first_batch = next(loader_iter)\n",
    "            _ = first_batch[\"image\"][tio.DATA].shape\n",
    "            cold_start_time = (time.perf_counter() - cold_start) * 1000\n",
    "\n",
    "            batch_times = []\n",
    "            for _ in range(N_BATCHES):\n",
    "                try:\n",
    "                    start = time.perf_counter()\n",
    "                    batch = next(loader_iter)\n",
    "                    _ = batch[\"image\"][tio.DATA].shape\n",
    "                    batch_times.append((time.perf_counter() - start) * 1000)\n",
    "                except StopIteration:\n",
    "                    loader_iter = iter(loader)\n",
    "                    batch = next(loader_iter)\n",
    "\n",
    "            cpu_mean, cpu_peak = cpu_sampler.stop()\n",
    "            _, peak_heap = tracemalloc.get_traced_memory()\n",
    "            tracemalloc.stop()\n",
    "\n",
    "            mean_batch = float(np.mean(batch_times)) if batch_times else 0.0\n",
    "            throughput = (BATCH_SIZE / (mean_batch / 1000)) if mean_batch > 0 else 0.0\n",
    "\n",
    "            result = BenchmarkResult(\n",
    "                framework=\"TorchIO\",\n",
    "                benchmark_name=\"dataloader_throughput\",\n",
    "                scenario=\"local\",\n",
    "                storage_format=\"nifti_gz\",\n",
    "                time_mean_ms=mean_batch,\n",
    "                time_std_ms=float(np.std(batch_times)) if batch_times else 0.0,\n",
    "                cold_start_ms=cold_start_time,\n",
    "                batch_times_ms=batch_times,\n",
    "                cpu_percent_mean=cpu_mean,\n",
    "                cpu_percent_peak=cpu_peak,\n",
    "                peak_heap_mb=peak_heap / (1024 * 1024),\n",
    "                throughput_samples_per_sec=throughput,\n",
    "                n_samples=len(batch_times) * BATCH_SIZE,\n",
    "            )\n",
    "            results.append(result)\n",
    "            print(f\"TorchIO (local): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "            print(f\"  Batch: {result.time_mean_ms:.1f} ms | Memory: {result.peak_heap_mb:.0f} MB\")\n",
    "            del loader\n",
    "            gc.collect()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_dataloader_throughput())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cat4-header",
   "metadata": {},
   "source": [
    "## 7. Category 4: S3 Cloud Storage Benchmarks\n",
    "\n",
    "RadiObject's unique capability: native S3 access via TileDB VFS.\n",
    "\n",
    "| Benchmark | What It Tests | Notes |\n",
    "|-----------|---------------|-------|\n",
    "| S3 vs Local | Performance overhead | Expected 2-5x slower |\n",
    "| S3 Partial Read | Slice from S3 | RadiObject unique |\n",
    "| S3 Training | ML training from S3 | No pre-download required |\n",
    "\n",
    "**Important:** MONAI and TorchIO cannot natively read from S3 - they require downloading files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat4-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_s3_vs_local():\n",
    "    \"\"\"Benchmark 4.1: S3 vs Local Performance Comparison.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 4.1: S3 vs Local (RadiObject)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Compare local vs S3 performance for the same operations\")\n",
    "    print(\"Expectation: S3 2-5x slower due to network latency\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if not (radi_local_axial and radi_s3_axial):\n",
    "        print(\"Need both local and S3 datasets for comparison\")\n",
    "        return results\n",
    "\n",
    "    local_vol = radi_local_axial.collection(radi_local_axial.collection_names[0]).iloc[0]\n",
    "    s3_vol = radi_s3_axial.collection(radi_s3_axial.collection_names[0]).iloc[0]\n",
    "\n",
    "    # Full volume comparison\n",
    "    print(\"--- Full Volume Load ---\")\n",
    "    result_local = benchmark_operation(\n",
    "        lambda: local_vol.to_numpy(), \"RadiObject\", \"s3_comparison_full\", \"local\", \"axial\", n_runs=3\n",
    "    )\n",
    "    results.append(result_local)\n",
    "    print(f\"Local: {result_local.time_mean_ms:.1f} +/- {result_local.time_std_ms:.1f} ms\")\n",
    "\n",
    "    result_s3 = benchmark_operation(\n",
    "        lambda: s3_vol.to_numpy(), \"RadiObject\", \"s3_comparison_full\", \"s3\", \"axial\", n_runs=3\n",
    "    )\n",
    "    results.append(result_s3)\n",
    "    print(f\"S3: {result_s3.time_mean_ms:.1f} +/- {result_s3.time_std_ms:.1f} ms\")\n",
    "\n",
    "    if result_local.time_mean_ms > 0:\n",
    "        overhead = (result_s3.time_mean_ms / result_local.time_mean_ms - 1) * 100\n",
    "        print(f\"S3 overhead: {overhead:.1f}%\")\n",
    "\n",
    "    # Slice comparison\n",
    "    print(\"\\n--- 2D Slice ---\")\n",
    "    mid_z = local_vol.shape[2] // 2\n",
    "\n",
    "    result_local = benchmark_operation(\n",
    "        lambda: local_vol.axial(mid_z), \"RadiObject\", \"s3_comparison_slice\", \"local\", \"axial\"\n",
    "    )\n",
    "    results.append(result_local)\n",
    "    print(f\"Local: {result_local.time_mean_ms:.2f} +/- {result_local.time_std_ms:.2f} ms\")\n",
    "\n",
    "    mid_z_s3 = s3_vol.shape[2] // 2\n",
    "    result_s3 = benchmark_operation(\n",
    "        lambda: s3_vol.axial(mid_z_s3), \"RadiObject\", \"s3_comparison_slice\", \"s3\", \"axial\"\n",
    "    )\n",
    "    results.append(result_s3)\n",
    "    print(f\"S3: {result_s3.time_mean_ms:.2f} +/- {result_s3.time_std_ms:.2f} ms\")\n",
    "\n",
    "    if result_local.time_mean_ms > 0:\n",
    "        overhead = (result_s3.time_mean_ms / result_local.time_mean_ms - 1) * 100\n",
    "        print(f\"S3 overhead: {overhead:.1f}%\")\n",
    "\n",
    "    print(\"\\n--- Key Insight ---\")\n",
    "    print(\"RadiObject can read directly from S3 without downloading files\")\n",
    "    print(\"Partial reads from S3 are particularly efficient due to TileDB tiling\")\n",
    "    print(\"MONAI/TorchIO would require downloading all NIfTI files first\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if RUN_S3_BENCHMARKS:\n",
    "    all_results.extend(benchmark_s3_vs_local())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 8. Results Visualization\n",
    "\n",
    "Publication-quality visualizations of benchmark results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colorblind-friendly palette (Wong 2011)\n",
    "COLORS = {\n",
    "    \"RadiObject\": \"#0077BB\",\n",
    "    \"MONAI\": \"#EE7733\",\n",
    "    \"TorchIO\": \"#009988\",\n",
    "    \"File\": \"#888888\",\n",
    "    \"local\": \"#0077BB\",\n",
    "    \"s3\": \"#CC3311\",\n",
    "    \"axial\": \"#0077BB\",\n",
    "    \"isotropic\": \"#EE7733\",\n",
    "}\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 11,\n",
    "        \"axes.titlesize\": 13,\n",
    "        \"axes.labelsize\": 11,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "        \"figure.dpi\": 120,\n",
    "        \"savefig.dpi\": 300,\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"figure.facecolor\": \"white\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6fkcekwv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERO CHART: Consolidated Backend Comparison\n",
    "# Shows all operations across all backends in one visualization\n",
    "\n",
    "\n",
    "def create_hero_chart():\n",
    "    \"\"\"Create consolidated comparison chart across all backends and operations.\"\"\"\n",
    "\n",
    "    # Collect data for key operations\n",
    "    operations = {\n",
    "        \"Full Volume\": \"full_volume\",\n",
    "        \"2D Slice\": \"slice_2d\",\n",
    "        \"64³ ROI\": \"roi_3d\",\n",
    "    }\n",
    "\n",
    "    # Include S3 backend if benchmarks were run\n",
    "    has_s3_results = any(r.scenario == \"s3\" and r.framework == \"RadiObject\" for r in all_results)\n",
    "\n",
    "    backends = [\n",
    "        (\"RadiObject (local)\", \"RadiObject\", \"local\"),\n",
    "    ]\n",
    "    if has_s3_results:\n",
    "        backends.append((\"RadiObject (S3)\", \"RadiObject\", \"s3\"))\n",
    "    backends.extend(\n",
    "        [\n",
    "            (\"MONAI\", \"MONAI\", \"local\"),\n",
    "            (\"TorchIO\", \"TorchIO\", \"local\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Build data matrix\n",
    "    data = {op: [] for op in operations}\n",
    "    backend_labels = []\n",
    "\n",
    "    for label, framework, scenario in backends:\n",
    "        backend_labels.append(label)\n",
    "        for op_name, bench_name in operations.items():\n",
    "            result = next(\n",
    "                (\n",
    "                    r\n",
    "                    for r in all_results\n",
    "                    if r.benchmark_name == bench_name\n",
    "                    and r.framework == framework\n",
    "                    and r.scenario == scenario\n",
    "                    and (r.tiling_strategy in [\"\", \"axial\", \"isotropic\"])\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            # For RadiObject, prefer optimal tiling per operation\n",
    "            if framework == \"RadiObject\":\n",
    "                if bench_name == \"slice_2d\":\n",
    "                    result = next(\n",
    "                        (\n",
    "                            r\n",
    "                            for r in all_results\n",
    "                            if r.benchmark_name == bench_name\n",
    "                            and r.framework == framework\n",
    "                            and r.tiling_strategy == \"axial\"\n",
    "                            and r.scenario == scenario\n",
    "                        ),\n",
    "                        result,\n",
    "                    )\n",
    "                elif bench_name == \"roi_3d\":\n",
    "                    result = next(\n",
    "                        (\n",
    "                            r\n",
    "                            for r in all_results\n",
    "                            if r.benchmark_name == bench_name\n",
    "                            and r.framework == framework\n",
    "                            and r.tiling_strategy == \"isotropic\"\n",
    "                            and r.scenario == scenario\n",
    "                        ),\n",
    "                        result,\n",
    "                    )\n",
    "\n",
    "            data[op_name].append(result.time_mean_ms if result else 0)\n",
    "\n",
    "    # Create grouped bar chart\n",
    "    n_backends = len(backend_labels)\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    x = np.arange(n_backends)\n",
    "    width = 0.25\n",
    "    multiplier = 0\n",
    "\n",
    "    colors = [\"#0077BB\", \"#EE7733\", \"#009988\"]\n",
    "\n",
    "    for i, (op_name, times) in enumerate(data.items()):\n",
    "        offset = width * multiplier\n",
    "        bars = ax.bar(\n",
    "            x + offset,\n",
    "            times,\n",
    "            width,\n",
    "            label=op_name,\n",
    "            color=colors[i],\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        # Add value labels\n",
    "        for bar, val in zip(bars, times):\n",
    "            if val > 0:\n",
    "                height = bar.get_height()\n",
    "                label = f\"{val:.0f}\" if val >= 10 else f\"{val:.1f}\"\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    height,\n",
    "                    label,\n",
    "                    ha=\"center\",\n",
    "                    va=\"bottom\",\n",
    "                    fontsize=8,\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "        multiplier += 1\n",
    "\n",
    "    ax.set_ylabel(\"Time (ms) — lower is better\", fontweight=\"bold\")\n",
    "    title = \"I/O Performance: RadiObject vs MONAI vs TorchIO\"\n",
    "    if has_s3_results:\n",
    "        title = \"I/O Performance: RadiObject (Local & S3) vs MONAI vs TorchIO\"\n",
    "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(backend_labels, fontweight=\"bold\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Add speedup annotations\n",
    "    ax.axhline(y=10, color=\"gray\", linestyle=\":\", alpha=0.5)\n",
    "    ax.text(n_backends - 0.5, 12, \"10ms threshold\", fontsize=8, color=\"gray\", ha=\"right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filepath = ASSETS_DIR / \"benchmark_hero.png\"\n",
    "    plt.savefig(filepath, dpi=300)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print speedup summary\n",
    "    print(\"\\n--- Speedup Summary (vs slowest) ---\")\n",
    "    for op_name, times in data.items():\n",
    "        if all(t > 0 for t in times):\n",
    "            max_time = max(times)\n",
    "            for label, t in zip(backend_labels, times):\n",
    "                speedup = max_time / t\n",
    "                print(f\"{op_name} | {label}: {speedup:.1f}x\")\n",
    "\n",
    "\n",
    "create_hero_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_comparison(\n",
    "    data: dict[str, float],\n",
    "    title: str,\n",
    "    ylabel: str,\n",
    "    filename: str,\n",
    "    errors: dict[str, float] | None = None,\n",
    "    color_key: str = \"framework\",\n",
    "):\n",
    "    \"\"\"Create a bar chart comparing frameworks.\"\"\"\n",
    "    labels = list(data.keys())\n",
    "    values = list(data.values())\n",
    "\n",
    "    # Determine colors\n",
    "    if color_key == \"framework\":\n",
    "        colors = [COLORS.get(l.split()[0], \"#999999\") for l in labels]\n",
    "    else:\n",
    "        colors = [COLORS.get(l.lower(), \"#999999\") for l in labels]\n",
    "\n",
    "    error_vals = [errors.get(l, 0) for l in labels] if errors else None\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    bars = ax.bar(\n",
    "        labels,\n",
    "        values,\n",
    "        yerr=error_vals,\n",
    "        capsize=5,\n",
    "        color=colors,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Rotate labels if needed\n",
    "    if len(labels) > 4 or max(len(l) for l in labels) > 15:\n",
    "        plt.xticks(rotation=30, ha=\"right\")\n",
    "\n",
    "    # Add value labels\n",
    "    max_val = max(values) if values else 1\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + (max_val * 0.02),\n",
    "            f\"{val:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filepath = ASSETS_DIR / filename\n",
    "    plt.savefig(filepath)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widar6x4m4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Disk Space Comparison\n",
    "if disk_space_results:\n",
    "    data = {r.format_name: r.size_mb for r in disk_space_results}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    labels = list(data.keys())\n",
    "    values = list(data.values())\n",
    "    colors = [\"#0077BB\", \"#0077BB\", \"#EE7733\", \"#EE7733\", \"#009988\"]\n",
    "\n",
    "    bars = ax.bar(labels, values, color=colors[: len(labels)], edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "    ax.set_ylabel(\"Size (MB)\")\n",
    "    ax.set_title(\"Disk Space by Storage Format\")\n",
    "    ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "\n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + (max(values) * 0.02),\n",
    "            f\"{val:.0f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filepath = ASSETS_DIR / \"disk_space_comparison.png\"\n",
    "    plt.savefig(filepath)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mftguo9cr3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Format Overhead Comparison\n",
    "format_results = [r for r in all_results if r.benchmark_name == \"format_comparison\"]\n",
    "if format_results:\n",
    "    data = {}\n",
    "    for r in format_results:\n",
    "        if r.storage_format == \"nifti_gz\":\n",
    "            label = \"NIfTI (.nii.gz)\"\n",
    "        elif r.storage_format == \"nifti\":\n",
    "            label = \"NIfTI (.nii)\"\n",
    "        elif r.storage_format == \"numpy\":\n",
    "            label = \"NumPy (.npy)\"\n",
    "        elif r.storage_format == \"tiledb\":\n",
    "            label = f\"TileDB ({r.tiling_strategy})\"\n",
    "        else:\n",
    "            label = r.storage_format\n",
    "        data[label] = r.time_mean_ms\n",
    "\n",
    "    plot_bar_comparison(\n",
    "        data, \"Full Volume Load: Format Overhead\", \"Time (ms)\", \"format_overhead.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6yvokpvbvd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Memory by Backend (Heap comparison)\n",
    "memory_results = [\n",
    "    r\n",
    "    for r in all_results\n",
    "    if r.benchmark_name in [\"full_volume\", \"slice_2d\"] and r.scenario == \"local\"\n",
    "]\n",
    "if memory_results:\n",
    "    # Group by benchmark type\n",
    "    full_vol = [r for r in memory_results if r.benchmark_name == \"full_volume\"]\n",
    "    slice_2d = [r for r in memory_results if r.benchmark_name == \"slice_2d\"]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Full volume memory\n",
    "    if full_vol:\n",
    "        data = {r.framework: r.peak_heap_mb for r in full_vol if r.peak_heap_mb > 0}\n",
    "        if data:\n",
    "            ax = axes[0]\n",
    "            labels = list(data.keys())\n",
    "            values = list(data.values())\n",
    "            colors = [COLORS.get(l, \"#999999\") for l in labels]\n",
    "            bars = ax.bar(labels, values, color=colors, edgecolor=\"black\", linewidth=1)\n",
    "            ax.set_ylabel(\"Peak Heap (MB)\")\n",
    "            ax.set_title(\"Memory: Full Volume Load\")\n",
    "            ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "            for bar, val in zip(bars, values):\n",
    "                height = bar.get_height()\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    height + (max(values) * 0.02),\n",
    "                    f\"{val:.0f}\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"bottom\",\n",
    "                    fontsize=9,\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "\n",
    "    # Slice extraction memory\n",
    "    if slice_2d:\n",
    "        data = {\n",
    "            f\"{r.framework} ({r.tiling_strategy or 'nifti'})\": r.peak_heap_mb\n",
    "            for r in slice_2d\n",
    "            if r.peak_heap_mb > 0\n",
    "        }\n",
    "        if data:\n",
    "            ax = axes[1]\n",
    "            labels = list(data.keys())\n",
    "            values = list(data.values())\n",
    "            colors = [COLORS.get(l.split()[0], \"#999999\") for l in labels]\n",
    "            bars = ax.bar(labels, values, color=colors, edgecolor=\"black\", linewidth=1)\n",
    "            ax.set_ylabel(\"Peak Heap (MB)\")\n",
    "            ax.set_title(\"Memory: 2D Slice Extraction\")\n",
    "            ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "            plt.xticks(rotation=30, ha=\"right\")\n",
    "            for bar, val in zip(bars, values):\n",
    "                height = bar.get_height()\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    height + (max(values) * 0.02),\n",
    "                    f\"{val:.0f}\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"bottom\",\n",
    "                    fontsize=9,\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filepath = ASSETS_DIR / \"memory_by_backend.png\"\n",
    "    plt.savefig(filepath)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-full-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Full Volume Load Time\n",
    "full_volume_results = [r for r in all_results if r.benchmark_name == \"full_volume\"]\n",
    "if full_volume_results:\n",
    "    data = {}\n",
    "    errors = {}\n",
    "    for r in full_volume_results:\n",
    "        label = f\"{r.framework} ({r.scenario})\"\n",
    "        data[label] = r.time_mean_ms\n",
    "        errors[label] = r.time_std_ms\n",
    "\n",
    "    plot_bar_comparison(data, \"Full Volume Load Time\", \"Time (ms)\", \"full_volume_load.png\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-slice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Slice Extraction (Tiling Comparison)\n",
    "slice_results = [r for r in all_results if r.benchmark_name == \"slice_2d\"]\n",
    "if slice_results:\n",
    "    data = {}\n",
    "    for r in slice_results:\n",
    "        if r.framework == \"RadiObject\":\n",
    "            label = f\"{r.tiling_strategy.upper()} ({r.scenario})\"\n",
    "        else:\n",
    "            label = f\"{r.framework} ({r.scenario})\"\n",
    "        data[label] = r.time_mean_ms\n",
    "\n",
    "    plot_bar_comparison(\n",
    "        data, \"2D Slice Extraction: Tiling Impact\", \"Time (ms)\", \"slice_extraction.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-roi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: ROI Extraction (Tiling Comparison)\n",
    "roi_results = [r for r in all_results if r.benchmark_name == \"roi_3d\"]\n",
    "if roi_results:\n",
    "    data = {}\n",
    "    for r in roi_results:\n",
    "        if r.framework == \"RadiObject\":\n",
    "            label = f\"{r.tiling_strategy.upper()} ({r.scenario})\"\n",
    "        else:\n",
    "            label = f\"{r.framework} ({r.scenario})\"\n",
    "        data[label] = r.time_mean_ms\n",
    "\n",
    "    plot_bar_comparison(\n",
    "        data, \"3D ROI Extraction (64x64x64): Tiling Impact\", \"Time (ms)\", \"roi_extraction.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-throughput",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: DataLoader Throughput\n",
    "throughput_results = [r for r in all_results if r.benchmark_name == \"dataloader_throughput\"]\n",
    "if throughput_results:\n",
    "    data = {}\n",
    "    for r in throughput_results:\n",
    "        label = f\"{r.framework} ({r.scenario})\"\n",
    "        data[label] = r.throughput_samples_per_sec\n",
    "\n",
    "    plot_bar_comparison(data, \"DataLoader Throughput\", \"Samples/sec\", \"dataloader_throughput.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-s3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: S3 vs Local Comparison\n",
    "s3_comp_results = [r for r in all_results if \"s3_comparison\" in r.benchmark_name]\n",
    "if s3_comp_results:\n",
    "    # Full volume comparison\n",
    "    full_results = [r for r in s3_comp_results if \"full\" in r.benchmark_name]\n",
    "    if len(full_results) >= 2:\n",
    "        data = {r.scenario.upper(): r.time_mean_ms for r in full_results}\n",
    "        plot_bar_comparison(\n",
    "            data,\n",
    "            \"RadiObject: Local vs S3 Full Volume Load\",\n",
    "            \"Time (ms)\",\n",
    "            \"s3_vs_local_full.png\",\n",
    "            color_key=\"scenario\",\n",
    "        )\n",
    "\n",
    "    # Slice comparison\n",
    "    slice_results = [r for r in s3_comp_results if \"slice\" in r.benchmark_name]\n",
    "    if len(slice_results) >= 2:\n",
    "        data = {r.scenario.upper(): r.time_mean_ms for r in slice_results}\n",
    "        plot_bar_comparison(\n",
    "            data,\n",
    "            \"RadiObject: Local vs S3 Slice Extraction\",\n",
    "            \"Time (ms)\",\n",
    "            \"s3_vs_local_slice.png\",\n",
    "            color_key=\"scenario\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 9. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build summary DataFrame\n",
    "summary_rows = [r.to_dict() for r in all_results]\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Display key columns\n",
    "display_cols = [\n",
    "    \"framework\",\n",
    "    \"benchmark_name\",\n",
    "    \"scenario\",\n",
    "    \"tiling_strategy\",\n",
    "    \"time_mean_ms\",\n",
    "    \"time_std_ms\",\n",
    "    \"cpu_percent_mean\",\n",
    "    \"peak_heap_mb\",\n",
    "    \"throughput_samples_per_sec\",\n",
    "]\n",
    "existing_cols = [c for c in display_cols if c in summary_df.columns]\n",
    "display(summary_df[existing_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to JSON\n",
    "results_json = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"config\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"patch_size\": list(PATCH_SIZE),\n",
    "        \"num_workers\": NUM_WORKERS,\n",
    "        \"n_warmup\": N_WARMUP,\n",
    "        \"n_batches\": N_BATCHES,\n",
    "        \"n_runs\": N_RUNS,\n",
    "        \"random_seed\": RANDOM_SEED,\n",
    "        \"s3_bucket\": S3_BUCKET,\n",
    "        \"n_subjects\": N_SUBJECTS_FOR_TILED,\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"local_axial\": LOCAL_AXIAL_URI,\n",
    "        \"local_isotropic\": LOCAL_ISOTROPIC_URI,\n",
    "        \"nifti_compressed\": str(NIFTI_COMPRESSED_DIR),\n",
    "        \"nifti_uncompressed\": str(NIFTI_UNCOMPRESSED_DIR),\n",
    "        \"numpy\": str(NUMPY_DIR),\n",
    "        \"s3_axial\": S3_AXIAL_URI if radi_s3_axial else None,\n",
    "        \"s3_isotropic\": S3_ISOTROPIC_URI if radi_s3_isotropic else None,\n",
    "    },\n",
    "    \"disk_space\": [r.to_dict() for r in disk_space_results],\n",
    "    \"benchmarks\": [r.to_dict() for r in all_results],\n",
    "}\n",
    "\n",
    "results_path = ASSETS_DIR / \"benchmark_results.json\"\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results_json, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Results exported: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "## 10. Conclusions\n",
    "\n",
    "### Tiling Strategy Impact\n",
    "\n",
    "| Operation | Optimal Tiling | Why |\n",
    "|-----------|---------------|-----|\n",
    "| 2D Axial Slice | AXIAL (z=1) | Reads exactly 1 tile per slice |\n",
    "| 3D ROI (64x64x64) | ISOTROPIC (64^3) | Reads 1-8 tiles depending on alignment |\n",
    "\n",
    "**Key Insight**: Choose tiling strategy based on your primary access pattern!\n",
    "\n",
    "### When to Use Each Framework\n",
    "\n",
    "| Use Case | Recommended Framework | Reason |\n",
    "|----------|----------------------|--------|\n",
    "| **S3/Cloud data** | RadiObject | Only option with native S3 support |\n",
    "| **Partial volume reads** | RadiObject | TileDB tile-level access |\n",
    "| **Large dataset exploration** | RadiObject | O(1) indexing, lazy views |\n",
    "| **Multi-modal alignment** | RadiObject | Unified subject index |\n",
    "| **Local NIfTI training** | MONAI/TorchIO | Optimized transforms |\n",
    "| **Data augmentation** | TorchIO | Rich transform library |\n",
    "| **Production DL pipelines** | MONAI | Comprehensive ecosystem |\n",
    "\n",
    "### RadiObject's Sweet Spot\n",
    "\n",
    "1. **Cloud-native workflows**: Train directly from S3 without downloading\n",
    "2. **Interactive analysis**: Fast metadata queries and partial reads\n",
    "3. **Large cohort studies**: Scale to 10,000+ subjects with O(1) operations\n",
    "4. **Multi-modal data**: Unified index across T1w, FLAIR, CT, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BENCHMARK COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nDatasets:\")\n",
    "print(f\"  Local AXIAL: {len(radi_local_axial) if radi_local_axial else 'N/A'} subjects\")\n",
    "print(f\"  Local ISOTROPIC: {len(radi_local_isotropic) if radi_local_isotropic else 'N/A'} subjects\")\n",
    "print(f\"  S3 AXIAL: {len(radi_s3_axial) if radi_s3_axial else 'N/A'} subjects\")\n",
    "print(f\"  S3 ISOTROPIC: {len(radi_s3_isotropic) if radi_s3_isotropic else 'N/A'} subjects\")\n",
    "print(f\"  NIfTI files: {len(nifti_paths) if nifti_paths else 0}\")\n",
    "\n",
    "print(\"\\nConfiguration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Patch size: {PATCH_SIZE}\")\n",
    "print(f\"  Runs per benchmark: {N_RUNS}\")\n",
    "\n",
    "print(\"\\nFramework Availability:\")\n",
    "print(\"  RadiObject: Available\")\n",
    "print(f\"  MONAI: {'Available' if HAVE_MONAI else 'Not installed'}\")\n",
    "print(f\"  TorchIO: {'Available' if HAVE_TORCHIO else 'Not installed'}\")\n",
    "\n",
    "print(\"\\nGenerated Artifacts:\")\n",
    "for f in sorted(ASSETS_DIR.glob(\"*\")):\n",
    "    if not f.name.startswith(\".\"):\n",
    "        print(f\"  {f.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}