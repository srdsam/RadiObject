{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-98729",
   "metadata": {},
   "source": [
    "# Experiment 04: ML DataLoader Throughput\n",
    "\n",
    "## 1. Hypothesis & Rationale\n",
    "\n",
    "**Research Question:** How does RadiObject's patch-based loading compare to MONAI/TorchIO for ML training throughput?\n",
    "\n",
    "**Hypothesis:** RadiObject's patch-based loading reduces I/O by 100x, enabling higher training throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-40122",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (papermill)\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SIZE = (64, 64, 64)\n",
    "NUM_WORKERS = 0\n",
    "N_WARMUP = 5\n",
    "N_RUNS = 10\n",
    "N_BATCHES = 20\n",
    "N_SUBJECTS = 20\n",
    "RANDOM_SEED = 42\n",
    "S3_BUCKET = \"souzy-scratch\"\n",
    "TILING_STRATEGIES = [\"axial\", \"isotropic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-parse-params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse parameters (papermill passes tuples as strings)\n",
    "import ast\n",
    "\n",
    "if isinstance(PATCH_SIZE, str):\n",
    "    PATCH_SIZE = ast.literal_eval(PATCH_SIZE)\n",
    "if isinstance(TILING_STRATEGIES, str):\n",
    "    TILING_STRATEGIES = ast.literal_eval(TILING_STRATEGIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-77079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchio as tio\n",
    "from monai.data import DataLoader as MonaiDataLoader\n",
    "from monai.data import Dataset as MonaiDataset\n",
    "from monai.transforms import Compose, EnsureChannelFirstd, LoadImaged, RandSpatialCropd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Derive project root from absolute config paths\n",
    "from benchmarks.config import _BENCHMARKS_DIR, BENCHMARK_DIR, FIGURES_DIR, S3_REGION\n",
    "\n",
    "project_root = _BENCHMARKS_DIR.parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "from benchmarks.infrastructure import (\n",
    "    BenchmarkResult,\n",
    "    CPUSampler,\n",
    "    benchmark_dataloader,\n",
    "    plot_bar_comparison,\n",
    ")\n",
    "from radiobject import RadiObject\n",
    "from radiobject.ctx import S3Config, configure\n",
    "from radiobject.ml import create_training_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-64834",
   "metadata": {},
   "source": [
    "## 2. Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-47722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIfTI files\n",
    "nifti_gz_paths = sorted((BENCHMARK_DIR / \"nifti-compressed\").glob(\"*.nii.gz\"))[:N_SUBJECTS]\n",
    "print(f\"NIfTI files: {len(nifti_gz_paths)}\")\n",
    "\n",
    "# RadiObject local dataset\n",
    "radi_local_isotropic = RadiObject(str(BENCHMARK_DIR / \"radiobject-isotropic\"))\n",
    "print(f\"Loaded local ISOTROPIC: {len(radi_local_isotropic)} subjects\")\n",
    "\n",
    "# RadiObject S3 dataset\n",
    "configure(s3=S3Config(region=S3_REGION))\n",
    "radi_s3_isotropic = RadiObject(f\"s3://{S3_BUCKET}/benchmark/radiobject-isotropic\")\n",
    "print(f\"Loaded S3 ISOTROPIC: {len(radi_s3_isotropic)} subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-17810",
   "metadata": {},
   "source": [
    "## 3. DataLoader Factory Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-46069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radiobject_loader(radi, patch_size=None, batch_size=None, num_workers=None):\n",
    "    ps = patch_size or PATCH_SIZE\n",
    "    bs = batch_size or BATCH_SIZE\n",
    "    nw = num_workers if num_workers is not None else NUM_WORKERS\n",
    "\n",
    "    collection = radi.collection(list(radi.collection_names)[0])\n",
    "    return create_training_dataloader(\n",
    "        collection,\n",
    "        batch_size=bs,\n",
    "        patch_size=ps,\n",
    "        num_workers=nw,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_monai_loader(paths, patch_size=None, batch_size=None, num_workers=None):\n",
    "    ps = patch_size or PATCH_SIZE\n",
    "    bs = batch_size or BATCH_SIZE\n",
    "    nw = num_workers if num_workers is not None else NUM_WORKERS\n",
    "\n",
    "    data_dicts = [{\"image\": str(p)} for p in paths]\n",
    "    transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\"]),\n",
    "            RandSpatialCropd(keys=[\"image\"], roi_size=ps, random_size=False),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = MonaiDataset(data=data_dicts, transform=transforms)\n",
    "    return MonaiDataLoader(dataset, batch_size=bs, num_workers=nw, shuffle=True)\n",
    "\n",
    "\n",
    "def create_torchio_loader(paths, patch_size=None, batch_size=None, num_workers=None):\n",
    "    ps = patch_size or PATCH_SIZE\n",
    "    bs = batch_size or BATCH_SIZE\n",
    "    nw = num_workers if num_workers is not None else NUM_WORKERS\n",
    "\n",
    "    subjects = [tio.Subject(image=tio.ScalarImage(str(p))) for p in paths]\n",
    "    transform = tio.Compose([tio.CropOrPad(ps)])\n",
    "    dataset = tio.SubjectsDataset(subjects, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=bs, num_workers=nw, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-78884",
   "metadata": {},
   "source": [
    "## 4. Throughput Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BENCHMARK: ML DataLoader Throughput\")\n",
    "print(f\"Config: batch_size={BATCH_SIZE}, patch_size={PATCH_SIZE}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# RadiObject Local\n",
    "loader = create_radiobject_loader(radi_local_isotropic)\n",
    "result = benchmark_dataloader(\n",
    "    loader,\n",
    "    \"RadiObject\",\n",
    "    \"dataloader\",\n",
    "    \"local\",\n",
    "    \"isotropic\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_warmup=N_WARMUP,\n",
    "    n_batches=N_BATCHES,\n",
    ")\n",
    "all_results.append(result)\n",
    "print(f\"RadiObject (local): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "print(f\"  Batch: {result.time_mean_ms:.1f} ms | Memory: {result.peak_heap_mb:.0f} MB\")\n",
    "del loader\n",
    "gc.collect()\n",
    "\n",
    "# RadiObject S3\n",
    "loader = create_radiobject_loader(radi_s3_isotropic)\n",
    "result = benchmark_dataloader(\n",
    "    loader,\n",
    "    \"RadiObject\",\n",
    "    \"dataloader\",\n",
    "    \"s3\",\n",
    "    \"isotropic\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_warmup=N_WARMUP,\n",
    "    n_batches=min(10, N_BATCHES),\n",
    ")\n",
    "all_results.append(result)\n",
    "print(f\"RadiObject (S3): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "print(f\"  Batch: {result.time_mean_ms:.1f} ms\")\n",
    "del loader\n",
    "gc.collect()\n",
    "\n",
    "# MONAI\n",
    "loader = create_monai_loader(nifti_gz_paths)\n",
    "result = benchmark_dataloader(\n",
    "    loader,\n",
    "    \"MONAI\",\n",
    "    \"dataloader\",\n",
    "    \"local\",\n",
    "    \"\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_warmup=N_WARMUP,\n",
    "    n_batches=N_BATCHES,\n",
    ")\n",
    "result.storage_format = \"nifti_gz\"\n",
    "all_results.append(result)\n",
    "print(f\"MONAI (local): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "print(f\"  Batch: {result.time_mean_ms:.1f} ms | Memory: {result.peak_heap_mb:.0f} MB\")\n",
    "del loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-41461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchIO\n",
    "loader = create_torchio_loader(nifti_gz_paths)\n",
    "gc.collect()\n",
    "tracemalloc.start()\n",
    "cpu_sampler = CPUSampler()\n",
    "cpu_sampler.start()\n",
    "\n",
    "loader_iter = iter(loader)\n",
    "cold_start = time.perf_counter()\n",
    "first_batch = next(loader_iter)\n",
    "_ = first_batch[\"image\"][tio.DATA].shape\n",
    "cold_start_time = (time.perf_counter() - cold_start) * 1000\n",
    "\n",
    "batch_times = []\n",
    "for _ in range(N_BATCHES):\n",
    "    try:\n",
    "        start = time.perf_counter()\n",
    "        batch = next(loader_iter)\n",
    "        _ = batch[\"image\"][tio.DATA].shape\n",
    "        batch_times.append((time.perf_counter() - start) * 1000)\n",
    "    except StopIteration:\n",
    "        loader_iter = iter(loader)\n",
    "        batch = next(loader_iter)\n",
    "\n",
    "cpu_mean, cpu_peak = cpu_sampler.stop()\n",
    "_, peak_heap = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "mean_batch = float(np.mean(batch_times)) if batch_times else 0.0\n",
    "throughput = (BATCH_SIZE / (mean_batch / 1000)) if mean_batch > 0 else 0.0\n",
    "\n",
    "result = BenchmarkResult(\n",
    "    framework=\"TorchIO\",\n",
    "    benchmark_name=\"dataloader\",\n",
    "    scenario=\"local\",\n",
    "    storage_format=\"nifti_gz\",\n",
    "    time_mean_ms=mean_batch,\n",
    "    time_std_ms=float(np.std(batch_times)) if batch_times else 0.0,\n",
    "    cold_start_ms=cold_start_time,\n",
    "    batch_times_ms=batch_times,\n",
    "    cpu_percent_mean=cpu_mean,\n",
    "    cpu_percent_peak=cpu_peak,\n",
    "    peak_heap_mb=peak_heap / (1024 * 1024),\n",
    "    throughput_samples_per_sec=throughput,\n",
    "    n_samples=len(batch_times) * BATCH_SIZE,\n",
    ")\n",
    "all_results.append(result)\n",
    "print(f\"TorchIO (local): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "print(f\"  Batch: {result.time_mean_ms:.1f} ms | Memory: {result.peak_heap_mb:.0f} MB\")\n",
    "del loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-55282",
   "metadata": {},
   "source": [
    "## 5. Results (Tidy Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-64156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy results table\n",
    "df = pd.DataFrame([r.to_dict() for r in all_results])\n",
    "cols = [\"framework\", \"scenario\", \"throughput_samples_per_sec\", \"time_mean_ms\", \"peak_heap_mb\"]\n",
    "df = df[[c for c in cols if c in df.columns]]\n",
    "df.columns = [\"framework\", \"scenario\", \"throughput\", \"batch_ms\", \"heap_mb\"][: len(df.columns)]\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-90620",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-66863",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Throughput comparison chart\n",
    "data = {f\"{r.framework} ({r.scenario})\": r.throughput_samples_per_sec for r in all_results}\n",
    "plot_bar_comparison(\n",
    "    data, \"DataLoader Throughput\", \"Samples/sec\", FIGURES_DIR / \"dataloader_throughput.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-61882",
   "metadata": {},
   "source": [
    "## 7. Key Findings\n",
    "\n",
    "1. **Throughput Advantage:** RadiObject typically 2-5x higher throughput\n",
    "2. **Patch-based Loading:** Eliminates full-volume I/O overhead\n",
    "3. **S3 Performance:** RadiObject S3 competitive with local MONAI/TorchIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-6840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from benchmarks.config import RESULTS_DIR\n",
    "\n",
    "results_json = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"experiment\": \"04_ml_dataloader_throughput\",\n",
    "    \"config\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"patch_size\": list(PATCH_SIZE) if isinstance(PATCH_SIZE, tuple) else PATCH_SIZE,\n",
    "        \"num_workers\": NUM_WORKERS,\n",
    "        \"n_batches\": N_BATCHES,\n",
    "    },\n",
    "    \"benchmarks\": [r.to_dict() for r in all_results],\n",
    "}\n",
    "\n",
    "output_path = RESULTS_DIR / \"04_ml_dataloader_results.json\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results_json, f, indent=2)\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiobject",
   "language": "python",
   "name": "radiobject"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}