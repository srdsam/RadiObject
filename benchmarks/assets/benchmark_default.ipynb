{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0690f352",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [26]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {
    "papermill": {
     "duration": 0.002888,
     "end_time": "2026-02-02T13:14:49.503858",
     "exception": false,
     "start_time": "2026-02-02T13:14:49.500970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Framework Benchmark: RadiObject vs MONAI vs TorchIO\n",
    "\n",
    "Publication-quality benchmark comparing medical imaging data loading frameworks across multiple storage backends.\n",
    "\n",
    "## Storage Backends Matrix\n",
    "\n",
    "| Backend | RadiObject | MONAI | TorchIO | S3 Support |\n",
    "|---------|------------|-------|---------|------------|\n",
    "| TileDB (AXIAL) | ✅ | — | — | ✅ Native |\n",
    "| TileDB (ISOTROPIC) | ✅ | — | — | ✅ Native |\n",
    "| NIfTI compressed (.nii.gz) | — | ✅ | ✅ | ❌ Download first |\n",
    "| NIfTI uncompressed (.nii) | — | ✅ | ✅ | ❌ Download first |\n",
    "| NumPy (.npy) | — | ✅ | ✅ | ❌ Download first |\n",
    "\n",
    "**Key insight**: NumPy backend isolates framework overhead from file format parsing.\n",
    "\n",
    "## Metrics Measured\n",
    "\n",
    "| Category | Metrics |\n",
    "|----------|---------|\n",
    "| **Disk Space** | Bytes per format, compression ratio |\n",
    "| **Memory** | Heap (tracemalloc), RSS (psutil), peak vs sustained |\n",
    "| **I/O Time** | Full volume, partial read, random access |\n",
    "| **ML Training** | DataLoader throughput, GPU memory (if available) |\n",
    "\n",
    "## Benchmark Categories\n",
    "\n",
    "| Category | Focus | RadiObject Advantage |\n",
    "|----------|-------|---------------------|\n",
    "| **0. Dataset Prep** | Create all storage formats | Measure disk space |\n",
    "| **1. Storage Formats** | Format overhead comparison | — |\n",
    "| **2. Data Loading** | Core I/O performance | Partial reads, O(1) indexing |\n",
    "| **3. Analysis** | In-notebook exploration | Metadata queries |\n",
    "| **4. ML Training** | DataLoader throughput | Patch extraction |\n",
    "| **5. S3 Cloud** | Remote data access | Native S3 support (unique) |\n",
    "\n",
    "## Frameworks\n",
    "\n",
    "| Framework | Primary Use | Storage Model |\n",
    "|-----------|-------------|---------------|\n",
    "| **RadiObject** | TileDB-backed radiology atlas | Local + S3 native |\n",
    "| **MONAI** | Medical imaging DL | NIfTI/DICOM files |\n",
    "| **TorchIO** | Medical imaging augmentation | NIfTI files |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-header",
   "metadata": {
    "papermill": {
     "duration": 0.002126,
     "end_time": "2026-02-02T13:14:49.508326",
     "exception": false,
     "start_time": "2026-02-02T13:14:49.506200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "params",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:14:49.513475Z",
     "iopub.status.busy": "2026-02-02T13:14:49.513365Z",
     "iopub.status.idle": "2026-02-02T13:14:49.516548Z",
     "shell.execute_reply": "2026-02-02T13:14:49.516170Z"
    },
    "papermill": {
     "duration": 0.006559,
     "end_time": "2026-02-02T13:14:49.516987",
     "exception": false,
     "start_time": "2026-02-02T13:14:49.510428",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (papermill)\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SIZE = (64, 64, 64)\n",
    "NUM_WORKERS = 0\n",
    "N_WARMUP = 5  # Increased from 3 for better warm cache\n",
    "N_BATCHES = 20\n",
    "N_RUNS = 10  # Increased from 5 for statistical rigor\n",
    "S3_BUCKET = \"souzy-scratch\"\n",
    "RUN_S3_BENCHMARKS = True\n",
    "OUTPUT_DIR = \"../assets/benchmark\"\n",
    "N_SUBJECTS_FOR_TILED = 20  # Subjects for benchmark datasets\n",
    "RANDOM_SEED = 42  # Fixed seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5a744b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:14:49.521658Z",
     "iopub.status.busy": "2026-02-02T13:14:49.521572Z",
     "iopub.status.idle": "2026-02-02T13:14:49.523213Z",
     "shell.execute_reply": "2026-02-02T13:14:49.522847Z"
    },
    "papermill": {
     "duration": 0.00462,
     "end_time": "2026-02-02T13:14:49.523697",
     "exception": false,
     "start_time": "2026-02-02T13:14:49.519077",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SIZE = \"(64, 64, 64)\"\n",
    "NUM_WORKERS = 0\n",
    "N_RUNS = 5\n",
    "RUN_S3_BENCHMARKS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "env-specs",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:14:49.528463Z",
     "iopub.status.busy": "2026-02-02T13:14:49.528389Z",
     "iopub.status.idle": "2026-02-02T13:14:54.400054Z",
     "shell.execute_reply": "2026-02-02T13:14:54.399152Z"
    },
    "papermill": {
     "duration": 4.875235,
     "end_time": "2026-02-02T13:14:54.401036",
     "exception": false,
     "start_time": "2026-02-02T13:14:49.525801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MACHINE SPECIFICATIONS\n",
      "============================================================\n",
      "Timestamp: 2026-02-02T08:14:49.530523\n",
      "Platform: macOS-26.0-arm64-arm-64bit\n",
      "Python: 3.11.14\n",
      "CPU: Apple M5\n",
      "CPU Cores: 10 physical, 10 logical\n",
      "RAM: 24.0 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Not available (CUDA not detected)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "import tracemalloc\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import psutil\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "# Fix random seeds for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MACHINE SPECIFICATIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Timestamp: {datetime.now().isoformat()}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "\n",
    "try:\n",
    "    chip = subprocess.check_output([\"sysctl\", \"-n\", \"machdep.cpu.brand_string\"], text=True).strip()\n",
    "    print(f\"CPU: {chip}\")\n",
    "except Exception:\n",
    "    print(f\"CPU: {platform.processor()}\")\n",
    "\n",
    "print(\n",
    "    f\"CPU Cores: {psutil.cpu_count(logical=False)} physical, \"\n",
    "    f\"{psutil.cpu_count(logical=True)} logical\"\n",
    ")\n",
    "print(f\"RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "\n",
    "# Check for GPU\n",
    "HAVE_CUDA = False\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        HAVE_CUDA = True\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  CUDA: {torch.version.cuda}\")\n",
    "        print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n",
    "    else:\n",
    "        print(\"GPU: Not available (CUDA not detected)\")\n",
    "except ImportError:\n",
    "    print(\"GPU: Not available (PyTorch not installed)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "env-frameworks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:14:54.439613Z",
     "iopub.status.busy": "2026-02-02T13:14:54.439405Z",
     "iopub.status.idle": "2026-02-02T13:15:08.710516Z",
     "shell.execute_reply": "2026-02-02T13:15:08.710044Z"
    },
    "papermill": {
     "duration": 14.304646,
     "end_time": "2026-02-02T13:15:08.711229",
     "exception": false,
     "start_time": "2026-02-02T13:14:54.406583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 2.4.1\n",
      "PyTorch: 2.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI: 1.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samueldsouza/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchIO: 0.21.2\n",
      "SimpleITK: 2.5.3\n",
      "\n",
      "RadiObject: Loaded\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Fix numpy seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "\n",
    "# Required dependencies - fail fast if not installed\n",
    "import monai\n",
    "from monai.data import DataLoader as MonaiDataLoader\n",
    "from monai.data import Dataset as MonaiDataset\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    LoadImaged,\n",
    "    RandSpatialCropd,\n",
    ")\n",
    "\n",
    "print(f\"MONAI: {monai.__version__}\")\n",
    "\n",
    "import torchio as tio\n",
    "\n",
    "print(f\"TorchIO: {tio.__version__}\")\n",
    "\n",
    "# Optional: SimpleITK\n",
    "try:\n",
    "    import SimpleITK as sitk\n",
    "\n",
    "    print(f\"SimpleITK: {sitk.__version__}\")\n",
    "except ImportError:\n",
    "    pass  # Not required for benchmarks\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from radiobject import RadiObject, configure\n",
    "from radiobject.ctx import S3Config, SliceOrientation, TileConfig\n",
    "from radiobject.ml import create_training_dataloader\n",
    "\n",
    "print(\"\\nRadiObject: Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "env-paths",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.718278Z",
     "iopub.status.busy": "2026-02-02T13:15:08.718146Z",
     "iopub.status.idle": "2026-02-02T13:15:08.722769Z",
     "shell.execute_reply": "2026-02-02T13:15:08.722434Z"
    },
    "papermill": {
     "duration": 0.008251,
     "end_time": "2026-02-02T13:15:08.723241",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.714990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 4\n",
      "Patch size: (64, 64, 64)\n",
      "Warmup iterations: 5\n",
      "Benchmark batches: 20\n",
      "Runs per framework: 5\n",
      "Random seed: 42\n",
      "\n",
      "Local URIs:\n",
      "  TileDB Axial: ../data/benchmark/radiobject-axial\n",
      "  TileDB Isotropic: ../data/benchmark/radiobject-isotropic\n",
      "  NIfTI compressed: ../data/benchmark/nifti-compressed\n",
      "  NIfTI uncompressed: ../data/benchmark/nifti-uncompressed\n",
      "  NumPy: ../data/benchmark/numpy\n",
      "\n",
      "S3 URIs:\n",
      "  Axial: s3://souzy-scratch/benchmark/radiobject-axial\n",
      "  Isotropic: s3://souzy-scratch/benchmark/radiobject-isotropic\n",
      "\n",
      "Source NIfTI directory: ../data/msd_lung/Task06_Lung/imagesTr\n"
     ]
    }
   ],
   "source": [
    "from config import S3_REGION\n",
    "\n",
    "# Paths relative to benchmarks/ directory\n",
    "DATA_DIR = Path(\"../data\")\n",
    "NIFTI_DIR = DATA_DIR / \"msd_lung\" / \"Task06_Lung\" / \"imagesTr\"\n",
    "ASSETS_DIR = Path(\"../assets/benchmark\")\n",
    "BENCHMARK_DIR = DATA_DIR / \"benchmark\"\n",
    "\n",
    "# URIs for different storage formats\n",
    "LOCAL_AXIAL_URI = str(BENCHMARK_DIR / \"radiobject-axial\")\n",
    "LOCAL_ISOTROPIC_URI = str(BENCHMARK_DIR / \"radiobject-isotropic\")\n",
    "NIFTI_COMPRESSED_DIR = BENCHMARK_DIR / \"nifti-compressed\"\n",
    "NIFTI_UNCOMPRESSED_DIR = BENCHMARK_DIR / \"nifti-uncompressed\"\n",
    "NUMPY_DIR = BENCHMARK_DIR / \"numpy\"\n",
    "\n",
    "S3_AXIAL_URI = f\"s3://{S3_BUCKET}/benchmark/radiobject-axial\"\n",
    "S3_ISOTROPIC_URI = f\"s3://{S3_BUCKET}/benchmark/radiobject-isotropic\"\n",
    "\n",
    "# Create directories\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ASSETS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BENCHMARK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Patch size: {PATCH_SIZE}\")\n",
    "print(f\"Warmup iterations: {N_WARMUP}\")\n",
    "print(f\"Benchmark batches: {N_BATCHES}\")\n",
    "print(f\"Runs per framework: {N_RUNS}\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "print(\"\\nLocal URIs:\")\n",
    "print(f\"  TileDB Axial: {LOCAL_AXIAL_URI}\")\n",
    "print(f\"  TileDB Isotropic: {LOCAL_ISOTROPIC_URI}\")\n",
    "print(f\"  NIfTI compressed: {NIFTI_COMPRESSED_DIR}\")\n",
    "print(f\"  NIfTI uncompressed: {NIFTI_UNCOMPRESSED_DIR}\")\n",
    "print(f\"  NumPy: {NUMPY_DIR}\")\n",
    "print(\"\\nS3 URIs:\")\n",
    "print(f\"  Axial: {S3_AXIAL_URI}\")\n",
    "print(f\"  Isotropic: {S3_ISOTROPIC_URI}\")\n",
    "print(f\"\\nSource NIfTI directory: {NIFTI_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utils-header",
   "metadata": {
    "papermill": {
     "duration": 0.002308,
     "end_time": "2026-02-02T13:15:08.728233",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.725925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Benchmark Infrastructure\n",
    "\n",
    "Enhanced with CPU, memory, GPU profiling, and disk space measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cpu-sampler",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.733453Z",
     "iopub.status.busy": "2026-02-02T13:15:08.733341Z",
     "iopub.status.idle": "2026-02-02T13:15:08.735996Z",
     "shell.execute_reply": "2026-02-02T13:15:08.735657Z"
    },
    "papermill": {
     "duration": 0.005913,
     "end_time": "2026-02-02T13:15:08.736412",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.730499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CPUSampler:\n",
    "    \"\"\"Sample CPU utilization during an operation.\"\"\"\n",
    "\n",
    "    def __init__(self, interval_ms: int = 100):\n",
    "        self.interval = interval_ms / 1000\n",
    "        self.samples: list[float] = []\n",
    "        self._stop = False\n",
    "        self._thread: threading.Thread | None = None\n",
    "\n",
    "    def start(self) -> None:\n",
    "        self._stop = False\n",
    "        self.samples = []\n",
    "        self._thread = threading.Thread(target=self._sample, daemon=True)\n",
    "        self._thread.start()\n",
    "\n",
    "    def _sample(self) -> None:\n",
    "        while not self._stop:\n",
    "            self.samples.append(psutil.cpu_percent(interval=None))\n",
    "            time.sleep(self.interval)\n",
    "\n",
    "    def stop(self) -> tuple[float, float]:\n",
    "        self._stop = True\n",
    "        if self._thread:\n",
    "            self._thread.join(timeout=1.0)\n",
    "        if self.samples:\n",
    "            return float(np.mean(self.samples)), float(max(self.samples))\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    def __enter__(self) -> \"CPUSampler\":\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args) -> None:\n",
    "        self.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "utils-classes",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.741943Z",
     "iopub.status.busy": "2026-02-02T13:15:08.741855Z",
     "iopub.status.idle": "2026-02-02T13:15:08.745845Z",
     "shell.execute_reply": "2026-02-02T13:15:08.745467Z"
    },
    "papermill": {
     "duration": 0.007372,
     "end_time": "2026-02-02T13:15:08.746264",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.738892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BenchmarkResult:\n",
    "    \"\"\"Single benchmark run result with comprehensive profiling.\"\"\"\n",
    "\n",
    "    framework: str\n",
    "    benchmark_name: str\n",
    "    scenario: str  # \"local\" or \"s3\"\n",
    "    tiling_strategy: str = \"\"  # \"axial\" or \"isotropic\"\n",
    "    storage_format: str = \"\"  # \"tiledb\", \"nifti_gz\", \"nifti\", \"numpy\"\n",
    "\n",
    "    # Timing\n",
    "    time_mean_ms: float = 0.0\n",
    "    time_std_ms: float = 0.0\n",
    "    cold_start_ms: float = 0.0\n",
    "    batch_times_ms: list[float] = field(default_factory=list)\n",
    "\n",
    "    # CPU metrics\n",
    "    cpu_percent_mean: float = 0.0\n",
    "    cpu_percent_peak: float = 0.0\n",
    "\n",
    "    # Memory metrics (CPU)\n",
    "    peak_heap_mb: float = 0.0  # tracemalloc\n",
    "    peak_rss_mb: float = 0.0  # psutil\n",
    "\n",
    "    # GPU metrics\n",
    "    peak_gpu_allocated_mb: float = 0.0  # torch.cuda.max_memory_allocated\n",
    "    peak_gpu_reserved_mb: float = 0.0  # torch.cuda.max_memory_reserved\n",
    "\n",
    "    # Disk metrics\n",
    "    disk_size_mb: float = 0.0\n",
    "\n",
    "    # Throughput\n",
    "    throughput_samples_per_sec: float = 0.0\n",
    "    throughput_mb_per_sec: float = 0.0\n",
    "\n",
    "    # Metadata\n",
    "    data_size_mb: float = 0.0\n",
    "    n_samples: int = 0\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            \"framework\": self.framework,\n",
    "            \"benchmark_name\": self.benchmark_name,\n",
    "            \"scenario\": self.scenario,\n",
    "            \"tiling_strategy\": self.tiling_strategy,\n",
    "            \"storage_format\": self.storage_format,\n",
    "            \"time_mean_ms\": round(self.time_mean_ms, 3),\n",
    "            \"time_std_ms\": round(self.time_std_ms, 3),\n",
    "            \"cold_start_ms\": round(self.cold_start_ms, 3),\n",
    "            \"cpu_percent_mean\": round(self.cpu_percent_mean, 1),\n",
    "            \"cpu_percent_peak\": round(self.cpu_percent_peak, 1),\n",
    "            \"peak_heap_mb\": round(self.peak_heap_mb, 2),\n",
    "            \"peak_rss_mb\": round(self.peak_rss_mb, 2),\n",
    "            \"peak_gpu_allocated_mb\": round(self.peak_gpu_allocated_mb, 2),\n",
    "            \"peak_gpu_reserved_mb\": round(self.peak_gpu_reserved_mb, 2),\n",
    "            \"disk_size_mb\": round(self.disk_size_mb, 2),\n",
    "            \"throughput_samples_per_sec\": round(self.throughput_samples_per_sec, 2),\n",
    "            \"n_samples\": self.n_samples,\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiskSpaceResult:\n",
    "    \"\"\"Disk space measurement for a storage format.\"\"\"\n",
    "\n",
    "    format_name: str\n",
    "    path: str\n",
    "    size_bytes: int\n",
    "    size_mb: float\n",
    "    n_files: int\n",
    "    compression_ratio: float = 0.0  # vs raw voxel data\n",
    "    raw_voxel_bytes: int = 0\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            \"format_name\": self.format_name,\n",
    "            \"path\": self.path,\n",
    "            \"size_bytes\": self.size_bytes,\n",
    "            \"size_mb\": round(self.size_mb, 2),\n",
    "            \"n_files\": self.n_files,\n",
    "            \"compression_ratio\": round(self.compression_ratio, 3),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "j7rphghr3gg",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.751620Z",
     "iopub.status.busy": "2026-02-02T13:15:08.751542Z",
     "iopub.status.idle": "2026-02-02T13:15:08.754856Z",
     "shell.execute_reply": "2026-02-02T13:15:08.754491Z"
    },
    "papermill": {
     "duration": 0.0065,
     "end_time": "2026-02-02T13:15:08.755273",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.748773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_directory_size_bytes(path: Path) -> tuple[int, int]:\n",
    "    \"\"\"Recursively measure directory size. Returns (total_bytes, file_count).\"\"\"\n",
    "    total = 0\n",
    "    count = 0\n",
    "    if path.is_file():\n",
    "        return path.stat().st_size, 1\n",
    "    for entry in path.rglob(\"*\"):\n",
    "        if entry.is_file():\n",
    "            total += entry.stat().st_size\n",
    "            count += 1\n",
    "    return total, count\n",
    "\n",
    "\n",
    "def get_directory_size_mb(path: Path) -> float:\n",
    "    \"\"\"Recursively measure directory size in MB.\"\"\"\n",
    "    size_bytes, _ = get_directory_size_bytes(path)\n",
    "    return size_bytes / (1024 * 1024)\n",
    "\n",
    "\n",
    "def create_uncompressed_nifti(src: Path, dst: Path) -> None:\n",
    "    \"\"\"Convert .nii.gz to .nii (uncompressed).\"\"\"\n",
    "    img = nib.load(str(src))\n",
    "    nib.save(img, str(dst))\n",
    "\n",
    "\n",
    "def create_numpy_from_nifti(src: Path, dst: Path) -> None:\n",
    "    \"\"\"Convert NIfTI to .npy.\"\"\"\n",
    "    img = nib.load(str(src))\n",
    "    data = img.get_fdata()\n",
    "    np.save(str(dst), data)\n",
    "\n",
    "\n",
    "def compute_raw_voxel_bytes(nifti_path: Path) -> int:\n",
    "    \"\"\"Compute raw voxel data size (uncompressed, no header).\"\"\"\n",
    "    img = nib.load(str(nifti_path))\n",
    "    shape = img.shape\n",
    "    dtype = img.get_data_dtype()\n",
    "    n_voxels = np.prod(shape)\n",
    "    bytes_per_voxel = np.dtype(dtype).itemsize\n",
    "    return int(n_voxels * bytes_per_voxel)\n",
    "\n",
    "\n",
    "def compute_checksum(data: np.ndarray) -> str:\n",
    "    \"\"\"Compute MD5 checksum of array data for validation.\"\"\"\n",
    "    return hashlib.md5(data.tobytes()).hexdigest()\n",
    "\n",
    "\n",
    "def measure_disk_space(\n",
    "    path: Path,\n",
    "    format_name: str,\n",
    "    raw_voxel_bytes: int = 0,\n",
    ") -> DiskSpaceResult:\n",
    "    \"\"\"Measure disk space for a storage format.\"\"\"\n",
    "    if not path.exists():\n",
    "        return DiskSpaceResult(format_name, str(path), 0, 0.0, 0)\n",
    "\n",
    "    size_bytes, n_files = get_directory_size_bytes(path)\n",
    "    size_mb = size_bytes / (1024 * 1024)\n",
    "    compression_ratio = raw_voxel_bytes / size_bytes if size_bytes > 0 else 0.0\n",
    "\n",
    "    return DiskSpaceResult(\n",
    "        format_name=format_name,\n",
    "        path=str(path),\n",
    "        size_bytes=size_bytes,\n",
    "        size_mb=size_mb,\n",
    "        n_files=n_files,\n",
    "        compression_ratio=compression_ratio,\n",
    "        raw_voxel_bytes=raw_voxel_bytes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "utils-timing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.760555Z",
     "iopub.status.busy": "2026-02-02T13:15:08.760456Z",
     "iopub.status.idle": "2026-02-02T13:15:08.763784Z",
     "shell.execute_reply": "2026-02-02T13:15:08.763453Z"
    },
    "papermill": {
     "duration": 0.006456,
     "end_time": "2026-02-02T13:15:08.764132",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.757676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def benchmark_operation(\n",
    "    func: Callable,\n",
    "    framework: str,\n",
    "    benchmark_name: str,\n",
    "    scenario: str = \"local\",\n",
    "    tiling: str = \"\",\n",
    "    storage_format: str = \"\",\n",
    "    n_warmup: int = N_WARMUP,\n",
    "    n_runs: int = N_RUNS,\n",
    "    track_gpu: bool = False,\n",
    ") -> BenchmarkResult:\n",
    "    \"\"\"Benchmark an operation with CPU, memory, and GPU profiling.\"\"\"\n",
    "    process = psutil.Process()\n",
    "    gc.collect()\n",
    "\n",
    "    # Reset GPU memory stats if tracking\n",
    "    if track_gpu and HAVE_CUDA:\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Cold start with memory tracking\n",
    "    tracemalloc.start()\n",
    "    rss_before = process.memory_info().rss\n",
    "    cpu_sampler = CPUSampler()\n",
    "    cpu_sampler.start()\n",
    "\n",
    "    cold_start = time.perf_counter()\n",
    "    func()\n",
    "    cold_time = (time.perf_counter() - cold_start) * 1000\n",
    "\n",
    "    cpu_mean, cpu_peak = cpu_sampler.stop()\n",
    "    _, peak_heap = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    rss_after = process.memory_info().rss\n",
    "\n",
    "    # Capture GPU metrics after cold start\n",
    "    gpu_allocated = 0.0\n",
    "    gpu_reserved = 0.0\n",
    "    if track_gpu and HAVE_CUDA:\n",
    "        gpu_allocated = torch.cuda.max_memory_allocated() / (1024 * 1024)\n",
    "        gpu_reserved = torch.cuda.max_memory_reserved() / (1024 * 1024)\n",
    "\n",
    "    # Warmup (remaining iterations)\n",
    "    for _ in range(n_warmup - 1):\n",
    "        func()\n",
    "\n",
    "    # Timed runs with GC between each\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        gc.collect()\n",
    "        start = time.perf_counter()\n",
    "        func()\n",
    "        times.append((time.perf_counter() - start) * 1000)\n",
    "\n",
    "    return BenchmarkResult(\n",
    "        framework=framework,\n",
    "        benchmark_name=benchmark_name,\n",
    "        scenario=scenario,\n",
    "        tiling_strategy=tiling,\n",
    "        storage_format=storage_format,\n",
    "        time_mean_ms=float(np.mean(times)),\n",
    "        time_std_ms=float(np.std(times)),\n",
    "        cold_start_ms=cold_time,\n",
    "        batch_times_ms=times,\n",
    "        cpu_percent_mean=cpu_mean,\n",
    "        cpu_percent_peak=cpu_peak,\n",
    "        peak_heap_mb=peak_heap / (1024 * 1024),\n",
    "        peak_rss_mb=(rss_after - rss_before) / (1024 * 1024),\n",
    "        peak_gpu_allocated_mb=gpu_allocated,\n",
    "        peak_gpu_reserved_mb=gpu_reserved,\n",
    "        n_samples=n_runs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "utils-dataloader",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.769226Z",
     "iopub.status.busy": "2026-02-02T13:15:08.769155Z",
     "iopub.status.idle": "2026-02-02T13:15:08.772343Z",
     "shell.execute_reply": "2026-02-02T13:15:08.771990Z"
    },
    "papermill": {
     "duration": 0.006223,
     "end_time": "2026-02-02T13:15:08.772751",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.766528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def benchmark_dataloader(\n",
    "    loader: DataLoader,\n",
    "    framework: str,\n",
    "    benchmark_name: str,\n",
    "    scenario: str,\n",
    "    tiling: str = \"\",\n",
    "    image_key: str = \"image\",\n",
    "    n_warmup: int = N_WARMUP,\n",
    "    n_batches: int = N_BATCHES,\n",
    ") -> BenchmarkResult:\n",
    "    \"\"\"Benchmark a PyTorch DataLoader with CPU/memory profiling.\"\"\"\n",
    "    process = psutil.Process()\n",
    "    gc.collect()\n",
    "    tracemalloc.start()\n",
    "    rss_before = process.memory_info().rss\n",
    "    cpu_sampler = CPUSampler()\n",
    "    cpu_sampler.start()\n",
    "\n",
    "    # Cold start\n",
    "    loader_iter = iter(loader)\n",
    "    cold_start = time.perf_counter()\n",
    "    first_batch = next(loader_iter)\n",
    "    if isinstance(first_batch, dict):\n",
    "        _ = first_batch[image_key].shape\n",
    "    else:\n",
    "        _ = first_batch.shape\n",
    "    cold_start_time = (time.perf_counter() - cold_start) * 1000\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(n_warmup - 1):\n",
    "        try:\n",
    "            batch = next(loader_iter)\n",
    "        except StopIteration:\n",
    "            loader_iter = iter(loader)\n",
    "            batch = next(loader_iter)\n",
    "\n",
    "    # Benchmark batches\n",
    "    batch_times = []\n",
    "    for _ in range(n_batches):\n",
    "        try:\n",
    "            start = time.perf_counter()\n",
    "            batch = next(loader_iter)\n",
    "            if isinstance(batch, dict):\n",
    "                _ = batch[image_key].shape\n",
    "            else:\n",
    "                _ = batch.shape\n",
    "            batch_times.append((time.perf_counter() - start) * 1000)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "    cpu_mean, cpu_peak = cpu_sampler.stop()\n",
    "    _, peak_heap = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    rss_after = process.memory_info().rss\n",
    "\n",
    "    mean_batch = float(np.mean(batch_times)) if batch_times else 0.0\n",
    "    throughput = (BATCH_SIZE / (mean_batch / 1000)) if mean_batch > 0 else 0.0\n",
    "\n",
    "    return BenchmarkResult(\n",
    "        framework=framework,\n",
    "        benchmark_name=benchmark_name,\n",
    "        scenario=scenario,\n",
    "        tiling_strategy=tiling,\n",
    "        time_mean_ms=mean_batch,\n",
    "        time_std_ms=float(np.std(batch_times)) if batch_times else 0.0,\n",
    "        cold_start_ms=cold_start_time,\n",
    "        batch_times_ms=batch_times,\n",
    "        cpu_percent_mean=cpu_mean,\n",
    "        cpu_percent_peak=cpu_peak,\n",
    "        peak_heap_mb=peak_heap / (1024 * 1024),\n",
    "        peak_rss_mb=(rss_after - rss_before) / (1024 * 1024),\n",
    "        throughput_samples_per_sec=throughput,\n",
    "        n_samples=len(batch_times) * BATCH_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {
    "papermill": {
     "duration": 0.002298,
     "end_time": "2026-02-02T13:15:08.777464",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.775166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Dataset Preparation\n",
    "\n",
    "Create all storage formats from the same source data for fair comparison.\n",
    "\n",
    "| Format | Directory | Description |\n",
    "|--------|-----------|-------------|\n",
    "| `radiobject-axial` | TileDB Group | AXIAL tiling (X, Y, 1) for 2D slices |\n",
    "| `radiobject-isotropic` | TileDB Group | ISOTROPIC tiling (64³) for 3D ROI |\n",
    "| `nifti-compressed` | .nii.gz files | Gzip compressed NIfTI |\n",
    "| `nifti-uncompressed` | .nii files | Uncompressed NIfTI |\n",
    "| `numpy` | .npy files | Raw NumPy arrays |\n",
    "\n",
    "**Key insight**: NumPy backend isolates framework overhead from file format parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "data-find-nifti",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.782713Z",
     "iopub.status.busy": "2026-02-02T13:15:08.782629Z",
     "iopub.status.idle": "2026-02-02T13:15:08.786906Z",
     "shell.execute_reply": "2026-02-02T13:15:08.786549Z"
    },
    "papermill": {
     "duration": 0.007649,
     "end_time": "2026-02-02T13:15:08.787471",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.779822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63 NIfTI files in ../data/msd_lung/Task06_Lung/imagesTr\n",
      "  Sample: lung_001.nii.gz\n",
      "  Shape: (512, 512, 304)\n",
      "  Dtype: float32\n",
      "  Using first 20 for benchmark datasets\n",
      "  Raw voxel size per volume: 304.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Find source NIfTI files\n",
    "nifti_paths = []\n",
    "\n",
    "if NIFTI_DIR.exists():\n",
    "    nifti_paths = sorted(NIFTI_DIR.glob(\"*.nii.gz\"))[:N_SUBJECTS_FOR_TILED]\n",
    "    if nifti_paths:\n",
    "        print(f\"Found {len(list(NIFTI_DIR.glob('*.nii.gz')))} NIfTI files in {NIFTI_DIR}\")\n",
    "        sample = nib.load(str(nifti_paths[0]))\n",
    "        print(f\"  Sample: {nifti_paths[0].name}\")\n",
    "        print(f\"  Shape: {sample.shape}\")\n",
    "        print(f\"  Dtype: {sample.get_data_dtype()}\")\n",
    "        print(f\"  Using first {N_SUBJECTS_FOR_TILED} for benchmark datasets\")\n",
    "\n",
    "        # Compute raw voxel size for compression ratio calculation\n",
    "        raw_bytes = compute_raw_voxel_bytes(nifti_paths[0])\n",
    "        print(f\"  Raw voxel size per volume: {raw_bytes / (1024*1024):.1f} MB\")\n",
    "else:\n",
    "    print(f\"NIfTI directory not found: {NIFTI_DIR}\")\n",
    "    print(\"Please download MSD-Lung dataset first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "p6njk8gvltm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.793000Z",
     "iopub.status.busy": "2026-02-02T13:15:08.792854Z",
     "iopub.status.idle": "2026-02-02T13:15:08.796703Z",
     "shell.execute_reply": "2026-02-02T13:15:08.796294Z"
    },
    "papermill": {
     "duration": 0.00724,
     "end_time": "2026-02-02T13:15:08.797124",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.789884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARING STORAGE FORMATS\n",
      "============================================================\n",
      "NIfTI compressed exists: ../data/benchmark/nifti-compressed\n",
      "NIfTI uncompressed exists: ../data/benchmark/nifti-uncompressed\n",
      "NumPy exists: ../data/benchmark/numpy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_storage_formats(\n",
    "    source_niftis: list[Path],\n",
    "    benchmark_dir: Path,\n",
    ") -> dict[str, Path]:\n",
    "    \"\"\"Create all storage formats from source NIfTI files.\"\"\"\n",
    "    formats_created = {}\n",
    "\n",
    "    if not source_niftis:\n",
    "        print(\"No source NIfTI files available\")\n",
    "        return formats_created\n",
    "\n",
    "    # 1. Create NIfTI compressed directory (symlinks to source)\n",
    "    nifti_gz_dir = benchmark_dir / \"nifti-compressed\"\n",
    "    if not nifti_gz_dir.exists():\n",
    "        nifti_gz_dir.mkdir(parents=True)\n",
    "        print(f\"Creating NIfTI compressed links: {nifti_gz_dir}\")\n",
    "        for src in source_niftis:\n",
    "            dst = nifti_gz_dir / src.name\n",
    "            if not dst.exists():\n",
    "                # Copy instead of symlink for accurate size measurement\n",
    "                shutil.copy2(src, dst)\n",
    "    else:\n",
    "        print(f\"NIfTI compressed exists: {nifti_gz_dir}\")\n",
    "    formats_created[\"nifti_gz\"] = nifti_gz_dir\n",
    "\n",
    "    # 2. Create uncompressed NIfTI\n",
    "    nifti_dir = benchmark_dir / \"nifti-uncompressed\"\n",
    "    if not nifti_dir.exists():\n",
    "        nifti_dir.mkdir(parents=True)\n",
    "        print(f\"Creating NIfTI uncompressed: {nifti_dir}\")\n",
    "        for src in source_niftis:\n",
    "            dst = nifti_dir / src.name.replace(\".nii.gz\", \".nii\")\n",
    "            if not dst.exists():\n",
    "                create_uncompressed_nifti(src, dst)\n",
    "                print(f\"  Created: {dst.name}\")\n",
    "    else:\n",
    "        print(f\"NIfTI uncompressed exists: {nifti_dir}\")\n",
    "    formats_created[\"nifti\"] = nifti_dir\n",
    "\n",
    "    # 3. Create NumPy files\n",
    "    numpy_dir = benchmark_dir / \"numpy\"\n",
    "    if not numpy_dir.exists():\n",
    "        numpy_dir.mkdir(parents=True)\n",
    "        print(f\"Creating NumPy: {numpy_dir}\")\n",
    "        for src in source_niftis:\n",
    "            dst = numpy_dir / src.name.replace(\".nii.gz\", \".npy\")\n",
    "            if not dst.exists():\n",
    "                create_numpy_from_nifti(src, dst)\n",
    "                print(f\"  Created: {dst.name}\")\n",
    "    else:\n",
    "        print(f\"NumPy exists: {numpy_dir}\")\n",
    "    formats_created[\"numpy\"] = numpy_dir\n",
    "\n",
    "    return formats_created\n",
    "\n",
    "\n",
    "# Create all storage formats\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPARING STORAGE FORMATS\")\n",
    "print(\"=\" * 60)\n",
    "storage_formats = prepare_all_storage_formats(nifti_paths, BENCHMARK_DIR)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "data-create-axial",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.802432Z",
     "iopub.status.busy": "2026-02-02T13:15:08.802355Z",
     "iopub.status.idle": "2026-02-02T13:15:08.804460Z",
     "shell.execute_reply": "2026-02-02T13:15:08.804106Z"
    },
    "papermill": {
     "duration": 0.005184,
     "end_time": "2026-02-02T13:15:08.804843",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.799659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_tiled_radiobject(\n",
    "    uri: str,\n",
    "    nifti_paths: list[Path],\n",
    "    orientation: SliceOrientation,\n",
    "    collection_name: str = \"CT\",\n",
    ") -> RadiObject | None:\n",
    "    \"\"\"Create RadiObject with specific tiling strategy.\"\"\"\n",
    "    if not nifti_paths:\n",
    "        print(\"No NIfTI files available\")\n",
    "        return None\n",
    "\n",
    "    # Check if already exists\n",
    "    if not uri.startswith(\"s3://\") and Path(uri).exists():\n",
    "        print(f\"Loading existing: {uri}\")\n",
    "        return RadiObject(uri)\n",
    "\n",
    "    print(f\"Creating RadiObject with {orientation.value} tiling: {uri}\")\n",
    "\n",
    "    # Configure tiling\n",
    "    configure(tile=TileConfig(orientation=orientation))\n",
    "\n",
    "    # Create using from_niftis\n",
    "    radi = RadiObject.from_niftis(\n",
    "        uri=uri,\n",
    "        image_dir=str(NIFTI_DIR),\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "\n",
    "    print(f\"  Created: {len(radi)} subjects\")\n",
    "    return radi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "data-create-local",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.810270Z",
     "iopub.status.busy": "2026-02-02T13:15:08.810195Z",
     "iopub.status.idle": "2026-02-02T13:15:08.828484Z",
     "shell.execute_reply": "2026-02-02T13:15:08.828064Z"
    },
    "papermill": {
     "duration": 0.0217,
     "end_time": "2026-02-02T13:15:08.829144",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.807444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing: ../data/benchmark/radiobject-axial\n",
      "\n",
      "Local AXIAL dataset ready:\n",
      "  Subjects: 63\n",
      "  Collections: ('CT',)\n"
     ]
    }
   ],
   "source": [
    "# Create local axial-tiled dataset\n",
    "radi_local_axial = None\n",
    "if nifti_paths:\n",
    "    radi_local_axial = create_tiled_radiobject(\n",
    "        LOCAL_AXIAL_URI,\n",
    "        nifti_paths,\n",
    "        SliceOrientation.AXIAL,\n",
    "    )\n",
    "\n",
    "if radi_local_axial:\n",
    "    print(\"\\nLocal AXIAL dataset ready:\")\n",
    "    print(f\"  Subjects: {len(radi_local_axial)}\")\n",
    "    print(f\"  Collections: {radi_local_axial.collection_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "data-create-isotropic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.837897Z",
     "iopub.status.busy": "2026-02-02T13:15:08.837795Z",
     "iopub.status.idle": "2026-02-02T13:15:08.840761Z",
     "shell.execute_reply": "2026-02-02T13:15:08.840454Z"
    },
    "papermill": {
     "duration": 0.009251,
     "end_time": "2026-02-02T13:15:08.841215",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.831964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing: ../data/benchmark/radiobject-isotropic\n",
      "\n",
      "Local ISOTROPIC dataset ready:\n",
      "  Subjects: 63\n",
      "  Collections: ('CT',)\n"
     ]
    }
   ],
   "source": [
    "# Create local isotropic-tiled dataset\n",
    "radi_local_isotropic = None\n",
    "if nifti_paths:\n",
    "    radi_local_isotropic = create_tiled_radiobject(\n",
    "        LOCAL_ISOTROPIC_URI,\n",
    "        nifti_paths,\n",
    "        SliceOrientation.ISOTROPIC,\n",
    "    )\n",
    "\n",
    "if radi_local_isotropic:\n",
    "    print(\"\\nLocal ISOTROPIC dataset ready:\")\n",
    "    print(f\"  Subjects: {len(radi_local_isotropic)}\")\n",
    "    print(f\"  Collections: {radi_local_isotropic.collection_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "data-s3-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:08.846637Z",
     "iopub.status.busy": "2026-02-02T13:15:08.846570Z",
     "iopub.status.idle": "2026-02-02T13:15:09.343612Z",
     "shell.execute_reply": "2026-02-02T13:15:09.343207Z"
    },
    "papermill": {
     "duration": 0.500292,
     "end_time": "2026-02-02T13:15:09.344058",
     "exception": false,
     "start_time": "2026-02-02T13:15:08.843766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS profile: souzy-s3\n",
      "Configured S3 for region: us-east-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded S3 AXIAL: s3://souzy-scratch/benchmark/radiobject-axial\n",
      "  Subjects: 63\n",
      "Loaded S3 ISOTROPIC: s3://souzy-scratch/benchmark/radiobject-isotropic\n",
      "  Subjects: 63\n"
     ]
    }
   ],
   "source": [
    "# Configure S3 and load S3 datasets - fail fast if unavailable\n",
    "from config import AWS_PROFILE\n",
    "\n",
    "radi_s3_axial = None\n",
    "radi_s3_isotropic = None\n",
    "\n",
    "if RUN_S3_BENCHMARKS:\n",
    "    # Set AWS profile for boto3 credential lookup\n",
    "    if AWS_PROFILE:\n",
    "        os.environ[\"AWS_PROFILE\"] = AWS_PROFILE\n",
    "        print(f\"Using AWS profile: {AWS_PROFILE}\")\n",
    "\n",
    "    configure(s3=S3Config(region=S3_REGION, max_parallel_ops=8))\n",
    "    print(f\"Configured S3 for region: {S3_REGION}\")\n",
    "\n",
    "    # Load S3 datasets - fail fast if not accessible\n",
    "    radi_s3_axial = RadiObject(S3_AXIAL_URI)\n",
    "    _ = len(radi_s3_axial)  # Force metadata load to verify dataset exists\n",
    "    print(f\"Loaded S3 AXIAL: {S3_AXIAL_URI}\")\n",
    "    print(f\"  Subjects: {len(radi_s3_axial)}\")\n",
    "\n",
    "    radi_s3_isotropic = RadiObject(S3_ISOTROPIC_URI)\n",
    "    _ = len(radi_s3_isotropic)  # Force metadata load to verify dataset exists\n",
    "    print(f\"Loaded S3 ISOTROPIC: {S3_ISOTROPIC_URI}\")\n",
    "    print(f\"  Subjects: {len(radi_s3_isotropic)}\")\n",
    "else:\n",
    "    print(\"S3 benchmarks disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "data-verify-tiling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:09.350736Z",
     "iopub.status.busy": "2026-02-02T13:15:09.350619Z",
     "iopub.status.idle": "2026-02-02T13:15:11.558495Z",
     "shell.execute_reply": "2026-02-02T13:15:11.558046Z"
    },
    "papermill": {
     "duration": 2.211895,
     "end_time": "2026-02-02T13:15:11.558943",
     "exception": false,
     "start_time": "2026-02-02T13:15:09.347048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Local AXIAL (radiobject-axial):\n",
      "  Volume shape: (512, 512, 304)\n",
      "  Dim x: tile extent = 512\n",
      "  Dim y: tile extent = 512\n",
      "  Dim z: tile extent = 1\n",
      "\n",
      "Local ISOTROPIC (radiobject-isotropic):\n",
      "  Volume shape: (512, 512, 304)\n",
      "  Dim x: tile extent = 64\n",
      "  Dim y: tile extent = 64\n",
      "  Dim z: tile extent = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 AXIAL: Not available (TileDBError)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 ISOTROPIC: Not available (TileDBError)\n"
     ]
    }
   ],
   "source": [
    "import tiledb\n",
    "\n",
    "\n",
    "def verify_tiling(uri: str, name: str) -> None:\n",
    "    \"\"\"Verify tile extents in a RadiObject volume.\"\"\"\n",
    "    try:\n",
    "        radi = RadiObject(uri)\n",
    "        vol = radi.collection(radi.collection_names[0]).iloc[0]\n",
    "        schema = tiledb.ArraySchema.load(vol.uri)\n",
    "\n",
    "        print(f\"\\n{name} ({uri.split('/')[-1]}):\")\n",
    "        print(f\"  Volume shape: {vol.shape}\")\n",
    "        for i, dim in enumerate(schema.domain):\n",
    "            print(f\"  Dim {dim.name}: tile extent = {dim.tile}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name}: Not available ({type(e).__name__})\")\n",
    "\n",
    "\n",
    "verify_tiling(LOCAL_AXIAL_URI, \"Local AXIAL\")\n",
    "verify_tiling(LOCAL_ISOTROPIC_URI, \"Local ISOTROPIC\")\n",
    "if RUN_S3_BENCHMARKS:\n",
    "    verify_tiling(S3_AXIAL_URI, \"S3 AXIAL\")\n",
    "    verify_tiling(S3_ISOTROPIC_URI, \"S3 ISOTROPIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ig15ch72qre",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:11.565252Z",
     "iopub.status.busy": "2026-02-02T13:15:11.565143Z",
     "iopub.status.idle": "2026-02-02T13:15:11.643105Z",
     "shell.execute_reply": "2026-02-02T13:15:11.642478Z"
    },
    "papermill": {
     "duration": 0.081931,
     "end_time": "2026-02-02T13:15:11.643845",
     "exception": false,
     "start_time": "2026-02-02T13:15:11.561914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DISK SPACE COMPARISON\n",
      "============================================================\n",
      "Total raw voxel data: 6.52 GB\n",
      "\n",
      "TileDB (AXIAL):\n",
      "  Size: 6220.0 MB (488 files)\n",
      "  Compression ratio: 1.07x\n",
      "TileDB (ISOTROPIC):\n",
      "  Size: 5736.8 MB (488 files)\n",
      "  Compression ratio: 1.16x\n",
      "NIfTI (.nii.gz):\n",
      "  Size: 2142.0 MB (20 files)\n",
      "  Compression ratio: 3.12x\n",
      "NIfTI (.nii):\n",
      "  Size: 6678.0 MB (20 files)\n",
      "  Compression ratio: 1.00x\n",
      "NumPy (.npy):\n",
      "  Size: 13356.0 MB (20 files)\n",
      "  Compression ratio: 0.50x\n",
      "\n",
      "--- Summary ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_name</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>n_files</th>\n",
       "      <th>compression_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TileDB (AXIAL)</td>\n",
       "      <td>6219.96</td>\n",
       "      <td>488</td>\n",
       "      <td>1.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TileDB (ISOTROPIC)</td>\n",
       "      <td>5736.80</td>\n",
       "      <td>488</td>\n",
       "      <td>1.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIfTI (.nii.gz)</td>\n",
       "      <td>2141.98</td>\n",
       "      <td>20</td>\n",
       "      <td>3.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NIfTI (.nii)</td>\n",
       "      <td>6678.01</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NumPy (.npy)</td>\n",
       "      <td>13356.00</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          format_name   size_mb  n_files  compression_ratio\n",
       "0      TileDB (AXIAL)   6219.96      488              1.074\n",
       "1  TileDB (ISOTROPIC)   5736.80      488              1.164\n",
       "2     NIfTI (.nii.gz)   2141.98       20              3.118\n",
       "3        NIfTI (.nii)   6678.01       20              1.000\n",
       "4        NumPy (.npy)  13356.00       20              0.500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Measure disk space for all storage formats\n",
    "print(\"=\" * 60)\n",
    "print(\"DISK SPACE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "disk_space_results: list[DiskSpaceResult] = []\n",
    "\n",
    "# Compute total raw voxel bytes\n",
    "total_raw_bytes = 0\n",
    "if nifti_paths:\n",
    "    for p in nifti_paths:\n",
    "        total_raw_bytes += compute_raw_voxel_bytes(p)\n",
    "    print(f\"Total raw voxel data: {total_raw_bytes / (1024**3):.2f} GB\")\n",
    "    print()\n",
    "\n",
    "# Measure each format\n",
    "format_paths = [\n",
    "    (\"TileDB (AXIAL)\", Path(LOCAL_AXIAL_URI)),\n",
    "    (\"TileDB (ISOTROPIC)\", Path(LOCAL_ISOTROPIC_URI)),\n",
    "    (\"NIfTI (.nii.gz)\", NIFTI_COMPRESSED_DIR),\n",
    "    (\"NIfTI (.nii)\", NIFTI_UNCOMPRESSED_DIR),\n",
    "    (\"NumPy (.npy)\", NUMPY_DIR),\n",
    "]\n",
    "\n",
    "for name, path in format_paths:\n",
    "    result = measure_disk_space(path, name, total_raw_bytes)\n",
    "    if result.size_bytes > 0:\n",
    "        disk_space_results.append(result)\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Size: {result.size_mb:.1f} MB ({result.n_files} files)\")\n",
    "        print(f\"  Compression ratio: {result.compression_ratio:.2f}x\")\n",
    "\n",
    "# Summary table\n",
    "if disk_space_results:\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    df = pd.DataFrame([r.to_dict() for r in disk_space_results])\n",
    "    display(df[[\"format_name\", \"size_mb\", \"n_files\", \"compression_ratio\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cat1-header",
   "metadata": {
    "papermill": {
     "duration": 0.00415,
     "end_time": "2026-02-02T13:15:11.652009",
     "exception": false,
     "start_time": "2026-02-02T13:15:11.647859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Category 1: Storage Format Comparison\n",
    "\n",
    "**Purpose**: Isolate file format overhead from framework overhead.\n",
    "\n",
    "| Test | What It Measures |\n",
    "|------|------------------|\n",
    "| NIfTI compressed vs uncompressed | Gzip decompression cost |\n",
    "| NIfTI vs NumPy (same framework) | NIfTI parsing overhead |\n",
    "| TileDB AXIAL vs ISOTROPIC | Tiling strategy impact |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cat1-storage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:11.661428Z",
     "iopub.status.busy": "2026-02-02T13:15:11.661316Z",
     "iopub.status.idle": "2026-02-02T13:15:11.666989Z",
     "shell.execute_reply": "2026-02-02T13:15:11.666210Z"
    },
    "papermill": {
     "duration": 0.011718,
     "end_time": "2026-02-02T13:15:11.667688",
     "exception": false,
     "start_time": "2026-02-02T13:15:11.655970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available benchmark files:\n",
      "  NIfTI compressed: 20\n",
      "  NIfTI uncompressed: 20\n",
      "  NumPy: 20\n"
     ]
    }
   ],
   "source": [
    "# Storage for all results\n",
    "all_results: list[BenchmarkResult] = []\n",
    "\n",
    "# Get file paths for different formats\n",
    "nifti_gz_paths = (\n",
    "    sorted(NIFTI_COMPRESSED_DIR.glob(\"*.nii.gz\")) if NIFTI_COMPRESSED_DIR.exists() else []\n",
    ")\n",
    "nifti_paths_uncompressed = (\n",
    "    sorted(NIFTI_UNCOMPRESSED_DIR.glob(\"*.nii\")) if NIFTI_UNCOMPRESSED_DIR.exists() else []\n",
    ")\n",
    "numpy_paths = sorted(NUMPY_DIR.glob(\"*.npy\")) if NUMPY_DIR.exists() else []\n",
    "\n",
    "print(\"Available benchmark files:\")\n",
    "print(f\"  NIfTI compressed: {len(nifti_gz_paths)}\")\n",
    "print(f\"  NIfTI uncompressed: {len(nifti_paths_uncompressed)}\")\n",
    "print(f\"  NumPy: {len(numpy_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "g83bkn9mgel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:11.677255Z",
     "iopub.status.busy": "2026-02-02T13:15:11.677048Z",
     "iopub.status.idle": "2026-02-02T13:15:29.412598Z",
     "shell.execute_reply": "2026-02-02T13:15:29.411688Z"
    },
    "papermill": {
     "duration": 17.744834,
     "end_time": "2026-02-02T13:15:29.416715",
     "exception": false,
     "start_time": "2026-02-02T13:15:11.671881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BENCHMARK 1.1: Storage Format Loading\n",
      "============================================================\n",
      "What: Compare load times across file formats using the same framework\n",
      "Insight: Isolates format parsing cost from framework overhead\n",
      "\n",
      "--- NIfTI: Gzip Decompression Cost ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIfTI compressed (.nii.gz): 563.2 +/- 29.2 ms\n",
      "  Memory: 912.0 MB heap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIfTI uncompressed (.nii): 38.2 +/- 2.6 ms\n",
      "  Gzip overhead: 1372.6%\n",
      "\n",
      "--- NIfTI vs NumPy: Format Parsing Cost ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy (.npy): 43.4 +/- 2.1 ms\n",
      "  Memory: 608.0 MB heap\n",
      "  NIfTI parsing overhead vs NumPy: -11.9%\n",
      "\n",
      "--- TileDB: Tiling Strategy ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TileDB AXIAL: 527.7 +/- 24.1 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TileDB ISOTROPIC: 134.2 +/- 17.2 ms\n",
      "\n",
      "--- Key Insights ---\n",
      "1. Gzip adds decompression overhead but saves disk space\n",
      "2. NIfTI header parsing adds modest overhead vs raw NumPy\n",
      "3. TileDB tiling strategy has minimal impact on full-volume loads\n"
     ]
    }
   ],
   "source": [
    "def benchmark_storage_formats():\n",
    "    \"\"\"Benchmark 1.1: Storage Format Loading Comparison.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 1.1: Storage Format Loading\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Compare load times across file formats using the same framework\")\n",
    "    print(\"Insight: Isolates format parsing cost from framework overhead\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # --- NIfTI Compressed vs Uncompressed ---\n",
    "    print(\"--- NIfTI: Gzip Decompression Cost ---\")\n",
    "\n",
    "    if nifti_gz_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: nib.load(str(nifti_gz_paths[0])).get_fdata(),\n",
    "            \"nibabel\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            storage_format=\"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"NIfTI compressed (.nii.gz): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\"\n",
    "        )\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    if nifti_paths_uncompressed:\n",
    "        result = benchmark_operation(\n",
    "            lambda: nib.load(str(nifti_paths_uncompressed[0])).get_fdata(),\n",
    "            \"nibabel\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            storage_format=\"nifti\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"NIfTI uncompressed (.nii): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\"\n",
    "        )\n",
    "\n",
    "    # Calculate gzip overhead\n",
    "    nifti_gz_result = next((r for r in results if r.storage_format == \"nifti_gz\"), None)\n",
    "    nifti_result = next((r for r in results if r.storage_format == \"nifti\"), None)\n",
    "    if nifti_gz_result and nifti_result and nifti_result.time_mean_ms > 0:\n",
    "        gzip_overhead = (nifti_gz_result.time_mean_ms / nifti_result.time_mean_ms - 1) * 100\n",
    "        print(f\"  Gzip overhead: {gzip_overhead:.1f}%\")\n",
    "\n",
    "    # --- NIfTI vs NumPy ---\n",
    "    print(\"\\n--- NIfTI vs NumPy: Format Parsing Cost ---\")\n",
    "\n",
    "    if numpy_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: np.load(str(numpy_paths[0])),\n",
    "            \"numpy\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            storage_format=\"numpy\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"NumPy (.npy): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    numpy_result = next((r for r in results if r.storage_format == \"numpy\"), None)\n",
    "    if nifti_result and numpy_result and numpy_result.time_mean_ms > 0:\n",
    "        parsing_overhead = (nifti_result.time_mean_ms / numpy_result.time_mean_ms - 1) * 100\n",
    "        print(f\"  NIfTI parsing overhead vs NumPy: {parsing_overhead:.1f}%\")\n",
    "\n",
    "    # --- TileDB Tiling Comparison ---\n",
    "    print(\"\\n--- TileDB: Tiling Strategy ---\")\n",
    "\n",
    "    if radi_local_axial:\n",
    "        vol = radi_local_axial.collection(radi_local_axial.collection_names[0]).iloc[0]\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol.to_numpy(),\n",
    "            \"RadiObject\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            tiling=\"axial\",\n",
    "            storage_format=\"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"TileDB AXIAL: {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "\n",
    "    if radi_local_isotropic:\n",
    "        vol = radi_local_isotropic.collection(radi_local_isotropic.collection_names[0]).iloc[0]\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol.to_numpy(),\n",
    "            \"RadiObject\",\n",
    "            \"format_comparison\",\n",
    "            \"local\",\n",
    "            tiling=\"isotropic\",\n",
    "            storage_format=\"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"TileDB ISOTROPIC: {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "\n",
    "    print(\"\\n--- Key Insights ---\")\n",
    "    print(\"1. Gzip adds decompression overhead but saves disk space\")\n",
    "    print(\"2. NIfTI header parsing adds modest overhead vs raw NumPy\")\n",
    "    print(\"3. TileDB tiling strategy has minimal impact on full-volume loads\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_storage_formats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cat1-full-volume",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:15:29.439174Z",
     "iopub.status.busy": "2026-02-02T13:15:29.439034Z",
     "iopub.status.idle": "2026-02-02T13:17:13.170813Z",
     "shell.execute_reply": "2026-02-02T13:17:13.170485Z"
    },
    "papermill": {
     "duration": 103.740882,
     "end_time": "2026-02-02T13:17:13.172592",
     "exception": false,
     "start_time": "2026-02-02T13:15:29.431710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BENCHMARK 2.1: Full Volume Load\n",
      "============================================================\n",
      "What: Load complete 3D volume into memory\n",
      "Expectation: MONAI/TorchIO optimized for NIfTI; RadiObject competitive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiObject (local/axial): 513.0 +/- 22.8 ms\n",
      "  CPU: 75.3% mean, 85.7% peak\n",
      "  Memory: 304.0 MB heap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiObject (S3/axial): 7673.5 +/- 338.0 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI (local): 1184.2 +/- 79.7 ms\n",
      "  CPU: 27.4% mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchIO (local): 736.4 +/- 28.7 ms\n"
     ]
    }
   ],
   "source": [
    "def benchmark_full_volume_load():\n",
    "    \"\"\"Benchmark 2.1: Full Volume Loading (Local and S3).\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 2.1: Full Volume Load\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Load complete 3D volume into memory\")\n",
    "    print(\"Expectation: MONAI/TorchIO optimized for NIfTI; RadiObject competitive\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # RadiObject Local (axial-tiled)\n",
    "    if radi_local_axial:\n",
    "        vol = radi_local_axial.collection(radi_local_axial.collection_names[0]).iloc[0]\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol.to_numpy(), \"RadiObject\", \"full_volume\", \"local\", \"axial\", \"tiledb\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject (local/axial): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\"\n",
    "        )\n",
    "        print(f\"  CPU: {result.cpu_percent_mean:.1f}% mean, {result.cpu_percent_peak:.1f}% peak\")\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    # RadiObject S3 (if available)\n",
    "    if radi_s3_axial:\n",
    "        vol = radi_s3_axial.collection(radi_s3_axial.collection_names[0]).iloc[0]\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol.to_numpy(), \"RadiObject\", \"full_volume\", \"s3\", \"axial\", \"tiledb\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"RadiObject (S3/axial): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "\n",
    "    # MONAI (local only - can't read S3 natively)\n",
    "    if nifti_gz_paths:\n",
    "        from monai.transforms import LoadImage\n",
    "\n",
    "        loader = LoadImage(image_only=True)\n",
    "        result = benchmark_operation(\n",
    "            lambda: loader(str(nifti_gz_paths[0])), \"MONAI\", \"full_volume\", \"local\", \"\", \"nifti_gz\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"MONAI (local): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "        print(f\"  CPU: {result.cpu_percent_mean:.1f}% mean\")\n",
    "\n",
    "    # TorchIO (local only)\n",
    "    if nifti_gz_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: tio.ScalarImage(str(nifti_gz_paths[0])).data,\n",
    "            \"TorchIO\",\n",
    "            \"full_volume\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"TorchIO (local): {result.time_mean_ms:.1f} +/- {result.time_std_ms:.1f} ms\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_full_volume_load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cat1-partial-reads",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:17:13.180645Z",
     "iopub.status.busy": "2026-02-02T13:17:13.180552Z",
     "iopub.status.idle": "2026-02-02T13:19:46.048327Z",
     "shell.execute_reply": "2026-02-02T13:19:46.047738Z"
    },
    "papermill": {
     "duration": 152.874476,
     "end_time": "2026-02-02T13:19:46.051055",
     "exception": false,
     "start_time": "2026-02-02T13:17:13.176579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BENCHMARK 2.2: Partial Reads (Tiling Comparison)\n",
      "============================================================\n",
      "What: Extract 2D slice or 3D ROI - compare tiling strategies\n",
      "Key insight: Tiling strategy MUST match access pattern!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2D Axial Slice Extraction ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXIAL-tiled (local): 3.41 +/- 0.40 ms [OPTIMAL]\n",
      "  Memory: 1.0 MB heap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISOTROPIC-tiled (local): 31.03 +/- 2.65 ms [suboptimal]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXIAL-tiled (S3): 199.77 +/- 26.94 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISOTROPIC-tiled (S3): 5555.14 +/- 498.48 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI (full load + slice): 2347.00 +/- 53.45 ms\n",
      "  Memory: 912.2 MB heap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchIO (full load + slice): 773.04 +/- 17.86 ms\n",
      "\n",
      "--- 3D ROI Extraction (64x64x64) ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISOTROPIC-tiled (local): 1.84 +/- 0.16 ms [OPTIMAL]\n",
      "  Memory: 1.0 MB heap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXIAL-tiled (local): 24.82 +/- 0.87 ms [suboptimal]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISOTROPIC-tiled (S3): 182.39 +/- 44.44 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXIAL-tiled (S3): 2843.09 +/- 505.14 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI (full load): 1253.38 +/- 51.49 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchIO (full load): 775.31 +/- 36.01 ms\n",
      "\n",
      "--- Tiling Strategy Impact ---\n",
      "2D Slice: AXIAL tiling is 9.1x faster than ISOTROPIC\n",
      "3D ROI: ISOTROPIC tiling is 13.5x faster than AXIAL\n"
     ]
    }
   ],
   "source": [
    "def benchmark_partial_reads():\n",
    "    \"\"\"Benchmark 2.2: Partial Reads with CORRECTLY TILED datasets.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 2.2: Partial Reads (Tiling Comparison)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Extract 2D slice or 3D ROI - compare tiling strategies\")\n",
    "    print(\"Key insight: Tiling strategy MUST match access pattern!\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Get volumes for testing\n",
    "    vol_axial_local = None\n",
    "    vol_isotropic_local = None\n",
    "    vol_axial_s3 = None\n",
    "    vol_isotropic_s3 = None\n",
    "\n",
    "    if radi_local_axial:\n",
    "        vol_axial_local = radi_local_axial.collection(radi_local_axial.collection_names[0]).iloc[0]\n",
    "    if radi_local_isotropic:\n",
    "        vol_isotropic_local = radi_local_isotropic.collection(\n",
    "            radi_local_isotropic.collection_names[0]\n",
    "        ).iloc[0]\n",
    "    if radi_s3_axial:\n",
    "        vol_axial_s3 = radi_s3_axial.collection(radi_s3_axial.collection_names[0]).iloc[0]\n",
    "    if radi_s3_isotropic:\n",
    "        vol_isotropic_s3 = radi_s3_isotropic.collection(radi_s3_isotropic.collection_names[0]).iloc[\n",
    "            0\n",
    "        ]\n",
    "\n",
    "    # --- 2D SLICE BENCHMARKS ---\n",
    "    print(\"\\n--- 2D Axial Slice Extraction ---\")\n",
    "\n",
    "    # 2D Slice on AXIAL-tiled (OPTIMAL)\n",
    "    if vol_axial_local:\n",
    "        mid_z = vol_axial_local.shape[2] // 2\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_axial_local.axial(mid_z),\n",
    "            \"RadiObject\",\n",
    "            \"slice_2d\",\n",
    "            \"local\",\n",
    "            \"axial\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"AXIAL-tiled (local): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms [OPTIMAL]\"\n",
    "        )\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    # 2D Slice on ISOTROPIC-tiled (SUBOPTIMAL)\n",
    "    if vol_isotropic_local:\n",
    "        mid_z = vol_isotropic_local.shape[2] // 2\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_isotropic_local.axial(mid_z),\n",
    "            \"RadiObject\",\n",
    "            \"slice_2d\",\n",
    "            \"local\",\n",
    "            \"isotropic\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"ISOTROPIC-tiled (local): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms [suboptimal]\"\n",
    "        )\n",
    "\n",
    "    # S3 variants\n",
    "    if vol_axial_s3:\n",
    "        mid_z = vol_axial_s3.shape[2] // 2\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_axial_s3.axial(mid_z), \"RadiObject\", \"slice_2d\", \"s3\", \"axial\", \"tiledb\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"AXIAL-tiled (S3): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    if vol_isotropic_s3:\n",
    "        mid_z = vol_isotropic_s3.shape[2] // 2\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_isotropic_s3.axial(mid_z),\n",
    "            \"RadiObject\",\n",
    "            \"slice_2d\",\n",
    "            \"s3\",\n",
    "            \"isotropic\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"ISOTROPIC-tiled (S3): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    # MONAI/TorchIO (must load full volume then slice)\n",
    "    if nifti_gz_paths:\n",
    "        from monai.transforms import LoadImage\n",
    "\n",
    "        loader = LoadImage(image_only=True)\n",
    "        result = benchmark_operation(\n",
    "            lambda: loader(str(nifti_gz_paths[0]))[\n",
    "                :, :, loader(str(nifti_gz_paths[0])).shape[2] // 2\n",
    "            ],\n",
    "            \"MONAI\",\n",
    "            \"slice_2d\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"MONAI (full load + slice): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\"\n",
    "        )\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    if nifti_gz_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: tio.ScalarImage(str(nifti_gz_paths[0])).data[\n",
    "                :, :, :, tio.ScalarImage(str(nifti_gz_paths[0])).shape[3] // 2\n",
    "            ],\n",
    "            \"TorchIO\",\n",
    "            \"slice_2d\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"TorchIO (full load + slice): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\"\n",
    "        )\n",
    "\n",
    "    # --- 3D ROI BENCHMARKS ---\n",
    "    print(\"\\n--- 3D ROI Extraction (64x64x64) ---\")\n",
    "    roi_size = 64\n",
    "\n",
    "    # 3D ROI on ISOTROPIC-tiled (OPTIMAL)\n",
    "    if vol_isotropic_local:\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_isotropic_local.slice(\n",
    "                x=slice(0, roi_size), y=slice(0, roi_size), z=slice(0, roi_size)\n",
    "            ),\n",
    "            \"RadiObject\",\n",
    "            \"roi_3d\",\n",
    "            \"local\",\n",
    "            \"isotropic\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"ISOTROPIC-tiled (local): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms [OPTIMAL]\"\n",
    "        )\n",
    "        print(f\"  Memory: {result.peak_heap_mb:.1f} MB heap\")\n",
    "\n",
    "    # 3D ROI on AXIAL-tiled (SUBOPTIMAL)\n",
    "    if vol_axial_local:\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_axial_local.slice(\n",
    "                x=slice(0, roi_size), y=slice(0, roi_size), z=slice(0, roi_size)\n",
    "            ),\n",
    "            \"RadiObject\",\n",
    "            \"roi_3d\",\n",
    "            \"local\",\n",
    "            \"axial\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"AXIAL-tiled (local): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms [suboptimal]\"\n",
    "        )\n",
    "\n",
    "    # S3 variants\n",
    "    if vol_isotropic_s3:\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_isotropic_s3.slice(\n",
    "                x=slice(0, roi_size), y=slice(0, roi_size), z=slice(0, roi_size)\n",
    "            ),\n",
    "            \"RadiObject\",\n",
    "            \"roi_3d\",\n",
    "            \"s3\",\n",
    "            \"isotropic\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"ISOTROPIC-tiled (S3): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    if vol_axial_s3:\n",
    "        result = benchmark_operation(\n",
    "            lambda: vol_axial_s3.slice(\n",
    "                x=slice(0, roi_size), y=slice(0, roi_size), z=slice(0, roi_size)\n",
    "            ),\n",
    "            \"RadiObject\",\n",
    "            \"roi_3d\",\n",
    "            \"s3\",\n",
    "            \"axial\",\n",
    "            \"tiledb\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"AXIAL-tiled (S3): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    # MONAI/TorchIO comparison\n",
    "    if nifti_gz_paths:\n",
    "        from monai.transforms import LoadImage\n",
    "\n",
    "        loader = LoadImage(image_only=True)\n",
    "        result = benchmark_operation(\n",
    "            lambda: loader(str(nifti_gz_paths[0]))[:roi_size, :roi_size, :roi_size],\n",
    "            \"MONAI\",\n",
    "            \"roi_3d\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"MONAI (full load): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    if nifti_gz_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: tio.ScalarImage(str(nifti_gz_paths[0])).data[\n",
    "                :, :roi_size, :roi_size, :roi_size\n",
    "            ],\n",
    "            \"TorchIO\",\n",
    "            \"roi_3d\",\n",
    "            \"local\",\n",
    "            \"\",\n",
    "            \"nifti_gz\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"TorchIO (full load): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    # --- Speedup Analysis ---\n",
    "    print(\"\\n--- Tiling Strategy Impact ---\")\n",
    "    slice_axial = next(\n",
    "        (\n",
    "            r\n",
    "            for r in results\n",
    "            if r.benchmark_name == \"slice_2d\"\n",
    "            and r.tiling_strategy == \"axial\"\n",
    "            and r.scenario == \"local\"\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    slice_isotropic = next(\n",
    "        (\n",
    "            r\n",
    "            for r in results\n",
    "            if r.benchmark_name == \"slice_2d\"\n",
    "            and r.tiling_strategy == \"isotropic\"\n",
    "            and r.scenario == \"local\"\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    if slice_axial and slice_isotropic and slice_axial.time_mean_ms > 0:\n",
    "        ratio = slice_isotropic.time_mean_ms / slice_axial.time_mean_ms\n",
    "        print(f\"2D Slice: AXIAL tiling is {ratio:.1f}x faster than ISOTROPIC\")\n",
    "\n",
    "    roi_isotropic = next(\n",
    "        (\n",
    "            r\n",
    "            for r in results\n",
    "            if r.benchmark_name == \"roi_3d\"\n",
    "            and r.tiling_strategy == \"isotropic\"\n",
    "            and r.scenario == \"local\"\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    roi_axial = next(\n",
    "        (\n",
    "            r\n",
    "            for r in results\n",
    "            if r.benchmark_name == \"roi_3d\"\n",
    "            and r.tiling_strategy == \"axial\"\n",
    "            and r.scenario == \"local\"\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "    if roi_isotropic and roi_axial and roi_isotropic.time_mean_ms > 0:\n",
    "        ratio = roi_axial.time_mean_ms / roi_isotropic.time_mean_ms\n",
    "        print(f\"3D ROI: ISOTROPIC tiling is {ratio:.1f}x faster than AXIAL\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_partial_reads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cat1-random-access",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:19:46.061470Z",
     "iopub.status.busy": "2026-02-02T13:19:46.061273Z",
     "iopub.status.idle": "2026-02-02T13:33:26.209491Z",
     "shell.execute_reply": "2026-02-02T13:33:26.208534Z"
    },
    "papermill": {
     "duration": 820.1591,
     "end_time": "2026-02-02T13:33:26.215092",
     "exception": false,
     "start_time": "2026-02-02T13:19:46.055992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BENCHMARK 2.3: Random Access\n",
      "============================================================\n",
      "What: Access volumes in random order (not sequential)\n",
      "Expectation: RadiObject O(1) indexing; file-based frameworks similar\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiObject (local): 584.3 ms/volume (5843.3 ms total)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiObject (S3): 7793.5 ms/volume (77934.9 ms total)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI (local): 1286.0 ms/volume (12860.5 ms total)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchIO (local): 889.0 ms/volume (8889.7 ms total)\n"
     ]
    }
   ],
   "source": [
    "def benchmark_random_access():\n",
    "    \"\"\"Benchmark 2.3: Random Access Pattern.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 2.3: Random Access\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Access volumes in random order (not sequential)\")\n",
    "    print(\"Expectation: RadiObject O(1) indexing; file-based frameworks similar\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "    n_accesses = min(10, len(nifti_gz_paths)) if nifti_gz_paths else 0\n",
    "\n",
    "    if n_accesses < 3:\n",
    "        print(\"Need at least 3 volumes for random access benchmark\")\n",
    "        return results\n",
    "\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    indices = np.random.permutation(n_accesses).tolist()\n",
    "\n",
    "    # RadiObject Local\n",
    "    if radi_local_axial and len(radi_local_axial) >= n_accesses:\n",
    "        collection = radi_local_axial.collection(radi_local_axial.collection_names[0])\n",
    "\n",
    "        def radiobject_random():\n",
    "            for idx in indices:\n",
    "                _ = collection.iloc[idx].to_numpy()\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            radiobject_random, \"RadiObject\", \"random_access\", \"local\", \"axial\", \"tiledb\", n_runs=3\n",
    "        )\n",
    "        result.n_samples = n_accesses\n",
    "        per_vol = result.time_mean_ms / n_accesses\n",
    "        results.append(result)\n",
    "        print(f\"RadiObject (local): {per_vol:.1f} ms/volume ({result.time_mean_ms:.1f} ms total)\")\n",
    "\n",
    "    # RadiObject S3\n",
    "    if radi_s3_axial and len(radi_s3_axial) >= n_accesses:\n",
    "        collection = radi_s3_axial.collection(radi_s3_axial.collection_names[0])\n",
    "\n",
    "        def radiobject_s3_random():\n",
    "            for idx in indices:\n",
    "                _ = collection.iloc[idx].to_numpy()\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            radiobject_s3_random, \"RadiObject\", \"random_access\", \"s3\", \"axial\", \"tiledb\", n_runs=3\n",
    "        )\n",
    "        result.n_samples = n_accesses\n",
    "        per_vol = result.time_mean_ms / n_accesses\n",
    "        results.append(result)\n",
    "        print(f\"RadiObject (S3): {per_vol:.1f} ms/volume ({result.time_mean_ms:.1f} ms total)\")\n",
    "\n",
    "    # MONAI\n",
    "    if len(nifti_gz_paths) >= n_accesses:\n",
    "        from monai.transforms import LoadImage\n",
    "\n",
    "        loader = LoadImage(image_only=True)\n",
    "        paths = [nifti_gz_paths[i] for i in range(n_accesses)]\n",
    "\n",
    "        def monai_random():\n",
    "            for idx in indices:\n",
    "                _ = loader(str(paths[idx]))\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            monai_random, \"MONAI\", \"random_access\", \"local\", \"\", \"nifti_gz\", n_runs=3\n",
    "        )\n",
    "        result.n_samples = n_accesses\n",
    "        per_vol = result.time_mean_ms / n_accesses\n",
    "        results.append(result)\n",
    "        print(f\"MONAI (local): {per_vol:.1f} ms/volume ({result.time_mean_ms:.1f} ms total)\")\n",
    "\n",
    "    # TorchIO\n",
    "    if len(nifti_gz_paths) >= n_accesses:\n",
    "        paths = [nifti_gz_paths[i] for i in range(n_accesses)]\n",
    "\n",
    "        def torchio_random():\n",
    "            for idx in indices:\n",
    "                img = tio.ScalarImage(str(paths[idx]))\n",
    "                _ = img.data\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            torchio_random, \"TorchIO\", \"random_access\", \"local\", \"\", \"nifti_gz\", n_runs=3\n",
    "        )\n",
    "        result.n_samples = n_accesses\n",
    "        per_vol = result.time_mean_ms / n_accesses\n",
    "        results.append(result)\n",
    "        print(f\"TorchIO (local): {per_vol:.1f} ms/volume ({result.time_mean_ms:.1f} ms total)\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_random_access())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cat2-header",
   "metadata": {
    "papermill": {
     "duration": 0.006577,
     "end_time": "2026-02-02T13:33:26.226095",
     "exception": false,
     "start_time": "2026-02-02T13:33:26.219518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Category 2: Analysis Workflow Benchmarks\n",
    "\n",
    "In-notebook exploration and analysis workflows.\n",
    "\n",
    "| Benchmark | What It Tests | RadiObject Advantage |\n",
    "|-----------|---------------|---------------------|\n",
    "| Metadata Query | Filter subjects by attributes | TileDB QueryCondition |\n",
    "| Index Lookup | Access by subject ID | O(1) vs file scan |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cat2-metadata",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:33:26.234641Z",
     "iopub.status.busy": "2026-02-02T13:33:26.234497Z",
     "iopub.status.idle": "2026-02-02T13:33:29.754328Z",
     "shell.execute_reply": "2026-02-02T13:33:29.753999Z"
    },
    "papermill": {
     "duration": 3.525833,
     "end_time": "2026-02-02T13:33:29.754948",
     "exception": false,
     "start_time": "2026-02-02T13:33:26.229115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BENCHMARK 2.1: Metadata & Index Operations\n",
      "============================================================\n",
      "What: Access metadata, filter subjects, lookup by ID\n",
      "Expectation: RadiObject O(1) operations; file-based need scanning\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiObject iloc[0] (local): 0.021 +/- 0.007 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiObject obs_subject_ids (local): 0.003 +/- 0.001 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiObject collection_names (local): 0.002 +/- 0.000 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiObject iloc[0] (S3): 0.019 +/- 0.003 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiObject obs_subject_ids (S3): 0.004 +/- 0.001 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File glob('*.nii.gz'): 0.18 +/- 0.05 ms\n",
      "\n",
      "--- Key Insight ---\n",
      "RadiObject metadata operations are O(1) due to TileDB indexing\n",
      "File-based systems require directory scanning or path construction\n"
     ]
    }
   ],
   "source": [
    "def benchmark_metadata_operations():\n",
    "    \"\"\"Benchmark 2.1: Metadata and Index Operations.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 2.1: Metadata & Index Operations\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Access metadata, filter subjects, lookup by ID\")\n",
    "    print(\"Expectation: RadiObject O(1) operations; file-based need scanning\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # RadiObject Local\n",
    "    if radi_local_axial:\n",
    "        # Index lookup by position\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_local_axial.iloc[0], \"RadiObject\", \"iloc_lookup\", \"local\", \"axial\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject iloc[0] (local): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\"\n",
    "        )\n",
    "\n",
    "        # obs_subject_ids property\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_local_axial.obs_subject_ids,\n",
    "            \"RadiObject\",\n",
    "            \"obs_subject_ids\",\n",
    "            \"local\",\n",
    "            \"axial\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject obs_subject_ids (local): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\"\n",
    "        )\n",
    "\n",
    "        # collection_names property\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_local_axial.collection_names,\n",
    "            \"RadiObject\",\n",
    "            \"collection_names\",\n",
    "            \"local\",\n",
    "            \"axial\",\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject collection_names (local): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\"\n",
    "        )\n",
    "\n",
    "    # RadiObject S3\n",
    "    if radi_s3_axial:\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_s3_axial.iloc[0], \"RadiObject\", \"iloc_lookup\", \"s3\", \"axial\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"RadiObject iloc[0] (S3): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\")\n",
    "\n",
    "        result = benchmark_operation(\n",
    "            lambda: radi_s3_axial.obs_subject_ids, \"RadiObject\", \"obs_subject_ids\", \"s3\", \"axial\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(\n",
    "            f\"RadiObject obs_subject_ids (S3): {result.time_mean_ms:.3f} +/- {result.time_std_ms:.3f} ms\"\n",
    "        )\n",
    "\n",
    "    # File-based comparison\n",
    "    if nifti_paths:\n",
    "        result = benchmark_operation(\n",
    "            lambda: list(NIFTI_DIR.glob(\"*.nii.gz\")), \"File\", \"glob_scan\", \"local\", \"\"\n",
    "        )\n",
    "        results.append(result)\n",
    "        print(f\"\\nFile glob('*.nii.gz'): {result.time_mean_ms:.2f} +/- {result.time_std_ms:.2f} ms\")\n",
    "\n",
    "    print(\"\\n--- Key Insight ---\")\n",
    "    print(\"RadiObject metadata operations are O(1) due to TileDB indexing\")\n",
    "    print(\"File-based systems require directory scanning or path construction\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_metadata_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cat3-header",
   "metadata": {
    "papermill": {
     "duration": 0.003322,
     "end_time": "2026-02-02T13:33:29.762138",
     "exception": false,
     "start_time": "2026-02-02T13:33:29.758816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Category 3: ML Training Benchmarks\n",
    "\n",
    "PyTorch DataLoader throughput for deep learning training.\n",
    "\n",
    "| Benchmark | What It Tests | RadiObject Advantage |\n",
    "|-----------|---------------|---------------------|\n",
    "| DataLoader Throughput | Samples/sec during training | Competitive locally |\n",
    "| Patch Extraction | Random patch loading | Partial reads |\n",
    "| Memory Efficiency | Peak RAM during epoch | Lazy loading |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cat3-adapters",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:33:29.769977Z",
     "iopub.status.busy": "2026-02-02T13:33:29.769875Z",
     "iopub.status.idle": "2026-02-02T13:33:29.776686Z",
     "shell.execute_reply": "2026-02-02T13:33:29.776331Z"
    },
    "papermill": {
     "duration": 0.011038,
     "end_time": "2026-02-02T13:33:29.777172",
     "exception": false,
     "start_time": "2026-02-02T13:33:29.766134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_radiobject_loader(\n",
    "    radi: RadiObject,\n",
    "    patch_size: tuple[int, int, int] | None = None,\n",
    ") -> DataLoader | None:\n",
    "    \"\"\"Create RadiObject DataLoader.\"\"\"\n",
    "    try:\n",
    "        collection = radi.collection(radi.collection_names[0])\n",
    "        return create_training_dataloader(\n",
    "            collection,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            patch_size=patch_size or PATCH_SIZE,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"  RadiObject DataLoader error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_monai_loader(\n",
    "    paths: list[Path],\n",
    "    patch_size: tuple[int, int, int] | None = None,\n",
    ") -> DataLoader | None:\n",
    "    \"\"\"Create MONAI DataLoader.\"\"\"\n",
    "    if not paths:\n",
    "        return None\n",
    "\n",
    "    data_dicts = [{\"image\": str(p)} for p in paths]\n",
    "    ps = patch_size or PATCH_SIZE\n",
    "\n",
    "    transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\"]),\n",
    "            RandSpatialCropd(keys=[\"image\"], roi_size=ps, random_size=False),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = MonaiDataset(data=data_dicts, transform=transforms)\n",
    "    return MonaiDataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "\n",
    "\n",
    "def create_torchio_loader(\n",
    "    paths: list[Path],\n",
    "    patch_size: tuple[int, int, int] | None = None,\n",
    ") -> DataLoader | None:\n",
    "    \"\"\"Create TorchIO DataLoader.\"\"\"\n",
    "    if not paths:\n",
    "        return None\n",
    "\n",
    "    subjects = [tio.Subject(image=tio.ScalarImage(str(p))) for p in paths]\n",
    "    ps = patch_size or PATCH_SIZE\n",
    "    transform = tio.Compose([tio.CropOrPad(ps)])\n",
    "    dataset = tio.SubjectsDataset(subjects, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b814db",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cat3-throughput",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:33:29.784036Z",
     "iopub.status.busy": "2026-02-02T13:33:29.783946Z",
     "iopub.status.idle": "2026-02-02T13:33:33.584891Z",
     "shell.execute_reply": "2026-02-02T13:33:33.583932Z"
    },
    "papermill": {
     "duration": 3.805415,
     "end_time": "2026-02-02T13:33:33.585657",
     "exception": true,
     "start_time": "2026-02-02T13:33:29.780242",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BENCHMARK: ML DataLoader Throughput\n",
      "============================================================\n",
      "Config: batch_size=4, patch_size=(64, 64, 64)\n",
      "\n",
      "  RadiObject DataLoader error: 1 validation error for DatasetConfig\n",
      "patch_size\n",
      "  Input should be a valid tuple [type=tuple_type, input_value='(64, 64, 64)', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/tuple_type\n",
      "  RadiObject DataLoader error: 1 validation error for DatasetConfig\n",
      "patch_size\n",
      "  Input should be a valid tuple [type=tuple_type, input_value='(64, 64, 64)', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/tuple_type\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.croppad.dictionary.RandSpatialCropd object at 0x108586b50>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/transforms/transform.py:150\u001b[39m, in \u001b[36mapply_transform\u001b[39m\u001b[34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[39m\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    147\u001b[39m             apply_transform(transform, item, map_items_ - \u001b[32m1\u001b[39m, unpack_items, log_stats, lazy, overrides)\n\u001b[32m    148\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[32m    149\u001b[39m         ]\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/transforms/transform.py:98\u001b[39m, in \u001b[36m_apply_transform\u001b[39m\u001b[34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(*data, lazy=lazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(*data)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/transforms/croppad/dictionary.py:405\u001b[39m, in \u001b[36mRandCropd.__call__\u001b[39m\u001b[34m(self, data, lazy)\u001b[39m\n\u001b[32m    404\u001b[39m first_item = d[\u001b[38;5;28mself\u001b[39m.first_key(d)]\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandomize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_item\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpeek_pending_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfirst_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMetaTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfirst_item\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m lazy_ = \u001b[38;5;28mself\u001b[39m.lazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/transforms/croppad/dictionary.py:399\u001b[39m, in \u001b[36mRandCropd.randomize\u001b[39m\u001b[34m(self, img_size)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.cropper, Randomizable):\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcropper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandomize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/transforms/croppad/array.py:603\u001b[39m, in \u001b[36mRandSpatialCrop.randomize\u001b[39m\u001b[34m(self, img_size)\u001b[39m\n\u001b[32m    602\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrandomize\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_size: Sequence[\u001b[38;5;28mint\u001b[39m]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     \u001b[38;5;28mself\u001b[39m._size = \u001b[43mfall_back_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroi_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    604\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.random_size:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/utils/misc.py:301\u001b[39m, in \u001b[36mfall_back_tuple\u001b[39m\u001b[34m(user_provided, default, func)\u001b[39m\n\u001b[32m    300\u001b[39m user = ensure_tuple_rep(user_provided, ndim)\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use the default values if user provided is not valid\u001b[39;49;00m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_c\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_c\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefault_c\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefault_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_c\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/utils/misc.py:302\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    300\u001b[39m user = ensure_tuple_rep(user_provided, ndim)\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(  \u001b[38;5;66;03m# use the default values if user provided is not valid\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     user_c \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_c\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m default_c \u001b[38;5;28;01mfor\u001b[39;00m default_c, user_c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(default, user)\n\u001b[32m    303\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/utils/misc.py:261\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m({k: v[ik] \u001b[38;5;28;01mfor\u001b[39;00m (k, v) \u001b[38;5;129;01min\u001b[39;00m dict_overrides.items()} \u001b[38;5;28;01mfor\u001b[39;00m ik \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(keys)))\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfall_back_tuple\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     user_provided: Any, default: Sequence | NdarrayTensor, func: Callable = \u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m    262\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Any, ...]:\n\u001b[32m    263\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[33;03m    Refine `user_provided` according to the `default`, and returns as a validated tuple.\u001b[39;00m\n\u001b[32m    265\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    297\u001b[39m \n\u001b[32m    298\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: '>' not supported between instances of 'str' and 'int'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 111\u001b[39m\n\u001b[32m    106\u001b[39m             gc.collect()\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m all_results.extend(\u001b[43mbenchmark_dataloader_throughput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mbenchmark_dataloader_throughput\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     44\u001b[39m loader = create_monai_loader(nifti_gz_paths)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loader:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     result = \u001b[43mbenchmark_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMONAI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataloader_throughput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlocal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     result.storage_format = \u001b[33m\"\u001b[39m\u001b[33mnifti_gz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m     results.append(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mbenchmark_dataloader\u001b[39m\u001b[34m(loader, framework, benchmark_name, scenario, tiling, image_key, n_warmup, n_batches)\u001b[39m\n\u001b[32m     20\u001b[39m loader_iter = \u001b[38;5;28miter\u001b[39m(loader)\n\u001b[32m     21\u001b[39m cold_start = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m first_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_batch, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     24\u001b[39m     _ = first_batch[image_key].shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:741\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    739\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    744\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    745\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    746\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    747\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:801\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    800\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    803\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     52\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     52\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/data/dataset.py:109\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, collections.abc.Sequence):\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# dataset[[1, 3, 4]]\u001b[39;00m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Subset(dataset=\u001b[38;5;28mself\u001b[39m, indices=index)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/data/dataset.py:95\u001b[39m, in \u001b[36mDataset._transform\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[33;03mFetch single data item from `self.data`.\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     94\u001b[39m data_i = \u001b[38;5;28mself\u001b[39m.data[index]\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/transforms/compose.py:346\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, input_, start, end, threading, lazy)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_, start=\u001b[32m0\u001b[39m, end=\u001b[38;5;28;01mNone\u001b[39;00m, threading=\u001b[38;5;28;01mFalse\u001b[39;00m, lazy: \u001b[38;5;28mbool\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    345\u001b[39m     _lazy = \u001b[38;5;28mself\u001b[39m._lazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     result = \u001b[43mexecute_compose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_lazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m        \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthreading\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/transforms/compose.py:116\u001b[39m, in \u001b[36mexecute_compose\u001b[39m\u001b[34m(data, transforms, map_items, unpack_items, start, end, lazy, overrides, threading, log_stats)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m threading:\n\u001b[32m    115\u001b[39m         _transform = deepcopy(_transform) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[38;5;28;01melse\u001b[39;00m _transform\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     data = \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_stats\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m data = apply_pending_transforms(data, \u001b[38;5;28;01mNone\u001b[39;00m, overrides, logger_name=log_stats)\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/RadiObject/.venv/lib/python3.11/site-packages/monai/transforms/transform.py:180\u001b[39m, in \u001b[36mapply_transform\u001b[39m\u001b[34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[39m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    179\u001b[39m         _log_stats(data=data)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mapplying transform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: applying transform <monai.transforms.croppad.dictionary.RandSpatialCropd object at 0x108586b50>"
     ]
    }
   ],
   "source": [
    "def benchmark_dataloader_throughput():\n",
    "    \"\"\"Benchmark: ML DataLoader Throughput (samples/sec).\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK: ML DataLoader Throughput\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Config: batch_size={BATCH_SIZE}, patch_size={PATCH_SIZE}\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # RadiObject Local (isotropic for patch extraction)\n",
    "    if radi_local_isotropic:\n",
    "        loader = create_radiobject_loader(radi_local_isotropic)\n",
    "        if loader:\n",
    "            result = benchmark_dataloader(\n",
    "                loader, \"RadiObject\", \"dataloader_throughput\", \"local\", \"isotropic\"\n",
    "            )\n",
    "            results.append(result)\n",
    "            print(f\"RadiObject (local): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "            print(f\"  Batch: {result.time_mean_ms:.1f} ms | Memory: {result.peak_heap_mb:.0f} MB\")\n",
    "            del loader\n",
    "            gc.collect()\n",
    "\n",
    "    # RadiObject S3\n",
    "    if radi_s3_isotropic:\n",
    "        loader = create_radiobject_loader(radi_s3_isotropic)\n",
    "        if loader:\n",
    "            result = benchmark_dataloader(\n",
    "                loader,\n",
    "                \"RadiObject\",\n",
    "                \"dataloader_throughput\",\n",
    "                \"s3\",\n",
    "                \"isotropic\",\n",
    "                n_batches=min(10, N_BATCHES),\n",
    "            )\n",
    "            results.append(result)\n",
    "            print(f\"RadiObject (S3): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "            print(f\"  Batch: {result.time_mean_ms:.1f} ms\")\n",
    "            del loader\n",
    "            gc.collect()\n",
    "\n",
    "    # MONAI - use benchmark NIfTI files\n",
    "    if nifti_gz_paths:\n",
    "        loader = create_monai_loader(nifti_gz_paths)\n",
    "        if loader:\n",
    "            result = benchmark_dataloader(loader, \"MONAI\", \"dataloader_throughput\", \"local\", \"\")\n",
    "            result.storage_format = \"nifti_gz\"\n",
    "            results.append(result)\n",
    "            print(f\"MONAI (local): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "            print(f\"  Batch: {result.time_mean_ms:.1f} ms | Memory: {result.peak_heap_mb:.0f} MB\")\n",
    "            del loader\n",
    "            gc.collect()\n",
    "\n",
    "    # TorchIO - use benchmark NIfTI files\n",
    "    if nifti_gz_paths:\n",
    "        loader = create_torchio_loader(nifti_gz_paths)\n",
    "        if loader:\n",
    "            gc.collect()\n",
    "            tracemalloc.start()\n",
    "            cpu_sampler = CPUSampler()\n",
    "            cpu_sampler.start()\n",
    "\n",
    "            loader_iter = iter(loader)\n",
    "            cold_start = time.perf_counter()\n",
    "            first_batch = next(loader_iter)\n",
    "            _ = first_batch[\"image\"][tio.DATA].shape\n",
    "            cold_start_time = (time.perf_counter() - cold_start) * 1000\n",
    "\n",
    "            batch_times = []\n",
    "            for _ in range(N_BATCHES):\n",
    "                try:\n",
    "                    start = time.perf_counter()\n",
    "                    batch = next(loader_iter)\n",
    "                    _ = batch[\"image\"][tio.DATA].shape\n",
    "                    batch_times.append((time.perf_counter() - start) * 1000)\n",
    "                except StopIteration:\n",
    "                    loader_iter = iter(loader)\n",
    "                    batch = next(loader_iter)\n",
    "\n",
    "            cpu_mean, cpu_peak = cpu_sampler.stop()\n",
    "            _, peak_heap = tracemalloc.get_traced_memory()\n",
    "            tracemalloc.stop()\n",
    "\n",
    "            mean_batch = float(np.mean(batch_times)) if batch_times else 0.0\n",
    "            throughput = (BATCH_SIZE / (mean_batch / 1000)) if mean_batch > 0 else 0.0\n",
    "\n",
    "            result = BenchmarkResult(\n",
    "                framework=\"TorchIO\",\n",
    "                benchmark_name=\"dataloader_throughput\",\n",
    "                scenario=\"local\",\n",
    "                storage_format=\"nifti_gz\",\n",
    "                time_mean_ms=mean_batch,\n",
    "                time_std_ms=float(np.std(batch_times)) if batch_times else 0.0,\n",
    "                cold_start_ms=cold_start_time,\n",
    "                batch_times_ms=batch_times,\n",
    "                cpu_percent_mean=cpu_mean,\n",
    "                cpu_percent_peak=cpu_peak,\n",
    "                peak_heap_mb=peak_heap / (1024 * 1024),\n",
    "                throughput_samples_per_sec=throughput,\n",
    "                n_samples=len(batch_times) * BATCH_SIZE,\n",
    "            )\n",
    "            results.append(result)\n",
    "            print(f\"TorchIO (local): {result.throughput_samples_per_sec:.2f} samples/sec\")\n",
    "            print(f\"  Batch: {result.time_mean_ms:.1f} ms | Memory: {result.peak_heap_mb:.0f} MB\")\n",
    "            del loader\n",
    "            gc.collect()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "all_results.extend(benchmark_dataloader_throughput())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cat4-header",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Category 4: S3 Cloud Storage Benchmarks\n",
    "\n",
    "RadiObject's unique capability: native S3 access via TileDB VFS.\n",
    "\n",
    "| Benchmark | What It Tests | Notes |\n",
    "|-----------|---------------|-------|\n",
    "| S3 vs Local | Performance overhead | Expected 2-5x slower |\n",
    "| S3 Partial Read | Slice from S3 | RadiObject unique |\n",
    "| S3 Training | ML training from S3 | No pre-download required |\n",
    "\n",
    "**Important:** MONAI and TorchIO cannot natively read from S3 - they require downloading files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cat4-comparison",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def benchmark_s3_vs_local():\n",
    "    \"\"\"Benchmark 4.1: S3 vs Local Performance Comparison.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK 4.1: S3 vs Local (RadiObject)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"What: Compare local vs S3 performance for the same operations\")\n",
    "    print(\"Expectation: S3 2-5x slower due to network latency\")\n",
    "    print()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if not (radi_local_axial and radi_s3_axial):\n",
    "        print(\"Need both local and S3 datasets for comparison\")\n",
    "        return results\n",
    "\n",
    "    local_vol = radi_local_axial.collection(radi_local_axial.collection_names[0]).iloc[0]\n",
    "    s3_vol = radi_s3_axial.collection(radi_s3_axial.collection_names[0]).iloc[0]\n",
    "\n",
    "    # Full volume comparison\n",
    "    print(\"--- Full Volume Load ---\")\n",
    "    result_local = benchmark_operation(\n",
    "        lambda: local_vol.to_numpy(), \"RadiObject\", \"s3_comparison_full\", \"local\", \"axial\", n_runs=3\n",
    "    )\n",
    "    results.append(result_local)\n",
    "    print(f\"Local: {result_local.time_mean_ms:.1f} +/- {result_local.time_std_ms:.1f} ms\")\n",
    "\n",
    "    result_s3 = benchmark_operation(\n",
    "        lambda: s3_vol.to_numpy(), \"RadiObject\", \"s3_comparison_full\", \"s3\", \"axial\", n_runs=3\n",
    "    )\n",
    "    results.append(result_s3)\n",
    "    print(f\"S3: {result_s3.time_mean_ms:.1f} +/- {result_s3.time_std_ms:.1f} ms\")\n",
    "\n",
    "    if result_local.time_mean_ms > 0:\n",
    "        overhead = (result_s3.time_mean_ms / result_local.time_mean_ms - 1) * 100\n",
    "        print(f\"S3 overhead: {overhead:.1f}%\")\n",
    "\n",
    "    # Slice comparison\n",
    "    print(\"\\n--- 2D Slice ---\")\n",
    "    mid_z = local_vol.shape[2] // 2\n",
    "\n",
    "    result_local = benchmark_operation(\n",
    "        lambda: local_vol.axial(mid_z), \"RadiObject\", \"s3_comparison_slice\", \"local\", \"axial\"\n",
    "    )\n",
    "    results.append(result_local)\n",
    "    print(f\"Local: {result_local.time_mean_ms:.2f} +/- {result_local.time_std_ms:.2f} ms\")\n",
    "\n",
    "    mid_z_s3 = s3_vol.shape[2] // 2\n",
    "    result_s3 = benchmark_operation(\n",
    "        lambda: s3_vol.axial(mid_z_s3), \"RadiObject\", \"s3_comparison_slice\", \"s3\", \"axial\"\n",
    "    )\n",
    "    results.append(result_s3)\n",
    "    print(f\"S3: {result_s3.time_mean_ms:.2f} +/- {result_s3.time_std_ms:.2f} ms\")\n",
    "\n",
    "    if result_local.time_mean_ms > 0:\n",
    "        overhead = (result_s3.time_mean_ms / result_local.time_mean_ms - 1) * 100\n",
    "        print(f\"S3 overhead: {overhead:.1f}%\")\n",
    "\n",
    "    print(\"\\n--- Key Insight ---\")\n",
    "    print(\"RadiObject can read directly from S3 without downloading files\")\n",
    "    print(\"Partial reads from S3 are particularly efficient due to TileDB tiling\")\n",
    "    print(\"MONAI/TorchIO would require downloading all NIfTI files first\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if RUN_S3_BENCHMARKS:\n",
    "    all_results.extend(benchmark_s3_vs_local())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. Results Visualization\n",
    "\n",
    "Publication-quality visualizations of benchmark results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-setup",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Colorblind-friendly palette (Wong 2011)\n",
    "COLORS = {\n",
    "    \"RadiObject\": \"#0077BB\",\n",
    "    \"MONAI\": \"#EE7733\",\n",
    "    \"TorchIO\": \"#009988\",\n",
    "    \"File\": \"#888888\",\n",
    "    \"local\": \"#0077BB\",\n",
    "    \"s3\": \"#CC3311\",\n",
    "    \"axial\": \"#0077BB\",\n",
    "    \"isotropic\": \"#EE7733\",\n",
    "}\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 11,\n",
    "        \"axes.titlesize\": 13,\n",
    "        \"axes.labelsize\": 11,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "        \"figure.dpi\": 120,\n",
    "        \"savefig.dpi\": 300,\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"figure.facecolor\": \"white\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6fkcekwv",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERO CHART: Consolidated Backend Comparison\n",
    "# Shows all operations across all backends in one visualization\n",
    "\n",
    "\n",
    "def create_hero_chart():\n",
    "    \"\"\"Create consolidated comparison chart across all backends and operations.\"\"\"\n",
    "\n",
    "    # Collect data for key operations\n",
    "    operations = {\n",
    "        \"Full Volume\": \"full_volume\",\n",
    "        \"2D Slice\": \"slice_2d\",\n",
    "        \"64³ ROI\": \"roi_3d\",\n",
    "    }\n",
    "\n",
    "    # Include S3 backend if benchmarks were run\n",
    "    has_s3_results = any(r.scenario == \"s3\" and r.framework == \"RadiObject\" for r in all_results)\n",
    "\n",
    "    backends = [\n",
    "        (\"RadiObject (local)\", \"RadiObject\", \"local\"),\n",
    "    ]\n",
    "    if has_s3_results:\n",
    "        backends.append((\"RadiObject (S3)\", \"RadiObject\", \"s3\"))\n",
    "    backends.extend(\n",
    "        [\n",
    "            (\"MONAI\", \"MONAI\", \"local\"),\n",
    "            (\"TorchIO\", \"TorchIO\", \"local\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Build data matrix\n",
    "    data = {op: [] for op in operations}\n",
    "    backend_labels = []\n",
    "\n",
    "    for label, framework, scenario in backends:\n",
    "        backend_labels.append(label)\n",
    "        for op_name, bench_name in operations.items():\n",
    "            result = next(\n",
    "                (\n",
    "                    r\n",
    "                    for r in all_results\n",
    "                    if r.benchmark_name == bench_name\n",
    "                    and r.framework == framework\n",
    "                    and r.scenario == scenario\n",
    "                    and (r.tiling_strategy in [\"\", \"axial\", \"isotropic\"])\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            # For RadiObject, prefer optimal tiling per operation\n",
    "            if framework == \"RadiObject\":\n",
    "                if bench_name == \"slice_2d\":\n",
    "                    result = next(\n",
    "                        (\n",
    "                            r\n",
    "                            for r in all_results\n",
    "                            if r.benchmark_name == bench_name\n",
    "                            and r.framework == framework\n",
    "                            and r.tiling_strategy == \"axial\"\n",
    "                            and r.scenario == scenario\n",
    "                        ),\n",
    "                        result,\n",
    "                    )\n",
    "                elif bench_name == \"roi_3d\":\n",
    "                    result = next(\n",
    "                        (\n",
    "                            r\n",
    "                            for r in all_results\n",
    "                            if r.benchmark_name == bench_name\n",
    "                            and r.framework == framework\n",
    "                            and r.tiling_strategy == \"isotropic\"\n",
    "                            and r.scenario == scenario\n",
    "                        ),\n",
    "                        result,\n",
    "                    )\n",
    "\n",
    "            data[op_name].append(result.time_mean_ms if result else 0)\n",
    "\n",
    "    # Create grouped bar chart\n",
    "    n_backends = len(backend_labels)\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    x = np.arange(n_backends)\n",
    "    width = 0.25\n",
    "    multiplier = 0\n",
    "\n",
    "    colors = [\"#0077BB\", \"#EE7733\", \"#009988\"]\n",
    "\n",
    "    for i, (op_name, times) in enumerate(data.items()):\n",
    "        offset = width * multiplier\n",
    "        bars = ax.bar(\n",
    "            x + offset,\n",
    "            times,\n",
    "            width,\n",
    "            label=op_name,\n",
    "            color=colors[i],\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        # Add value labels\n",
    "        for bar, val in zip(bars, times):\n",
    "            if val > 0:\n",
    "                height = bar.get_height()\n",
    "                label = f\"{val:.0f}\" if val >= 10 else f\"{val:.1f}\"\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    height,\n",
    "                    label,\n",
    "                    ha=\"center\",\n",
    "                    va=\"bottom\",\n",
    "                    fontsize=8,\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "        multiplier += 1\n",
    "\n",
    "    ax.set_ylabel(\"Time (ms) — lower is better\", fontweight=\"bold\")\n",
    "    title = \"I/O Performance: RadiObject vs MONAI vs TorchIO\"\n",
    "    if has_s3_results:\n",
    "        title = \"I/O Performance: RadiObject (Local & S3) vs MONAI vs TorchIO\"\n",
    "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(backend_labels, fontweight=\"bold\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Add speedup annotations\n",
    "    ax.axhline(y=10, color=\"gray\", linestyle=\":\", alpha=0.5)\n",
    "    ax.text(n_backends - 0.5, 12, \"10ms threshold\", fontsize=8, color=\"gray\", ha=\"right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filepath = ASSETS_DIR / \"benchmark_hero.png\"\n",
    "    plt.savefig(filepath, dpi=300)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print speedup summary\n",
    "    print(\"\\n--- Speedup Summary (vs slowest) ---\")\n",
    "    for op_name, times in data.items():\n",
    "        if all(t > 0 for t in times):\n",
    "            max_time = max(times)\n",
    "            for label, t in zip(backend_labels, times):\n",
    "                speedup = max_time / t\n",
    "                print(f\"{op_name} | {label}: {speedup:.1f}x\")\n",
    "\n",
    "\n",
    "create_hero_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-funcs",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_bar_comparison(\n",
    "    data: dict[str, float],\n",
    "    title: str,\n",
    "    ylabel: str,\n",
    "    filename: str,\n",
    "    errors: dict[str, float] | None = None,\n",
    "    color_key: str = \"framework\",\n",
    "):\n",
    "    \"\"\"Create a bar chart comparing frameworks.\"\"\"\n",
    "    labels = list(data.keys())\n",
    "    values = list(data.values())\n",
    "\n",
    "    # Determine colors\n",
    "    if color_key == \"framework\":\n",
    "        colors = [COLORS.get(l.split()[0], \"#999999\") for l in labels]\n",
    "    else:\n",
    "        colors = [COLORS.get(l.lower(), \"#999999\") for l in labels]\n",
    "\n",
    "    error_vals = [errors.get(l, 0) for l in labels] if errors else None\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    bars = ax.bar(\n",
    "        labels,\n",
    "        values,\n",
    "        yerr=error_vals,\n",
    "        capsize=5,\n",
    "        color=colors,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Rotate labels if needed\n",
    "    if len(labels) > 4 or max(len(l) for l in labels) > 15:\n",
    "        plt.xticks(rotation=30, ha=\"right\")\n",
    "\n",
    "    # Add value labels\n",
    "    max_val = max(values) if values else 1\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + (max_val * 0.02),\n",
    "            f\"{val:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filepath = ASSETS_DIR / filename\n",
    "    plt.savefig(filepath)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widar6x4m4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: Disk Space Comparison\n",
    "if disk_space_results:\n",
    "    data = {r.format_name: r.size_mb for r in disk_space_results}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    labels = list(data.keys())\n",
    "    values = list(data.values())\n",
    "    colors = [\"#0077BB\", \"#0077BB\", \"#EE7733\", \"#EE7733\", \"#009988\"]\n",
    "\n",
    "    bars = ax.bar(labels, values, color=colors[: len(labels)], edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "    ax.set_ylabel(\"Size (MB)\")\n",
    "    ax.set_title(\"Disk Space by Storage Format\")\n",
    "    ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "\n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + (max(values) * 0.02),\n",
    "            f\"{val:.0f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filepath = ASSETS_DIR / \"disk_space_comparison.png\"\n",
    "    plt.savefig(filepath)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mftguo9cr3b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: Format Overhead Comparison\n",
    "format_results = [r for r in all_results if r.benchmark_name == \"format_comparison\"]\n",
    "if format_results:\n",
    "    data = {}\n",
    "    for r in format_results:\n",
    "        if r.storage_format == \"nifti_gz\":\n",
    "            label = \"NIfTI (.nii.gz)\"\n",
    "        elif r.storage_format == \"nifti\":\n",
    "            label = \"NIfTI (.nii)\"\n",
    "        elif r.storage_format == \"numpy\":\n",
    "            label = \"NumPy (.npy)\"\n",
    "        elif r.storage_format == \"tiledb\":\n",
    "            label = f\"TileDB ({r.tiling_strategy})\"\n",
    "        else:\n",
    "            label = r.storage_format\n",
    "        data[label] = r.time_mean_ms\n",
    "\n",
    "    plot_bar_comparison(\n",
    "        data, \"Full Volume Load: Format Overhead\", \"Time (ms)\", \"format_overhead.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6yvokpvbvd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: Memory by Backend (Heap comparison)\n",
    "memory_results = [\n",
    "    r\n",
    "    for r in all_results\n",
    "    if r.benchmark_name in [\"full_volume\", \"slice_2d\"] and r.scenario == \"local\"\n",
    "]\n",
    "if memory_results:\n",
    "    # Group by benchmark type\n",
    "    full_vol = [r for r in memory_results if r.benchmark_name == \"full_volume\"]\n",
    "    slice_2d = [r for r in memory_results if r.benchmark_name == \"slice_2d\"]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Full volume memory\n",
    "    if full_vol:\n",
    "        data = {r.framework: r.peak_heap_mb for r in full_vol if r.peak_heap_mb > 0}\n",
    "        if data:\n",
    "            ax = axes[0]\n",
    "            labels = list(data.keys())\n",
    "            values = list(data.values())\n",
    "            colors = [COLORS.get(l, \"#999999\") for l in labels]\n",
    "            bars = ax.bar(labels, values, color=colors, edgecolor=\"black\", linewidth=1)\n",
    "            ax.set_ylabel(\"Peak Heap (MB)\")\n",
    "            ax.set_title(\"Memory: Full Volume Load\")\n",
    "            ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "            for bar, val in zip(bars, values):\n",
    "                height = bar.get_height()\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    height + (max(values) * 0.02),\n",
    "                    f\"{val:.0f}\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"bottom\",\n",
    "                    fontsize=9,\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "\n",
    "    # Slice extraction memory\n",
    "    if slice_2d:\n",
    "        data = {\n",
    "            f\"{r.framework} ({r.tiling_strategy or 'nifti'})\": r.peak_heap_mb\n",
    "            for r in slice_2d\n",
    "            if r.peak_heap_mb > 0\n",
    "        }\n",
    "        if data:\n",
    "            ax = axes[1]\n",
    "            labels = list(data.keys())\n",
    "            values = list(data.values())\n",
    "            colors = [COLORS.get(l.split()[0], \"#999999\") for l in labels]\n",
    "            bars = ax.bar(labels, values, color=colors, edgecolor=\"black\", linewidth=1)\n",
    "            ax.set_ylabel(\"Peak Heap (MB)\")\n",
    "            ax.set_title(\"Memory: 2D Slice Extraction\")\n",
    "            ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "            plt.xticks(rotation=30, ha=\"right\")\n",
    "            for bar, val in zip(bars, values):\n",
    "                height = bar.get_height()\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    height + (max(values) * 0.02),\n",
    "                    f\"{val:.0f}\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"bottom\",\n",
    "                    fontsize=9,\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filepath = ASSETS_DIR / \"memory_by_backend.png\"\n",
    "    plt.savefig(filepath)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-full-volume",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: Full Volume Load Time\n",
    "full_volume_results = [r for r in all_results if r.benchmark_name == \"full_volume\"]\n",
    "if full_volume_results:\n",
    "    data = {}\n",
    "    errors = {}\n",
    "    for r in full_volume_results:\n",
    "        label = f\"{r.framework} ({r.scenario})\"\n",
    "        data[label] = r.time_mean_ms\n",
    "        errors[label] = r.time_std_ms\n",
    "\n",
    "    plot_bar_comparison(data, \"Full Volume Load Time\", \"Time (ms)\", \"full_volume_load.png\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-slice",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: Slice Extraction (Tiling Comparison)\n",
    "slice_results = [r for r in all_results if r.benchmark_name == \"slice_2d\"]\n",
    "if slice_results:\n",
    "    data = {}\n",
    "    for r in slice_results:\n",
    "        if r.framework == \"RadiObject\":\n",
    "            label = f\"{r.tiling_strategy.upper()} ({r.scenario})\"\n",
    "        else:\n",
    "            label = f\"{r.framework} ({r.scenario})\"\n",
    "        data[label] = r.time_mean_ms\n",
    "\n",
    "    plot_bar_comparison(\n",
    "        data, \"2D Slice Extraction: Tiling Impact\", \"Time (ms)\", \"slice_extraction.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-roi",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: ROI Extraction (Tiling Comparison)\n",
    "roi_results = [r for r in all_results if r.benchmark_name == \"roi_3d\"]\n",
    "if roi_results:\n",
    "    data = {}\n",
    "    for r in roi_results:\n",
    "        if r.framework == \"RadiObject\":\n",
    "            label = f\"{r.tiling_strategy.upper()} ({r.scenario})\"\n",
    "        else:\n",
    "            label = f\"{r.framework} ({r.scenario})\"\n",
    "        data[label] = r.time_mean_ms\n",
    "\n",
    "    plot_bar_comparison(\n",
    "        data, \"3D ROI Extraction (64x64x64): Tiling Impact\", \"Time (ms)\", \"roi_extraction.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-throughput",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: DataLoader Throughput\n",
    "throughput_results = [r for r in all_results if r.benchmark_name == \"dataloader_throughput\"]\n",
    "if throughput_results:\n",
    "    data = {}\n",
    "    for r in throughput_results:\n",
    "        label = f\"{r.framework} ({r.scenario})\"\n",
    "        data[label] = r.throughput_samples_per_sec\n",
    "\n",
    "    plot_bar_comparison(data, \"DataLoader Throughput\", \"Samples/sec\", \"dataloader_throughput.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-s3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: S3 vs Local Comparison\n",
    "s3_comp_results = [r for r in all_results if \"s3_comparison\" in r.benchmark_name]\n",
    "if s3_comp_results:\n",
    "    # Full volume comparison\n",
    "    full_results = [r for r in s3_comp_results if \"full\" in r.benchmark_name]\n",
    "    if len(full_results) >= 2:\n",
    "        data = {r.scenario.upper(): r.time_mean_ms for r in full_results}\n",
    "        plot_bar_comparison(\n",
    "            data,\n",
    "            \"RadiObject: Local vs S3 Full Volume Load\",\n",
    "            \"Time (ms)\",\n",
    "            \"s3_vs_local_full.png\",\n",
    "            color_key=\"scenario\",\n",
    "        )\n",
    "\n",
    "    # Slice comparison\n",
    "    slice_results = [r for r in s3_comp_results if \"slice\" in r.benchmark_name]\n",
    "    if len(slice_results) >= 2:\n",
    "        data = {r.scenario.upper(): r.time_mean_ms for r in slice_results}\n",
    "        plot_bar_comparison(\n",
    "            data,\n",
    "            \"RadiObject: Local vs S3 Slice Extraction\",\n",
    "            \"Time (ms)\",\n",
    "            \"s3_vs_local_slice.png\",\n",
    "            color_key=\"scenario\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-table",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build summary DataFrame\n",
    "summary_rows = [r.to_dict() for r in all_results]\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Display key columns\n",
    "display_cols = [\n",
    "    \"framework\",\n",
    "    \"benchmark_name\",\n",
    "    \"scenario\",\n",
    "    \"tiling_strategy\",\n",
    "    \"time_mean_ms\",\n",
    "    \"time_std_ms\",\n",
    "    \"cpu_percent_mean\",\n",
    "    \"peak_heap_mb\",\n",
    "    \"throughput_samples_per_sec\",\n",
    "]\n",
    "existing_cols = [c for c in display_cols if c in summary_df.columns]\n",
    "display(summary_df[existing_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-export",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export results to JSON\n",
    "results_json = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"config\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"patch_size\": list(PATCH_SIZE),\n",
    "        \"num_workers\": NUM_WORKERS,\n",
    "        \"n_warmup\": N_WARMUP,\n",
    "        \"n_batches\": N_BATCHES,\n",
    "        \"n_runs\": N_RUNS,\n",
    "        \"random_seed\": RANDOM_SEED,\n",
    "        \"s3_bucket\": S3_BUCKET,\n",
    "        \"n_subjects\": N_SUBJECTS_FOR_TILED,\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"local_axial\": LOCAL_AXIAL_URI,\n",
    "        \"local_isotropic\": LOCAL_ISOTROPIC_URI,\n",
    "        \"nifti_compressed\": str(NIFTI_COMPRESSED_DIR),\n",
    "        \"nifti_uncompressed\": str(NIFTI_UNCOMPRESSED_DIR),\n",
    "        \"numpy\": str(NUMPY_DIR),\n",
    "        \"s3_axial\": S3_AXIAL_URI if radi_s3_axial else None,\n",
    "        \"s3_isotropic\": S3_ISOTROPIC_URI if radi_s3_isotropic else None,\n",
    "    },\n",
    "    \"disk_space\": [r.to_dict() for r in disk_space_results],\n",
    "    \"benchmarks\": [r.to_dict() for r in all_results],\n",
    "}\n",
    "\n",
    "results_path = ASSETS_DIR / \"benchmark_results.json\"\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results_json, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Results exported: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 10. Conclusions\n",
    "\n",
    "### Tiling Strategy Impact\n",
    "\n",
    "| Operation | Optimal Tiling | Why |\n",
    "|-----------|---------------|-----|\n",
    "| 2D Axial Slice | AXIAL (z=1) | Reads exactly 1 tile per slice |\n",
    "| 3D ROI (64x64x64) | ISOTROPIC (64^3) | Reads 1-8 tiles depending on alignment |\n",
    "\n",
    "**Key Insight**: Choose tiling strategy based on your primary access pattern!\n",
    "\n",
    "### When to Use Each Framework\n",
    "\n",
    "| Use Case | Recommended Framework | Reason |\n",
    "|----------|----------------------|--------|\n",
    "| **S3/Cloud data** | RadiObject | Only option with native S3 support |\n",
    "| **Partial volume reads** | RadiObject | TileDB tile-level access |\n",
    "| **Large dataset exploration** | RadiObject | O(1) indexing, lazy views |\n",
    "| **Multi-modal alignment** | RadiObject | Unified subject index |\n",
    "| **Local NIfTI training** | MONAI/TorchIO | Optimized transforms |\n",
    "| **Data augmentation** | TorchIO | Rich transform library |\n",
    "| **Production DL pipelines** | MONAI | Comprehensive ecosystem |\n",
    "\n",
    "### RadiObject's Sweet Spot\n",
    "\n",
    "1. **Cloud-native workflows**: Train directly from S3 without downloading\n",
    "2. **Interactive analysis**: Fast metadata queries and partial reads\n",
    "3. **Large cohort studies**: Scale to 10,000+ subjects with O(1) operations\n",
    "4. **Multi-modal data**: Unified index across T1w, FLAIR, CT, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BENCHMARK COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nDatasets:\")\n",
    "print(f\"  Local AXIAL: {len(radi_local_axial) if radi_local_axial else 'N/A'} subjects\")\n",
    "print(f\"  Local ISOTROPIC: {len(radi_local_isotropic) if radi_local_isotropic else 'N/A'} subjects\")\n",
    "print(f\"  S3 AXIAL: {len(radi_s3_axial) if radi_s3_axial else 'N/A'} subjects\")\n",
    "print(f\"  S3 ISOTROPIC: {len(radi_s3_isotropic) if radi_s3_isotropic else 'N/A'} subjects\")\n",
    "print(f\"  NIfTI files: {len(nifti_paths) if nifti_paths else 0}\")\n",
    "\n",
    "print(\"\\nConfiguration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Patch size: {PATCH_SIZE}\")\n",
    "print(f\"  Runs per benchmark: {N_RUNS}\")\n",
    "\n",
    "print(\"\\nFramework Availability:\")\n",
    "print(\"  RadiObject: Available\")\n",
    "print(\"  MONAI: Available\")\n",
    "print(\"  TorchIO: Available\")\n",
    "\n",
    "print(\"\\nGenerated Artifacts:\")\n",
    "for f in sorted(ASSETS_DIR.glob(\"*\")):\n",
    "    if not f.name.startswith(\".\"):\n",
    "        print(f\"  {f.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RadiObject)",
   "language": "python",
   "name": "radiobject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1125.978873,
   "end_time": "2026-02-02T13:33:34.515239",
   "environment_variables": {},
   "exception": true,
   "input_path": "framework_benchmark.ipynb",
   "output_path": "../assets/benchmark/benchmark_default.ipynb",
   "parameters": {
    "BATCH_SIZE": 4,
    "NUM_WORKERS": 0,
    "N_RUNS": 5,
    "PATCH_SIZE": [
     64,
     64,
     64
    ],
    "RUN_S3_BENCHMARKS": true
   },
   "start_time": "2026-02-02T13:14:48.536366",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}